{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "from random import random\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import random\n",
    "# import multiprocessing\n",
    "# from multiprocessing import Pool\n",
    "from datetime import date\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# plt.style.use('fivethirtyeight')\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import concurrent.futures\n",
    "\n",
    "from copy import deepcopy\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# import spacy\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from pandas.plotting import table \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from matplotlib_venn_wordcloud import venn3_wordcloud,venn2_wordcloud\n",
    "from wordcloud import WordCloud,ImageColorGenerator\n",
    "from matplotlib_venn import venn3, venn3_circles,venn2_circles,venn2,venn2_unweighted\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#read in top 1,000 celebs\n",
    "url='https://gist.githubusercontent.com/mbejda/9c3353780270e7298763/raw/1bfc4810db4240d85947e6aef85fcae71f475493/Top-1000-Celebrity-Twitter-Accounts.csv'\n",
    "celebs=pd.read_csv(url)\n",
    "\n",
    "celebs=celebs.to_dict()\n",
    "# celebs['twitter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ariana Grande', 'Adele', 'Liam', 'Emma Watson', 'daniel tosh', 'Aamir Khan', 'Beyoncé Knowles', 'Tyra Banks', 'Deepika Padukone', 'Paulina Rubio', 'Sean Diddy Combs', 'Sabrina Sato Rahal', 'Kelly Clarkson', 'Mesut Özil', 'Sherina Sinna', 'Xabi Alonso', 'Enrique Iglesias', 'Lindsay Lohan', 'afgansyah reza', 'Seth MacFarlane', 'Karan Johar', 'Queen Latifah', 'Raffi Ahmad', 'Calvin Harris', 'Olly Murs', 'shireen sungkar', 'Jessica Iskandar', 'Mario Teguh', 'Jennette McCurdy', 'Pitty ', 'Ceará - Wellington', 'Lana Del Rey', 'Sonakshi Sinha', 'Jaden Smith', 'Gonzalo Higuaín', 'Dr Bassem Youssef', 'Ahlam - احلام', 'Iker Casillas', '•Bambang Pamungkas•', 'Angel Rivera', 'Ben Stiller', 'Luke Bryan', 'SIWON CHOI', 'Mac', 'Jonah Hill', 'Nicole Richie', 'Ratan N. Tata', 'Alan Carr', 'Angelica Panganiban', 'Tiago Leifert', 'John Green', 'Lea Michele', 'Mahendra Singh Dhoni', 'KC Concepcion', 'hayley from Paramore', 'Steve Carell', 'Felipe Neto', 'LAMAR ODOM', 'Cristine Reyes', 'Victor Valdes', 'Julia Montes', 'zach galifianakis', 'Yılmaz Erdoğan', 'Lorde', 'Jenna Mourey/Marbles', 'Maite Perroni B', 'الوليد بن طلال', 'Kevin Aprilio', 'Taraji P. Henson', 'SAM SMITH', 'FREDDY', 'Franco De Vita ', 'Tulisa Contostavlos', 'James Franco', 'amanda bynes', 'Nelly Furtado', 'Matthew Espinosa', 'Blake Griffin', 'Lali Esposito', '숮이', 'Matt Pokora', 'Manuel Neuer', 'Mr. Carter', 'David Copperfield', 'Tracy Morgan', 'BlackBottleBoy', 'Hürriyet Yazarlar', 'Nina Garcia', 'SUPER', 'Juliana Paes', 'Josh Hutcherson', 'Justin', 'Wil SCREAMton', 'Sonu Nigam', 'Can u not', 'Zappos.com CEO -Tony', 'Sintonia Verso', 'Dr. Dre', 'Mark Wahlberg', 'Alfie Deyes', 'carolina dieckmann', 'Emilio Lovera', 'Marcelo Adnet', 'Carolina Cruz Osorio', 'Tyler, The Creator', 'YASSER.S.ALQAHTANI', 'Farruko', 'Jack Johnson', 'Aaron Paul', 'Manny Pacquiao', 'Lauren London', 'Ross Lynch', 'David Ospina']\n",
      "['Ariana Grande', 'Adele', 'Liam', 'Emma Watson', 'daniel tosh', 'Aamir Khan', 'Beyoncé Knowles', 'Tyra Banks', 'Deepika Padukone', 'Paulina Rubio', 'Sean Diddy Combs', 'Sabrina Sato Rahal', 'Kelly Clarkson', 'Mesut Özil', 'Sherina Sinna', 'Xabi Alonso', 'Enrique Iglesias', 'Lindsay Lohan', 'afgansyah reza', 'Seth MacFarlane', 'Karan Johar', 'Queen Latifah', 'Raffi Ahmad', 'Calvin Harris', 'Olly Murs', 'shireen sungkar', 'Jessica Iskandar', 'Mario Teguh', 'Jennette McCurdy', 'Pitty ', 'Ceará - Wellington', 'Lana Del Rey', 'Sonakshi Sinha', 'Jaden Smith', 'Gonzalo Higuaín', 'Dr Bassem Youssef', 'Ahlam - احلام', 'Iker Casillas', '•Bambang Pamungkas•', 'Angel Rivera', 'Ben Stiller', 'Luke Bryan', 'SIWON CHOI', 'Mac', 'Jonah Hill', 'Nicole Richie', 'Ratan N. Tata', 'Alan Carr', 'Angelica Panganiban', 'Tiago Leifert', 'John Green', 'Lea Michele', 'Mahendra Singh Dhoni', 'KC Concepcion', 'hayley from Paramore', 'Steve Carell', 'Felipe Neto', 'LAMAR ODOM', 'Cristine Reyes', 'Victor Valdes', 'Julia Montes', 'zach galifianakis', 'Yılmaz Erdoğan', 'Lorde', 'Jenna Mourey/Marbles', 'Maite Perroni B', 'الوليد بن طلال', 'Kevin Aprilio', 'Taraji P. Henson', 'SAM SMITH', 'FREDDY', 'Franco De Vita ', 'Tulisa Contostavlos', 'James Franco', 'amanda bynes', 'Nelly Furtado', 'Matthew Espinosa', 'Blake Griffin', 'Lali Esposito', '숮이', 'Matt Pokora', 'Manuel Neuer', 'Mr. Carter', 'David Copperfield', 'Tracy Morgan', 'BlackBottleBoy', 'Hürriyet Yazarlar', 'Nina Garcia', 'SUPER', 'Juliana Paes', 'Josh Hutcherson', 'Justin', 'Wil SCREAMton', 'Sonu Nigam', 'Can u not', 'Zappos.com CEO -Tony', 'Sintonia Verso', 'Dr. Dre', 'Mark Wahlberg', 'Alfie Deyes', 'carolina dieckmann', 'Emilio Lovera', 'Marcelo Adnet', 'Carolina Cruz Osorio', 'Tyler, The Creator', 'YASSER.S.ALQAHTANI', 'Farruko', 'Jack Johnson', 'Aaron Paul', 'Manny Pacquiao', 'Lauren London', 'Ross Lynch', 'David Ospina', 'Jason Segel']\n",
      "['Ariana Grande', 'Adele', 'Liam', 'Emma Watson', 'daniel tosh', 'Aamir Khan', 'Beyoncé Knowles', 'Tyra Banks', 'Deepika Padukone', 'Paulina Rubio', 'Sean Diddy Combs', 'Sabrina Sato Rahal', 'Kelly Clarkson', 'Mesut Özil', 'Sherina Sinna', 'Xabi Alonso', 'Enrique Iglesias', 'Lindsay Lohan', 'afgansyah reza', 'Seth MacFarlane', 'Karan Johar', 'Queen Latifah', 'Raffi Ahmad', 'Calvin Harris', 'Olly Murs', 'shireen sungkar', 'Jessica Iskandar', 'Mario Teguh', 'Jennette McCurdy', 'Pitty ', 'Ceará - Wellington', 'Lana Del Rey', 'Sonakshi Sinha', 'Jaden Smith', 'Gonzalo Higuaín', 'Dr Bassem Youssef', 'Ahlam - احلام', 'Iker Casillas', '•Bambang Pamungkas•', 'Angel Rivera', 'Ben Stiller', 'Luke Bryan', 'SIWON CHOI', 'Mac', 'Jonah Hill', 'Nicole Richie', 'Ratan N. Tata', 'Alan Carr', 'Angelica Panganiban', 'Tiago Leifert', 'John Green', 'Lea Michele', 'Mahendra Singh Dhoni', 'KC Concepcion', 'hayley from Paramore', 'Steve Carell', 'Felipe Neto', 'LAMAR ODOM', 'Cristine Reyes', 'Victor Valdes', 'Julia Montes', 'zach galifianakis', 'Yılmaz Erdoğan', 'Lorde', 'Jenna Mourey/Marbles', 'Maite Perroni B', 'الوليد بن طلال', 'Kevin Aprilio', 'Taraji P. Henson', 'SAM SMITH', 'FREDDY', 'Franco De Vita ', 'Tulisa Contostavlos', 'James Franco', 'amanda bynes', 'Nelly Furtado', 'Matthew Espinosa', 'Blake Griffin', 'Lali Esposito', '숮이', 'Matt Pokora', 'Manuel Neuer', 'Mr. Carter', 'David Copperfield', 'Tracy Morgan', 'BlackBottleBoy', 'Hürriyet Yazarlar', 'Nina Garcia', 'SUPER', 'Juliana Paes', 'Josh Hutcherson', 'Justin', 'Wil SCREAMton', 'Sonu Nigam', 'Can u not', 'Zappos.com CEO -Tony', 'Sintonia Verso', 'Dr. Dre', 'Mark Wahlberg', 'Alfie Deyes', 'carolina dieckmann', 'Emilio Lovera', 'Marcelo Adnet', 'Carolina Cruz Osorio', 'Tyler, The Creator', 'YASSER.S.ALQAHTANI', 'Farruko', 'Jack Johnson', 'Aaron Paul', 'Manny Pacquiao', 'Lauren London', 'Ross Lynch', 'David Ospina', 'Jason Segel', 'Wanda Icardi']\n",
      "['Ariana Grande', 'Adele', 'Liam', 'Emma Watson', 'daniel tosh', 'Aamir Khan', 'Beyoncé Knowles', 'Tyra Banks', 'Deepika Padukone', 'Paulina Rubio', 'Sean Diddy Combs', 'Sabrina Sato Rahal', 'Kelly Clarkson', 'Mesut Özil', 'Sherina Sinna', 'Xabi Alonso', 'Enrique Iglesias', 'Lindsay Lohan', 'afgansyah reza', 'Seth MacFarlane', 'Karan Johar', 'Queen Latifah', 'Raffi Ahmad', 'Calvin Harris', 'Olly Murs', 'shireen sungkar', 'Jessica Iskandar', 'Mario Teguh', 'Jennette McCurdy', 'Pitty ', 'Ceará - Wellington', 'Lana Del Rey', 'Sonakshi Sinha', 'Jaden Smith', 'Gonzalo Higuaín', 'Dr Bassem Youssef', 'Ahlam - احلام', 'Iker Casillas', '•Bambang Pamungkas•', 'Angel Rivera', 'Ben Stiller', 'Luke Bryan', 'SIWON CHOI', 'Mac', 'Jonah Hill', 'Nicole Richie', 'Ratan N. Tata', 'Alan Carr', 'Angelica Panganiban', 'Tiago Leifert', 'John Green', 'Lea Michele', 'Mahendra Singh Dhoni', 'KC Concepcion', 'hayley from Paramore', 'Steve Carell', 'Felipe Neto', 'LAMAR ODOM', 'Cristine Reyes', 'Victor Valdes', 'Julia Montes', 'zach galifianakis', 'Yılmaz Erdoğan', 'Lorde', 'Jenna Mourey/Marbles', 'Maite Perroni B', 'الوليد بن طلال', 'Kevin Aprilio', 'Taraji P. Henson', 'SAM SMITH', 'FREDDY', 'Franco De Vita ', 'Tulisa Contostavlos', 'James Franco', 'amanda bynes', 'Nelly Furtado', 'Matthew Espinosa', 'Blake Griffin', 'Lali Esposito', '숮이', 'Matt Pokora', 'Manuel Neuer', 'Mr. Carter', 'David Copperfield', 'Tracy Morgan', 'BlackBottleBoy', 'Hürriyet Yazarlar', 'Nina Garcia', 'SUPER', 'Juliana Paes', 'Josh Hutcherson', 'Justin', 'Wil SCREAMton', 'Sonu Nigam', 'Can u not', 'Zappos.com CEO -Tony', 'Sintonia Verso', 'Dr. Dre', 'Mark Wahlberg', 'Alfie Deyes', 'carolina dieckmann', 'Emilio Lovera', 'Marcelo Adnet', 'Carolina Cruz Osorio', 'Tyler, The Creator', 'YASSER.S.ALQAHTANI', 'Farruko', 'Jack Johnson', 'Aaron Paul', 'Manny Pacquiao', 'Lauren London', 'Ross Lynch', 'David Ospina', 'Jason Segel', 'Wanda Icardi', 'Sidharth Malhotra']\n",
      "['Ariana Grande', 'Adele', 'Liam', 'Emma Watson', 'daniel tosh', 'Aamir Khan', 'Beyoncé Knowles', 'Tyra Banks', 'Deepika Padukone', 'Paulina Rubio', 'Sean Diddy Combs', 'Sabrina Sato Rahal', 'Kelly Clarkson', 'Mesut Özil', 'Sherina Sinna', 'Xabi Alonso', 'Enrique Iglesias', 'Lindsay Lohan', 'afgansyah reza', 'Seth MacFarlane', 'Karan Johar', 'Queen Latifah', 'Raffi Ahmad', 'Calvin Harris', 'Olly Murs', 'shireen sungkar', 'Jessica Iskandar', 'Mario Teguh', 'Jennette McCurdy', 'Pitty ', 'Ceará - Wellington', 'Lana Del Rey', 'Sonakshi Sinha', 'Jaden Smith', 'Gonzalo Higuaín', 'Dr Bassem Youssef', 'Ahlam - احلام', 'Iker Casillas', '•Bambang Pamungkas•', 'Angel Rivera', 'Ben Stiller', 'Luke Bryan', 'SIWON CHOI', 'Mac', 'Jonah Hill', 'Nicole Richie', 'Ratan N. Tata', 'Alan Carr', 'Angelica Panganiban', 'Tiago Leifert', 'John Green', 'Lea Michele', 'Mahendra Singh Dhoni', 'KC Concepcion', 'hayley from Paramore', 'Steve Carell', 'Felipe Neto', 'LAMAR ODOM', 'Cristine Reyes', 'Victor Valdes', 'Julia Montes', 'zach galifianakis', 'Yılmaz Erdoğan', 'Lorde', 'Jenna Mourey/Marbles', 'Maite Perroni B', 'الوليد بن طلال', 'Kevin Aprilio', 'Taraji P. Henson', 'SAM SMITH', 'FREDDY', 'Franco De Vita ', 'Tulisa Contostavlos', 'James Franco', 'amanda bynes', 'Nelly Furtado', 'Matthew Espinosa', 'Blake Griffin', 'Lali Esposito', '숮이', 'Matt Pokora', 'Manuel Neuer', 'Mr. Carter', 'David Copperfield', 'Tracy Morgan', 'BlackBottleBoy', 'Hürriyet Yazarlar', 'Nina Garcia', 'SUPER', 'Juliana Paes', 'Josh Hutcherson', 'Justin', 'Wil SCREAMton', 'Sonu Nigam', 'Can u not', 'Zappos.com CEO -Tony', 'Sintonia Verso', 'Dr. Dre', 'Mark Wahlberg', 'Alfie Deyes', 'carolina dieckmann', 'Emilio Lovera', 'Marcelo Adnet', 'Carolina Cruz Osorio', 'Tyler, The Creator', 'YASSER.S.ALQAHTANI', 'Farruko', 'Jack Johnson', 'Aaron Paul', 'Manny Pacquiao', 'Lauren London', 'Ross Lynch', 'David Ospina', 'Jason Segel', 'Wanda Icardi', 'Sidharth Malhotra', 'Rajinikanth']\n",
      "['Ariana Grande', 'Adele', 'Liam', 'Emma Watson', 'daniel tosh', 'Aamir Khan', 'Beyoncé Knowles', 'Tyra Banks', 'Deepika Padukone', 'Paulina Rubio', 'Sean Diddy Combs', 'Sabrina Sato Rahal', 'Kelly Clarkson', 'Mesut Özil', 'Sherina Sinna', 'Xabi Alonso', 'Enrique Iglesias', 'Lindsay Lohan', 'afgansyah reza', 'Seth MacFarlane', 'Karan Johar', 'Queen Latifah', 'Raffi Ahmad', 'Calvin Harris', 'Olly Murs', 'shireen sungkar', 'Jessica Iskandar', 'Mario Teguh', 'Jennette McCurdy', 'Pitty ', 'Ceará - Wellington', 'Lana Del Rey', 'Sonakshi Sinha', 'Jaden Smith', 'Gonzalo Higuaín', 'Dr Bassem Youssef', 'Ahlam - احلام', 'Iker Casillas', '•Bambang Pamungkas•', 'Angel Rivera', 'Ben Stiller', 'Luke Bryan', 'SIWON CHOI', 'Mac', 'Jonah Hill', 'Nicole Richie', 'Ratan N. Tata', 'Alan Carr', 'Angelica Panganiban', 'Tiago Leifert', 'John Green', 'Lea Michele', 'Mahendra Singh Dhoni', 'KC Concepcion', 'hayley from Paramore', 'Steve Carell', 'Felipe Neto', 'LAMAR ODOM', 'Cristine Reyes', 'Victor Valdes', 'Julia Montes', 'zach galifianakis', 'Yılmaz Erdoğan', 'Lorde', 'Jenna Mourey/Marbles', 'Maite Perroni B', 'الوليد بن طلال', 'Kevin Aprilio', 'Taraji P. Henson', 'SAM SMITH', 'FREDDY', 'Franco De Vita ', 'Tulisa Contostavlos', 'James Franco', 'amanda bynes', 'Nelly Furtado', 'Matthew Espinosa', 'Blake Griffin', 'Lali Esposito', '숮이', 'Matt Pokora', 'Manuel Neuer', 'Mr. Carter', 'David Copperfield', 'Tracy Morgan', 'BlackBottleBoy', 'Hürriyet Yazarlar', 'Nina Garcia', 'SUPER', 'Juliana Paes', 'Josh Hutcherson', 'Justin', 'Wil SCREAMton', 'Sonu Nigam', 'Can u not', 'Zappos.com CEO -Tony', 'Sintonia Verso', 'Dr. Dre', 'Mark Wahlberg', 'Alfie Deyes', 'carolina dieckmann', 'Emilio Lovera', 'Marcelo Adnet', 'Carolina Cruz Osorio', 'Tyler, The Creator', 'YASSER.S.ALQAHTANI', 'Farruko', 'Jack Johnson', 'Aaron Paul', 'Manny Pacquiao', 'Lauren London', 'Ross Lynch', 'David Ospina', 'Jason Segel', 'Wanda Icardi', 'Sidharth Malhotra', 'Rajinikanth', 'Siyovush Dustov']\n",
      "['Ariana Grande', 'Adele', 'Liam', 'Emma Watson', 'daniel tosh', 'Aamir Khan', 'Beyoncé Knowles', 'Tyra Banks', 'Deepika Padukone', 'Paulina Rubio', 'Sean Diddy Combs', 'Sabrina Sato Rahal', 'Kelly Clarkson', 'Mesut Özil', 'Sherina Sinna', 'Xabi Alonso', 'Enrique Iglesias', 'Lindsay Lohan', 'afgansyah reza', 'Seth MacFarlane', 'Karan Johar', 'Queen Latifah', 'Raffi Ahmad', 'Calvin Harris', 'Olly Murs', 'shireen sungkar', 'Jessica Iskandar', 'Mario Teguh', 'Jennette McCurdy', 'Pitty ', 'Ceará - Wellington', 'Lana Del Rey', 'Sonakshi Sinha', 'Jaden Smith', 'Gonzalo Higuaín', 'Dr Bassem Youssef', 'Ahlam - احلام', 'Iker Casillas', '•Bambang Pamungkas•', 'Angel Rivera', 'Ben Stiller', 'Luke Bryan', 'SIWON CHOI', 'Mac', 'Jonah Hill', 'Nicole Richie', 'Ratan N. Tata', 'Alan Carr', 'Angelica Panganiban', 'Tiago Leifert', 'John Green', 'Lea Michele', 'Mahendra Singh Dhoni', 'KC Concepcion', 'hayley from Paramore', 'Steve Carell', 'Felipe Neto', 'LAMAR ODOM', 'Cristine Reyes', 'Victor Valdes', 'Julia Montes', 'zach galifianakis', 'Yılmaz Erdoğan', 'Lorde', 'Jenna Mourey/Marbles', 'Maite Perroni B', 'الوليد بن طلال', 'Kevin Aprilio', 'Taraji P. Henson', 'SAM SMITH', 'FREDDY', 'Franco De Vita ', 'Tulisa Contostavlos', 'James Franco', 'amanda bynes', 'Nelly Furtado', 'Matthew Espinosa', 'Blake Griffin', 'Lali Esposito', '숮이', 'Matt Pokora', 'Manuel Neuer', 'Mr. Carter', 'David Copperfield', 'Tracy Morgan', 'BlackBottleBoy', 'Hürriyet Yazarlar', 'Nina Garcia', 'SUPER', 'Juliana Paes', 'Josh Hutcherson', 'Justin', 'Wil SCREAMton', 'Sonu Nigam', 'Can u not', 'Zappos.com CEO -Tony', 'Sintonia Verso', 'Dr. Dre', 'Mark Wahlberg', 'Alfie Deyes', 'carolina dieckmann', 'Emilio Lovera', 'Marcelo Adnet', 'Carolina Cruz Osorio', 'Tyler, The Creator', 'YASSER.S.ALQAHTANI', 'Farruko', 'Jack Johnson', 'Aaron Paul', 'Manny Pacquiao', 'Lauren London', 'Ross Lynch', 'David Ospina', 'Jason Segel', 'Wanda Icardi', 'Sidharth Malhotra', 'Rajinikanth', 'Siyovush Dustov', 'Katt Williams']\n",
      "['Ariana Grande', 'Adele', 'Liam', 'Emma Watson', 'daniel tosh', 'Aamir Khan', 'Beyoncé Knowles', 'Tyra Banks', 'Deepika Padukone', 'Paulina Rubio', 'Sean Diddy Combs', 'Sabrina Sato Rahal', 'Kelly Clarkson', 'Mesut Özil', 'Sherina Sinna', 'Xabi Alonso', 'Enrique Iglesias', 'Lindsay Lohan', 'afgansyah reza', 'Seth MacFarlane', 'Karan Johar', 'Queen Latifah', 'Raffi Ahmad', 'Calvin Harris', 'Olly Murs', 'shireen sungkar', 'Jessica Iskandar', 'Mario Teguh', 'Jennette McCurdy', 'Pitty ', 'Ceará - Wellington', 'Lana Del Rey', 'Sonakshi Sinha', 'Jaden Smith', 'Gonzalo Higuaín', 'Dr Bassem Youssef', 'Ahlam - احلام', 'Iker Casillas', '•Bambang Pamungkas•', 'Angel Rivera', 'Ben Stiller', 'Luke Bryan', 'SIWON CHOI', 'Mac', 'Jonah Hill', 'Nicole Richie', 'Ratan N. Tata', 'Alan Carr', 'Angelica Panganiban', 'Tiago Leifert', 'John Green', 'Lea Michele', 'Mahendra Singh Dhoni', 'KC Concepcion', 'hayley from Paramore', 'Steve Carell', 'Felipe Neto', 'LAMAR ODOM', 'Cristine Reyes', 'Victor Valdes', 'Julia Montes', 'zach galifianakis', 'Yılmaz Erdoğan', 'Lorde', 'Jenna Mourey/Marbles', 'Maite Perroni B', 'الوليد بن طلال', 'Kevin Aprilio', 'Taraji P. Henson', 'SAM SMITH', 'FREDDY', 'Franco De Vita ', 'Tulisa Contostavlos', 'James Franco', 'amanda bynes', 'Nelly Furtado', 'Matthew Espinosa', 'Blake Griffin', 'Lali Esposito', '숮이', 'Matt Pokora', 'Manuel Neuer', 'Mr. Carter', 'David Copperfield', 'Tracy Morgan', 'BlackBottleBoy', 'Hürriyet Yazarlar', 'Nina Garcia', 'SUPER', 'Juliana Paes', 'Josh Hutcherson', 'Justin', 'Wil SCREAMton', 'Sonu Nigam', 'Can u not', 'Zappos.com CEO -Tony', 'Sintonia Verso', 'Dr. Dre', 'Mark Wahlberg', 'Alfie Deyes', 'carolina dieckmann', 'Emilio Lovera', 'Marcelo Adnet', 'Carolina Cruz Osorio', 'Tyler, The Creator', 'YASSER.S.ALQAHTANI', 'Farruko', 'Jack Johnson', 'Aaron Paul', 'Manny Pacquiao', 'Lauren London', 'Ross Lynch', 'David Ospina', 'Jason Segel', 'Wanda Icardi', 'Sidharth Malhotra', 'Rajinikanth', 'Siyovush Dustov', 'Katt Williams', 'Pepe']\n",
      "['Ariana Grande', 'Adele', 'Liam', 'Emma Watson', 'daniel tosh', 'Aamir Khan', 'Beyoncé Knowles', 'Tyra Banks', 'Deepika Padukone', 'Paulina Rubio', 'Sean Diddy Combs', 'Sabrina Sato Rahal', 'Kelly Clarkson', 'Mesut Özil', 'Sherina Sinna', 'Xabi Alonso', 'Enrique Iglesias', 'Lindsay Lohan', 'afgansyah reza', 'Seth MacFarlane', 'Karan Johar', 'Queen Latifah', 'Raffi Ahmad', 'Calvin Harris', 'Olly Murs', 'shireen sungkar', 'Jessica Iskandar', 'Mario Teguh', 'Jennette McCurdy', 'Pitty ', 'Ceará - Wellington', 'Lana Del Rey', 'Sonakshi Sinha', 'Jaden Smith', 'Gonzalo Higuaín', 'Dr Bassem Youssef', 'Ahlam - احلام', 'Iker Casillas', '•Bambang Pamungkas•', 'Angel Rivera', 'Ben Stiller', 'Luke Bryan', 'SIWON CHOI', 'Mac', 'Jonah Hill', 'Nicole Richie', 'Ratan N. Tata', 'Alan Carr', 'Angelica Panganiban', 'Tiago Leifert', 'John Green', 'Lea Michele', 'Mahendra Singh Dhoni', 'KC Concepcion', 'hayley from Paramore', 'Steve Carell', 'Felipe Neto', 'LAMAR ODOM', 'Cristine Reyes', 'Victor Valdes', 'Julia Montes', 'zach galifianakis', 'Yılmaz Erdoğan', 'Lorde', 'Jenna Mourey/Marbles', 'Maite Perroni B', 'الوليد بن طلال', 'Kevin Aprilio', 'Taraji P. Henson', 'SAM SMITH', 'FREDDY', 'Franco De Vita ', 'Tulisa Contostavlos', 'James Franco', 'amanda bynes', 'Nelly Furtado', 'Matthew Espinosa', 'Blake Griffin', 'Lali Esposito', '숮이', 'Matt Pokora', 'Manuel Neuer', 'Mr. Carter', 'David Copperfield', 'Tracy Morgan', 'BlackBottleBoy', 'Hürriyet Yazarlar', 'Nina Garcia', 'SUPER', 'Juliana Paes', 'Josh Hutcherson', 'Justin', 'Wil SCREAMton', 'Sonu Nigam', 'Can u not', 'Zappos.com CEO -Tony', 'Sintonia Verso', 'Dr. Dre', 'Mark Wahlberg', 'Alfie Deyes', 'carolina dieckmann', 'Emilio Lovera', 'Marcelo Adnet', 'Carolina Cruz Osorio', 'Tyler, The Creator', 'YASSER.S.ALQAHTANI', 'Farruko', 'Jack Johnson', 'Aaron Paul', 'Manny Pacquiao', 'Lauren London', 'Ross Lynch', 'David Ospina', 'Jason Segel', 'Wanda Icardi', 'Sidharth Malhotra', 'Rajinikanth', 'Siyovush Dustov', 'Katt Williams', 'Pepe', 'Lady Antebellum']\n",
      "['Ariana Grande', 'Adele', 'Liam', 'Emma Watson', 'daniel tosh', 'Aamir Khan', 'Beyoncé Knowles', 'Tyra Banks', 'Deepika Padukone', 'Paulina Rubio', 'Sean Diddy Combs', 'Sabrina Sato Rahal', 'Kelly Clarkson', 'Mesut Özil', 'Sherina Sinna', 'Xabi Alonso', 'Enrique Iglesias', 'Lindsay Lohan', 'afgansyah reza', 'Seth MacFarlane', 'Karan Johar', 'Queen Latifah', 'Raffi Ahmad', 'Calvin Harris', 'Olly Murs', 'shireen sungkar', 'Jessica Iskandar', 'Mario Teguh', 'Jennette McCurdy', 'Pitty ', 'Ceará - Wellington', 'Lana Del Rey', 'Sonakshi Sinha', 'Jaden Smith', 'Gonzalo Higuaín', 'Dr Bassem Youssef', 'Ahlam - احلام', 'Iker Casillas', '•Bambang Pamungkas•', 'Angel Rivera', 'Ben Stiller', 'Luke Bryan', 'SIWON CHOI', 'Mac', 'Jonah Hill', 'Nicole Richie', 'Ratan N. Tata', 'Alan Carr', 'Angelica Panganiban', 'Tiago Leifert', 'John Green', 'Lea Michele', 'Mahendra Singh Dhoni', 'KC Concepcion', 'hayley from Paramore', 'Steve Carell', 'Felipe Neto', 'LAMAR ODOM', 'Cristine Reyes', 'Victor Valdes', 'Julia Montes', 'zach galifianakis', 'Yılmaz Erdoğan', 'Lorde', 'Jenna Mourey/Marbles', 'Maite Perroni B', 'الوليد بن طلال', 'Kevin Aprilio', 'Taraji P. Henson', 'SAM SMITH', 'FREDDY', 'Franco De Vita ', 'Tulisa Contostavlos', 'James Franco', 'amanda bynes', 'Nelly Furtado', 'Matthew Espinosa', 'Blake Griffin', 'Lali Esposito', '숮이', 'Matt Pokora', 'Manuel Neuer', 'Mr. Carter', 'David Copperfield', 'Tracy Morgan', 'BlackBottleBoy', 'Hürriyet Yazarlar', 'Nina Garcia', 'SUPER', 'Juliana Paes', 'Josh Hutcherson', 'Justin', 'Wil SCREAMton', 'Sonu Nigam', 'Can u not', 'Zappos.com CEO -Tony', 'Sintonia Verso', 'Dr. Dre', 'Mark Wahlberg', 'Alfie Deyes', 'carolina dieckmann', 'Emilio Lovera', 'Marcelo Adnet', 'Carolina Cruz Osorio', 'Tyler, The Creator', 'YASSER.S.ALQAHTANI', 'Farruko', 'Jack Johnson', 'Aaron Paul', 'Manny Pacquiao', 'Lauren London', 'Ross Lynch', 'David Ospina', 'Jason Segel', 'Wanda Icardi', 'Sidharth Malhotra', 'Rajinikanth', 'Siyovush Dustov', 'Katt Williams', 'Pepe', 'Lady Antebellum', 'Dani Martínez']\n",
      "['Ariana Grande', 'Adele', 'Liam', 'Emma Watson', 'daniel tosh', 'Aamir Khan', 'Beyoncé Knowles', 'Tyra Banks', 'Deepika Padukone', 'Paulina Rubio', 'Sean Diddy Combs', 'Sabrina Sato Rahal', 'Kelly Clarkson', 'Mesut Özil', 'Sherina Sinna', 'Xabi Alonso', 'Enrique Iglesias', 'Lindsay Lohan', 'afgansyah reza', 'Seth MacFarlane', 'Karan Johar', 'Queen Latifah', 'Raffi Ahmad', 'Calvin Harris', 'Olly Murs', 'shireen sungkar', 'Jessica Iskandar', 'Mario Teguh', 'Jennette McCurdy', 'Pitty ', 'Ceará - Wellington', 'Lana Del Rey', 'Sonakshi Sinha', 'Jaden Smith', 'Gonzalo Higuaín', 'Dr Bassem Youssef', 'Ahlam - احلام', 'Iker Casillas', '•Bambang Pamungkas•', 'Angel Rivera', 'Ben Stiller', 'Luke Bryan', 'SIWON CHOI', 'Mac', 'Jonah Hill', 'Nicole Richie', 'Ratan N. Tata', 'Alan Carr', 'Angelica Panganiban', 'Tiago Leifert', 'John Green', 'Lea Michele', 'Mahendra Singh Dhoni', 'KC Concepcion', 'hayley from Paramore', 'Steve Carell', 'Felipe Neto', 'LAMAR ODOM', 'Cristine Reyes', 'Victor Valdes', 'Julia Montes', 'zach galifianakis', 'Yılmaz Erdoğan', 'Lorde', 'Jenna Mourey/Marbles', 'Maite Perroni B', 'الوليد بن طلال', 'Kevin Aprilio', 'Taraji P. Henson', 'SAM SMITH', 'FREDDY', 'Franco De Vita ', 'Tulisa Contostavlos', 'James Franco', 'amanda bynes', 'Nelly Furtado', 'Matthew Espinosa', 'Blake Griffin', 'Lali Esposito', '숮이', 'Matt Pokora', 'Manuel Neuer', 'Mr. Carter', 'David Copperfield', 'Tracy Morgan', 'BlackBottleBoy', 'Hürriyet Yazarlar', 'Nina Garcia', 'SUPER', 'Juliana Paes', 'Josh Hutcherson', 'Justin', 'Wil SCREAMton', 'Sonu Nigam', 'Can u not', 'Zappos.com CEO -Tony', 'Sintonia Verso', 'Dr. Dre', 'Mark Wahlberg', 'Alfie Deyes', 'carolina dieckmann', 'Emilio Lovera', 'Marcelo Adnet', 'Carolina Cruz Osorio', 'Tyler, The Creator', 'YASSER.S.ALQAHTANI', 'Farruko', 'Jack Johnson', 'Aaron Paul', 'Manny Pacquiao', 'Lauren London', 'Ross Lynch', 'David Ospina', 'Jason Segel', 'Wanda Icardi', 'Sidharth Malhotra', 'Rajinikanth', 'Siyovush Dustov', 'Katt Williams', 'Pepe', 'Lady Antebellum', 'Dani Martínez', 'Ferry Yolanda F']\n",
      "['Ariana Grande', 'Adele', 'Liam', 'Emma Watson', 'daniel tosh', 'Aamir Khan', 'Beyoncé Knowles', 'Tyra Banks', 'Deepika Padukone', 'Paulina Rubio', 'Sean Diddy Combs', 'Sabrina Sato Rahal', 'Kelly Clarkson', 'Mesut Özil', 'Sherina Sinna', 'Xabi Alonso', 'Enrique Iglesias', 'Lindsay Lohan', 'afgansyah reza', 'Seth MacFarlane', 'Karan Johar', 'Queen Latifah', 'Raffi Ahmad', 'Calvin Harris', 'Olly Murs', 'shireen sungkar', 'Jessica Iskandar', 'Mario Teguh', 'Jennette McCurdy', 'Pitty ', 'Ceará - Wellington', 'Lana Del Rey', 'Sonakshi Sinha', 'Jaden Smith', 'Gonzalo Higuaín', 'Dr Bassem Youssef', 'Ahlam - احلام', 'Iker Casillas', '•Bambang Pamungkas•', 'Angel Rivera', 'Ben Stiller', 'Luke Bryan', 'SIWON CHOI', 'Mac', 'Jonah Hill', 'Nicole Richie', 'Ratan N. Tata', 'Alan Carr', 'Angelica Panganiban', 'Tiago Leifert', 'John Green', 'Lea Michele', 'Mahendra Singh Dhoni', 'KC Concepcion', 'hayley from Paramore', 'Steve Carell', 'Felipe Neto', 'LAMAR ODOM', 'Cristine Reyes', 'Victor Valdes', 'Julia Montes', 'zach galifianakis', 'Yılmaz Erdoğan', 'Lorde', 'Jenna Mourey/Marbles', 'Maite Perroni B', 'الوليد بن طلال', 'Kevin Aprilio', 'Taraji P. Henson', 'SAM SMITH', 'FREDDY', 'Franco De Vita ', 'Tulisa Contostavlos', 'James Franco', 'amanda bynes', 'Nelly Furtado', 'Matthew Espinosa', 'Blake Griffin', 'Lali Esposito', '숮이', 'Matt Pokora', 'Manuel Neuer', 'Mr. Carter', 'David Copperfield', 'Tracy Morgan', 'BlackBottleBoy', 'Hürriyet Yazarlar', 'Nina Garcia', 'SUPER', 'Juliana Paes', 'Josh Hutcherson', 'Justin', 'Wil SCREAMton', 'Sonu Nigam', 'Can u not', 'Zappos.com CEO -Tony', 'Sintonia Verso', 'Dr. Dre', 'Mark Wahlberg', 'Alfie Deyes', 'carolina dieckmann', 'Emilio Lovera', 'Marcelo Adnet', 'Carolina Cruz Osorio', 'Tyler, The Creator', 'YASSER.S.ALQAHTANI', 'Farruko', 'Jack Johnson', 'Aaron Paul', 'Manny Pacquiao', 'Lauren London', 'Ross Lynch', 'David Ospina', 'Jason Segel', 'Wanda Icardi', 'Sidharth Malhotra', 'Rajinikanth', 'Siyovush Dustov', 'Katt Williams', 'Pepe', 'Lady Antebellum', 'Dani Martínez', 'Ferry Yolanda F', 'Mike Vick']\n",
      "['Ariana Grande', 'Adele', 'Liam', 'Emma Watson', 'daniel tosh', 'Aamir Khan', 'Beyoncé Knowles', 'Tyra Banks', 'Deepika Padukone', 'Paulina Rubio', 'Sean Diddy Combs', 'Sabrina Sato Rahal', 'Kelly Clarkson', 'Mesut Özil', 'Sherina Sinna', 'Xabi Alonso', 'Enrique Iglesias', 'Lindsay Lohan', 'afgansyah reza', 'Seth MacFarlane', 'Karan Johar', 'Queen Latifah', 'Raffi Ahmad', 'Calvin Harris', 'Olly Murs', 'shireen sungkar', 'Jessica Iskandar', 'Mario Teguh', 'Jennette McCurdy', 'Pitty ', 'Ceará - Wellington', 'Lana Del Rey', 'Sonakshi Sinha', 'Jaden Smith', 'Gonzalo Higuaín', 'Dr Bassem Youssef', 'Ahlam - احلام', 'Iker Casillas', '•Bambang Pamungkas•', 'Angel Rivera', 'Ben Stiller', 'Luke Bryan', 'SIWON CHOI', 'Mac', 'Jonah Hill', 'Nicole Richie', 'Ratan N. Tata', 'Alan Carr', 'Angelica Panganiban', 'Tiago Leifert', 'John Green', 'Lea Michele', 'Mahendra Singh Dhoni', 'KC Concepcion', 'hayley from Paramore', 'Steve Carell', 'Felipe Neto', 'LAMAR ODOM', 'Cristine Reyes', 'Victor Valdes', 'Julia Montes', 'zach galifianakis', 'Yılmaz Erdoğan', 'Lorde', 'Jenna Mourey/Marbles', 'Maite Perroni B', 'الوليد بن طلال', 'Kevin Aprilio', 'Taraji P. Henson', 'SAM SMITH', 'FREDDY', 'Franco De Vita ', 'Tulisa Contostavlos', 'James Franco', 'amanda bynes', 'Nelly Furtado', 'Matthew Espinosa', 'Blake Griffin', 'Lali Esposito', '숮이', 'Matt Pokora', 'Manuel Neuer', 'Mr. Carter', 'David Copperfield', 'Tracy Morgan', 'BlackBottleBoy', 'Hürriyet Yazarlar', 'Nina Garcia', 'SUPER', 'Juliana Paes', 'Josh Hutcherson', 'Justin', 'Wil SCREAMton', 'Sonu Nigam', 'Can u not', 'Zappos.com CEO -Tony', 'Sintonia Verso', 'Dr. Dre', 'Mark Wahlberg', 'Alfie Deyes', 'carolina dieckmann', 'Emilio Lovera', 'Marcelo Adnet', 'Carolina Cruz Osorio', 'Tyler, The Creator', 'YASSER.S.ALQAHTANI', 'Farruko', 'Jack Johnson', 'Aaron Paul', 'Manny Pacquiao', 'Lauren London', 'Ross Lynch', 'David Ospina', 'Jason Segel', 'Wanda Icardi', 'Sidharth Malhotra', 'Rajinikanth', 'Siyovush Dustov', 'Katt Williams', 'Pepe', 'Lady Antebellum', 'Dani Martínez', 'Ferry Yolanda F', 'Mike Vick', 'Marco Reus']\n",
      "['Ariana Grande', 'Adele', 'Liam', 'Emma Watson', 'daniel tosh', 'Aamir Khan', 'Beyoncé Knowles', 'Tyra Banks', 'Deepika Padukone', 'Paulina Rubio', 'Sean Diddy Combs', 'Sabrina Sato Rahal', 'Kelly Clarkson', 'Mesut Özil', 'Sherina Sinna', 'Xabi Alonso', 'Enrique Iglesias', 'Lindsay Lohan', 'afgansyah reza', 'Seth MacFarlane', 'Karan Johar', 'Queen Latifah', 'Raffi Ahmad', 'Calvin Harris', 'Olly Murs', 'shireen sungkar', 'Jessica Iskandar', 'Mario Teguh', 'Jennette McCurdy', 'Pitty ', 'Ceará - Wellington', 'Lana Del Rey', 'Sonakshi Sinha', 'Jaden Smith', 'Gonzalo Higuaín', 'Dr Bassem Youssef', 'Ahlam - احلام', 'Iker Casillas', '•Bambang Pamungkas•', 'Angel Rivera', 'Ben Stiller', 'Luke Bryan', 'SIWON CHOI', 'Mac', 'Jonah Hill', 'Nicole Richie', 'Ratan N. Tata', 'Alan Carr', 'Angelica Panganiban', 'Tiago Leifert', 'John Green', 'Lea Michele', 'Mahendra Singh Dhoni', 'KC Concepcion', 'hayley from Paramore', 'Steve Carell', 'Felipe Neto', 'LAMAR ODOM', 'Cristine Reyes', 'Victor Valdes', 'Julia Montes', 'zach galifianakis', 'Yılmaz Erdoğan', 'Lorde', 'Jenna Mourey/Marbles', 'Maite Perroni B', 'الوليد بن طلال', 'Kevin Aprilio', 'Taraji P. Henson', 'SAM SMITH', 'FREDDY', 'Franco De Vita ', 'Tulisa Contostavlos', 'James Franco', 'amanda bynes', 'Nelly Furtado', 'Matthew Espinosa', 'Blake Griffin', 'Lali Esposito', '숮이', 'Matt Pokora', 'Manuel Neuer', 'Mr. Carter', 'David Copperfield', 'Tracy Morgan', 'BlackBottleBoy', 'Hürriyet Yazarlar', 'Nina Garcia', 'SUPER', 'Juliana Paes', 'Josh Hutcherson', 'Justin', 'Wil SCREAMton', 'Sonu Nigam', 'Can u not', 'Zappos.com CEO -Tony', 'Sintonia Verso', 'Dr. Dre', 'Mark Wahlberg', 'Alfie Deyes', 'carolina dieckmann', 'Emilio Lovera', 'Marcelo Adnet', 'Carolina Cruz Osorio', 'Tyler, The Creator', 'YASSER.S.ALQAHTANI', 'Farruko', 'Jack Johnson', 'Aaron Paul', 'Manny Pacquiao', 'Lauren London', 'Ross Lynch', 'David Ospina', 'Jason Segel', 'Wanda Icardi', 'Sidharth Malhotra', 'Rajinikanth', 'Siyovush Dustov', 'Katt Williams', 'Pepe', 'Lady Antebellum', 'Dani Martínez', 'Ferry Yolanda F', 'Mike Vick', 'Marco Reus', 'Al Ghazali Kohler']\n",
      "['Ariana Grande', 'Adele', 'Liam', 'Emma Watson', 'daniel tosh', 'Aamir Khan', 'Beyoncé Knowles', 'Tyra Banks', 'Deepika Padukone', 'Paulina Rubio', 'Sean Diddy Combs', 'Sabrina Sato Rahal', 'Kelly Clarkson', 'Mesut Özil', 'Sherina Sinna', 'Xabi Alonso', 'Enrique Iglesias', 'Lindsay Lohan', 'afgansyah reza', 'Seth MacFarlane', 'Karan Johar', 'Queen Latifah', 'Raffi Ahmad', 'Calvin Harris', 'Olly Murs', 'shireen sungkar', 'Jessica Iskandar', 'Mario Teguh', 'Jennette McCurdy', 'Pitty ', 'Ceará - Wellington', 'Lana Del Rey', 'Sonakshi Sinha', 'Jaden Smith', 'Gonzalo Higuaín', 'Dr Bassem Youssef', 'Ahlam - احلام', 'Iker Casillas', '•Bambang Pamungkas•', 'Angel Rivera', 'Ben Stiller', 'Luke Bryan', 'SIWON CHOI', 'Mac', 'Jonah Hill', 'Nicole Richie', 'Ratan N. Tata', 'Alan Carr', 'Angelica Panganiban', 'Tiago Leifert', 'John Green', 'Lea Michele', 'Mahendra Singh Dhoni', 'KC Concepcion', 'hayley from Paramore', 'Steve Carell', 'Felipe Neto', 'LAMAR ODOM', 'Cristine Reyes', 'Victor Valdes', 'Julia Montes', 'zach galifianakis', 'Yılmaz Erdoğan', 'Lorde', 'Jenna Mourey/Marbles', 'Maite Perroni B', 'الوليد بن طلال', 'Kevin Aprilio', 'Taraji P. Henson', 'SAM SMITH', 'FREDDY', 'Franco De Vita ', 'Tulisa Contostavlos', 'James Franco', 'amanda bynes', 'Nelly Furtado', 'Matthew Espinosa', 'Blake Griffin', 'Lali Esposito', '숮이', 'Matt Pokora', 'Manuel Neuer', 'Mr. Carter', 'David Copperfield', 'Tracy Morgan', 'BlackBottleBoy', 'Hürriyet Yazarlar', 'Nina Garcia', 'SUPER', 'Juliana Paes', 'Josh Hutcherson', 'Justin', 'Wil SCREAMton', 'Sonu Nigam', 'Can u not', 'Zappos.com CEO -Tony', 'Sintonia Verso', 'Dr. Dre', 'Mark Wahlberg', 'Alfie Deyes', 'carolina dieckmann', 'Emilio Lovera', 'Marcelo Adnet', 'Carolina Cruz Osorio', 'Tyler, The Creator', 'YASSER.S.ALQAHTANI', 'Farruko', 'Jack Johnson', 'Aaron Paul', 'Manny Pacquiao', 'Lauren London', 'Ross Lynch', 'David Ospina', 'Jason Segel', 'Wanda Icardi', 'Sidharth Malhotra', 'Rajinikanth', 'Siyovush Dustov', 'Katt Williams', 'Pepe', 'Lady Antebellum', 'Dani Martínez', 'Ferry Yolanda F', 'Mike Vick', 'Marco Reus', 'Al Ghazali Kohler', 'Daniel Bryan']\n",
      "['Ariana Grande', 'Adele', 'Liam', 'Emma Watson', 'daniel tosh', 'Aamir Khan', 'Beyoncé Knowles', 'Tyra Banks', 'Deepika Padukone', 'Paulina Rubio', 'Sean Diddy Combs', 'Sabrina Sato Rahal', 'Kelly Clarkson', 'Mesut Özil', 'Sherina Sinna', 'Xabi Alonso', 'Enrique Iglesias', 'Lindsay Lohan', 'afgansyah reza', 'Seth MacFarlane', 'Karan Johar', 'Queen Latifah', 'Raffi Ahmad', 'Calvin Harris', 'Olly Murs', 'shireen sungkar', 'Jessica Iskandar', 'Mario Teguh', 'Jennette McCurdy', 'Pitty ', 'Ceará - Wellington', 'Lana Del Rey', 'Sonakshi Sinha', 'Jaden Smith', 'Gonzalo Higuaín', 'Dr Bassem Youssef', 'Ahlam - احلام', 'Iker Casillas', '•Bambang Pamungkas•', 'Angel Rivera', 'Ben Stiller', 'Luke Bryan', 'SIWON CHOI', 'Mac', 'Jonah Hill', 'Nicole Richie', 'Ratan N. Tata', 'Alan Carr', 'Angelica Panganiban', 'Tiago Leifert', 'John Green', 'Lea Michele', 'Mahendra Singh Dhoni', 'KC Concepcion', 'hayley from Paramore', 'Steve Carell', 'Felipe Neto', 'LAMAR ODOM', 'Cristine Reyes', 'Victor Valdes', 'Julia Montes', 'zach galifianakis', 'Yılmaz Erdoğan', 'Lorde', 'Jenna Mourey/Marbles', 'Maite Perroni B', 'الوليد بن طلال', 'Kevin Aprilio', 'Taraji P. Henson', 'SAM SMITH', 'FREDDY', 'Franco De Vita ', 'Tulisa Contostavlos', 'James Franco', 'amanda bynes', 'Nelly Furtado', 'Matthew Espinosa', 'Blake Griffin', 'Lali Esposito', '숮이', 'Matt Pokora', 'Manuel Neuer', 'Mr. Carter', 'David Copperfield', 'Tracy Morgan', 'BlackBottleBoy', 'Hürriyet Yazarlar', 'Nina Garcia', 'SUPER', 'Juliana Paes', 'Josh Hutcherson', 'Justin', 'Wil SCREAMton', 'Sonu Nigam', 'Can u not', 'Zappos.com CEO -Tony', 'Sintonia Verso', 'Dr. Dre', 'Mark Wahlberg', 'Alfie Deyes', 'carolina dieckmann', 'Emilio Lovera', 'Marcelo Adnet', 'Carolina Cruz Osorio', 'Tyler, The Creator', 'YASSER.S.ALQAHTANI', 'Farruko', 'Jack Johnson', 'Aaron Paul', 'Manny Pacquiao', 'Lauren London', 'Ross Lynch', 'David Ospina', 'Jason Segel', 'Wanda Icardi', 'Sidharth Malhotra', 'Rajinikanth', 'Siyovush Dustov', 'Katt Williams', 'Pepe', 'Lady Antebellum', 'Dani Martínez', 'Ferry Yolanda F', 'Mike Vick', 'Marco Reus', 'Al Ghazali Kohler', 'Daniel Bryan', 'Derrick Rose']\n",
      "['Ariana Grande', 'Adele', 'Liam', 'Emma Watson', 'daniel tosh', 'Aamir Khan', 'Beyoncé Knowles', 'Tyra Banks', 'Deepika Padukone', 'Paulina Rubio', 'Sean Diddy Combs', 'Sabrina Sato Rahal', 'Kelly Clarkson', 'Mesut Özil', 'Sherina Sinna', 'Xabi Alonso', 'Enrique Iglesias', 'Lindsay Lohan', 'afgansyah reza', 'Seth MacFarlane', 'Karan Johar', 'Queen Latifah', 'Raffi Ahmad', 'Calvin Harris', 'Olly Murs', 'shireen sungkar', 'Jessica Iskandar', 'Mario Teguh', 'Jennette McCurdy', 'Pitty ', 'Ceará - Wellington', 'Lana Del Rey', 'Sonakshi Sinha', 'Jaden Smith', 'Gonzalo Higuaín', 'Dr Bassem Youssef', 'Ahlam - احلام', 'Iker Casillas', '•Bambang Pamungkas•', 'Angel Rivera', 'Ben Stiller', 'Luke Bryan', 'SIWON CHOI', 'Mac', 'Jonah Hill', 'Nicole Richie', 'Ratan N. Tata', 'Alan Carr', 'Angelica Panganiban', 'Tiago Leifert', 'John Green', 'Lea Michele', 'Mahendra Singh Dhoni', 'KC Concepcion', 'hayley from Paramore', 'Steve Carell', 'Felipe Neto', 'LAMAR ODOM', 'Cristine Reyes', 'Victor Valdes', 'Julia Montes', 'zach galifianakis', 'Yılmaz Erdoğan', 'Lorde', 'Jenna Mourey/Marbles', 'Maite Perroni B', 'الوليد بن طلال', 'Kevin Aprilio', 'Taraji P. Henson', 'SAM SMITH', 'FREDDY', 'Franco De Vita ', 'Tulisa Contostavlos', 'James Franco', 'amanda bynes', 'Nelly Furtado', 'Matthew Espinosa', 'Blake Griffin', 'Lali Esposito', '숮이', 'Matt Pokora', 'Manuel Neuer', 'Mr. Carter', 'David Copperfield', 'Tracy Morgan', 'BlackBottleBoy', 'Hürriyet Yazarlar', 'Nina Garcia', 'SUPER', 'Juliana Paes', 'Josh Hutcherson', 'Justin', 'Wil SCREAMton', 'Sonu Nigam', 'Can u not', 'Zappos.com CEO -Tony', 'Sintonia Verso', 'Dr. Dre', 'Mark Wahlberg', 'Alfie Deyes', 'carolina dieckmann', 'Emilio Lovera', 'Marcelo Adnet', 'Carolina Cruz Osorio', 'Tyler, The Creator', 'YASSER.S.ALQAHTANI', 'Farruko', 'Jack Johnson', 'Aaron Paul', 'Manny Pacquiao', 'Lauren London', 'Ross Lynch', 'David Ospina', 'Jason Segel', 'Wanda Icardi', 'Sidharth Malhotra', 'Rajinikanth', 'Siyovush Dustov', 'Katt Williams', 'Pepe', 'Lady Antebellum', 'Dani Martínez', 'Ferry Yolanda F', 'Mike Vick', 'Marco Reus', 'Al Ghazali Kohler', 'Daniel Bryan', 'Derrick Rose', 'Fabio Coentrao']\n",
      "['Ariana Grande', 'Adele', 'Liam', 'Emma Watson', 'daniel tosh', 'Aamir Khan', 'Beyoncé Knowles', 'Tyra Banks', 'Deepika Padukone', 'Paulina Rubio', 'Sean Diddy Combs', 'Sabrina Sato Rahal', 'Kelly Clarkson', 'Mesut Özil', 'Sherina Sinna', 'Xabi Alonso', 'Enrique Iglesias', 'Lindsay Lohan', 'afgansyah reza', 'Seth MacFarlane', 'Karan Johar', 'Queen Latifah', 'Raffi Ahmad', 'Calvin Harris', 'Olly Murs', 'shireen sungkar', 'Jessica Iskandar', 'Mario Teguh', 'Jennette McCurdy', 'Pitty ', 'Ceará - Wellington', 'Lana Del Rey', 'Sonakshi Sinha', 'Jaden Smith', 'Gonzalo Higuaín', 'Dr Bassem Youssef', 'Ahlam - احلام', 'Iker Casillas', '•Bambang Pamungkas•', 'Angel Rivera', 'Ben Stiller', 'Luke Bryan', 'SIWON CHOI', 'Mac', 'Jonah Hill', 'Nicole Richie', 'Ratan N. Tata', 'Alan Carr', 'Angelica Panganiban', 'Tiago Leifert', 'John Green', 'Lea Michele', 'Mahendra Singh Dhoni', 'KC Concepcion', 'hayley from Paramore', 'Steve Carell', 'Felipe Neto', 'LAMAR ODOM', 'Cristine Reyes', 'Victor Valdes', 'Julia Montes', 'zach galifianakis', 'Yılmaz Erdoğan', 'Lorde', 'Jenna Mourey/Marbles', 'Maite Perroni B', 'الوليد بن طلال', 'Kevin Aprilio', 'Taraji P. Henson', 'SAM SMITH', 'FREDDY', 'Franco De Vita ', 'Tulisa Contostavlos', 'James Franco', 'amanda bynes', 'Nelly Furtado', 'Matthew Espinosa', 'Blake Griffin', 'Lali Esposito', '숮이', 'Matt Pokora', 'Manuel Neuer', 'Mr. Carter', 'David Copperfield', 'Tracy Morgan', 'BlackBottleBoy', 'Hürriyet Yazarlar', 'Nina Garcia', 'SUPER', 'Juliana Paes', 'Josh Hutcherson', 'Justin', 'Wil SCREAMton', 'Sonu Nigam', 'Can u not', 'Zappos.com CEO -Tony', 'Sintonia Verso', 'Dr. Dre', 'Mark Wahlberg', 'Alfie Deyes', 'carolina dieckmann', 'Emilio Lovera', 'Marcelo Adnet', 'Carolina Cruz Osorio', 'Tyler, The Creator', 'YASSER.S.ALQAHTANI', 'Farruko', 'Jack Johnson', 'Aaron Paul', 'Manny Pacquiao', 'Lauren London', 'Ross Lynch', 'David Ospina', 'Jason Segel', 'Wanda Icardi', 'Sidharth Malhotra', 'Rajinikanth', 'Siyovush Dustov', 'Katt Williams', 'Pepe', 'Lady Antebellum', 'Dani Martínez', 'Ferry Yolanda F', 'Mike Vick', 'Marco Reus', 'Al Ghazali Kohler', 'Daniel Bryan', 'Derrick Rose', 'Fabio Coentrao', 'Anthony Padilla']\n",
      "['Ariana Grande', 'Adele', 'Liam', 'Emma Watson', 'daniel tosh', 'Aamir Khan', 'Beyoncé Knowles', 'Tyra Banks', 'Deepika Padukone', 'Paulina Rubio', 'Sean Diddy Combs', 'Sabrina Sato Rahal', 'Kelly Clarkson', 'Mesut Özil', 'Sherina Sinna', 'Xabi Alonso', 'Enrique Iglesias', 'Lindsay Lohan', 'afgansyah reza', 'Seth MacFarlane', 'Karan Johar', 'Queen Latifah', 'Raffi Ahmad', 'Calvin Harris', 'Olly Murs', 'shireen sungkar', 'Jessica Iskandar', 'Mario Teguh', 'Jennette McCurdy', 'Pitty ', 'Ceará - Wellington', 'Lana Del Rey', 'Sonakshi Sinha', 'Jaden Smith', 'Gonzalo Higuaín', 'Dr Bassem Youssef', 'Ahlam - احلام', 'Iker Casillas', '•Bambang Pamungkas•', 'Angel Rivera', 'Ben Stiller', 'Luke Bryan', 'SIWON CHOI', 'Mac', 'Jonah Hill', 'Nicole Richie', 'Ratan N. Tata', 'Alan Carr', 'Angelica Panganiban', 'Tiago Leifert', 'John Green', 'Lea Michele', 'Mahendra Singh Dhoni', 'KC Concepcion', 'hayley from Paramore', 'Steve Carell', 'Felipe Neto', 'LAMAR ODOM', 'Cristine Reyes', 'Victor Valdes', 'Julia Montes', 'zach galifianakis', 'Yılmaz Erdoğan', 'Lorde', 'Jenna Mourey/Marbles', 'Maite Perroni B', 'الوليد بن طلال', 'Kevin Aprilio', 'Taraji P. Henson', 'SAM SMITH', 'FREDDY', 'Franco De Vita ', 'Tulisa Contostavlos', 'James Franco', 'amanda bynes', 'Nelly Furtado', 'Matthew Espinosa', 'Blake Griffin', 'Lali Esposito', '숮이', 'Matt Pokora', 'Manuel Neuer', 'Mr. Carter', 'David Copperfield', 'Tracy Morgan', 'BlackBottleBoy', 'Hürriyet Yazarlar', 'Nina Garcia', 'SUPER', 'Juliana Paes', 'Josh Hutcherson', 'Justin', 'Wil SCREAMton', 'Sonu Nigam', 'Can u not', 'Zappos.com CEO -Tony', 'Sintonia Verso', 'Dr. Dre', 'Mark Wahlberg', 'Alfie Deyes', 'carolina dieckmann', 'Emilio Lovera', 'Marcelo Adnet', 'Carolina Cruz Osorio', 'Tyler, The Creator', 'YASSER.S.ALQAHTANI', 'Farruko', 'Jack Johnson', 'Aaron Paul', 'Manny Pacquiao', 'Lauren London', 'Ross Lynch', 'David Ospina', 'Jason Segel', 'Wanda Icardi', 'Sidharth Malhotra', 'Rajinikanth', 'Siyovush Dustov', 'Katt Williams', 'Pepe', 'Lady Antebellum', 'Dani Martínez', 'Ferry Yolanda F', 'Mike Vick', 'Marco Reus', 'Al Ghazali Kohler', 'Daniel Bryan', 'Derrick Rose', 'Fabio Coentrao', 'Anthony Padilla', 'Amy Schumer']\n",
      "['Ariana Grande', 'Adele', 'Liam', 'Emma Watson', 'daniel tosh', 'Aamir Khan', 'Beyoncé Knowles', 'Tyra Banks', 'Deepika Padukone', 'Paulina Rubio', 'Sean Diddy Combs', 'Sabrina Sato Rahal', 'Kelly Clarkson', 'Mesut Özil', 'Sherina Sinna', 'Xabi Alonso', 'Enrique Iglesias', 'Lindsay Lohan', 'afgansyah reza', 'Seth MacFarlane', 'Karan Johar', 'Queen Latifah', 'Raffi Ahmad', 'Calvin Harris', 'Olly Murs', 'shireen sungkar', 'Jessica Iskandar', 'Mario Teguh', 'Jennette McCurdy', 'Pitty ', 'Ceará - Wellington', 'Lana Del Rey', 'Sonakshi Sinha', 'Jaden Smith', 'Gonzalo Higuaín', 'Dr Bassem Youssef', 'Ahlam - احلام', 'Iker Casillas', '•Bambang Pamungkas•', 'Angel Rivera', 'Ben Stiller', 'Luke Bryan', 'SIWON CHOI', 'Mac', 'Jonah Hill', 'Nicole Richie', 'Ratan N. Tata', 'Alan Carr', 'Angelica Panganiban', 'Tiago Leifert', 'John Green', 'Lea Michele', 'Mahendra Singh Dhoni', 'KC Concepcion', 'hayley from Paramore', 'Steve Carell', 'Felipe Neto', 'LAMAR ODOM', 'Cristine Reyes', 'Victor Valdes', 'Julia Montes', 'zach galifianakis', 'Yılmaz Erdoğan', 'Lorde', 'Jenna Mourey/Marbles', 'Maite Perroni B', 'الوليد بن طلال', 'Kevin Aprilio', 'Taraji P. Henson', 'SAM SMITH', 'FREDDY', 'Franco De Vita ', 'Tulisa Contostavlos', 'James Franco', 'amanda bynes', 'Nelly Furtado', 'Matthew Espinosa', 'Blake Griffin', 'Lali Esposito', '숮이', 'Matt Pokora', 'Manuel Neuer', 'Mr. Carter', 'David Copperfield', 'Tracy Morgan', 'BlackBottleBoy', 'Hürriyet Yazarlar', 'Nina Garcia', 'SUPER', 'Juliana Paes', 'Josh Hutcherson', 'Justin', 'Wil SCREAMton', 'Sonu Nigam', 'Can u not', 'Zappos.com CEO -Tony', 'Sintonia Verso', 'Dr. Dre', 'Mark Wahlberg', 'Alfie Deyes', 'carolina dieckmann', 'Emilio Lovera', 'Marcelo Adnet', 'Carolina Cruz Osorio', 'Tyler, The Creator', 'YASSER.S.ALQAHTANI', 'Farruko', 'Jack Johnson', 'Aaron Paul', 'Manny Pacquiao', 'Lauren London', 'Ross Lynch', 'David Ospina', 'Jason Segel', 'Wanda Icardi', 'Sidharth Malhotra', 'Rajinikanth', 'Siyovush Dustov', 'Katt Williams', 'Pepe', 'Lady Antebellum', 'Dani Martínez', 'Ferry Yolanda F', 'Mike Vick', 'Marco Reus', 'Al Ghazali Kohler', 'Daniel Bryan', 'Derrick Rose', 'Fabio Coentrao', 'Anthony Padilla', 'Amy Schumer', 'Seu Jorge']\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 30] Read-only file system: '/500perpull.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/Users/richardmacken/codeup-data-science/capstone-project/richard/wrangle_twitter.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 80>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/richardmacken/codeup-data-science/capstone-project/richard/wrangle_twitter.ipynb#W3sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m cols\u001b[39m.\u001b[39minsert(\u001b[39m0\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mhandle\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/richardmacken/codeup-data-science/capstone-project/richard/wrangle_twitter.ipynb#W3sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m dataframe\u001b[39m=\u001b[39mdataframe[cols]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/richardmacken/codeup-data-science/capstone-project/richard/wrangle_twitter.ipynb#W3sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m pd\u001b[39m.\u001b[39;49mto_pickle(dataframe,\u001b[39m\"\u001b[39;49m\u001b[39m/500perpull.pkl\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/io/pickle.py:97\u001b[0m, in \u001b[0;36mto_pickle\u001b[0;34m(obj, filepath_or_buffer, compression, protocol, storage_options)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39mif\u001b[39;00m protocol \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     95\u001b[0m     protocol \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mHIGHEST_PROTOCOL\n\u001b[0;32m---> 97\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[1;32m     98\u001b[0m     filepath_or_buffer,\n\u001b[1;32m     99\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mwb\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    100\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m    101\u001b[0m     is_text\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    102\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    103\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[1;32m    104\u001b[0m     \u001b[39mif\u001b[39;00m handles\u001b[39m.\u001b[39mcompression[\u001b[39m\"\u001b[39m\u001b[39mmethod\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mbz2\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mxz\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m protocol \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m5\u001b[39m:\n\u001b[1;32m    105\u001b[0m         \u001b[39m# some weird TypeError GH#39002 with pickle 5: fallback to letting\u001b[39;00m\n\u001b[1;32m    106\u001b[0m         \u001b[39m# pickle create the entire object and then write it to the buffer.\u001b[39;00m\n\u001b[1;32m    107\u001b[0m         \u001b[39m# \"zip\" would also be here if pandas.io.common._BytesZipFile\u001b[39;00m\n\u001b[1;32m    108\u001b[0m         \u001b[39m# wouldn't buffer write calls\u001b[39;00m\n\u001b[1;32m    109\u001b[0m         handles\u001b[39m.\u001b[39mhandle\u001b[39m.\u001b[39mwrite(pickle\u001b[39m.\u001b[39mdumps(obj, protocol\u001b[39m=\u001b[39mprotocol))\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/io/common.py:798\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    789\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[1;32m    790\u001b[0m             handle,\n\u001b[1;32m    791\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    794\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    795\u001b[0m         )\n\u001b[1;32m    796\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 798\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(handle, ioargs\u001b[39m.\u001b[39;49mmode)\n\u001b[1;32m    799\u001b[0m     handles\u001b[39m.\u001b[39mappend(handle)\n\u001b[1;32m    801\u001b[0m \u001b[39m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: '/500perpull.pkl'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Below are two ways of scraping using CLI commands.\n",
    "## Comment or uncomment as you need. If you currently run the script as is it will scrape both queries\n",
    "## then output two different csv files.\n",
    "#\n",
    "## Query by username\n",
    "## Setting variables to be used in format string command below\n",
    "\n",
    "\n",
    "tweet_count =500 #this number is the last n tweets\n",
    "dflist=[]\n",
    "dfdict={}\n",
    "count=-1*tweet_count\n",
    "celeblen=len(celebs.get('twitter').keys())\n",
    "numindex=list(range(0,tweet_count*celeblen))\n",
    "len(numindex)\n",
    "\n",
    "\n",
    "dictcount=0\n",
    "errornames=[]\n",
    "\n",
    "\n",
    "for c in range(0,celeblen):\n",
    "    sleep(random.randrange(0,7)/10)\n",
    "    dictcount+=1\n",
    "    count=count+tweet_count\n",
    "    maxnum=count+tweet_count\n",
    "\n",
    "    twitter_handle=str(celebs.get('twitter')[c])\n",
    "    name=str(celebs.get('name')[c])\n",
    "    \n",
    "    cur=numindex[count:maxnum]\n",
    "   \n",
    "    #create Series to append the current handle to the dataframe\n",
    "    handleseries={i:twitter_handle for i in cur}       \n",
    "    #create Series to append the current name to dataframe   \n",
    "    nameseries={i:name for i in cur}\n",
    "  \n",
    "\n",
    "  \n",
    "    try:\n",
    "        # Using OS library to call CLI commands in Python\n",
    "        os.system(\"snscrape --jsonl --max-results {} twitter-search 'from:{}'> user-tweets.json\".format(tweet_count, twitter_handle))\n",
    "\n",
    "         # Reads the json generated from the CLI command above and creates a pandas dataframe\n",
    "         #if there is an error then it will just move to the next  \n",
    "        tweets_df1 = pd.read_json('user-tweets.json', lines=True).set_index(keys=pd.Index(cur)).to_dict()\n",
    "    \n",
    "        if dictcount==1:\n",
    "            tweets_df1.update({'name':nameseries})\n",
    "            tweets_df1.update({'handle':handleseries})\n",
    "            dfdict={**dfdict,**tweets_df1}\n",
    "        else:\n",
    "            for key in dfdict.keys():\n",
    "                tweets_df1.update({'name':nameseries})\n",
    "                tweets_df1.update({'handle':handleseries})\n",
    "                a=tweets_df1.get(key)\n",
    "                b=dfdict.get(key)\n",
    "                c={**a,**b}\n",
    "                dfdict.update({key:c})\n",
    "    except:\n",
    "        errornames.append(name)\n",
    "        print(errornames)\n",
    "        pass\n",
    "            \n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "   \n",
    "    \n",
    "\n",
    "\n",
    "dataframe=pd.DataFrame(dfdict).sort_index()\n",
    "cols=list(set(dataframe.columns)-{'name','handle'})\n",
    "cols.insert(0,'name')\n",
    "cols.insert(0,'handle')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>handle</th>\n",
       "      <th>name</th>\n",
       "      <th>content</th>\n",
       "      <th>url</th>\n",
       "      <th>_type</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>quoteCount</th>\n",
       "      <th>outlinks</th>\n",
       "      <th>quotedTweet</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>...</th>\n",
       "      <th>cashtags</th>\n",
       "      <th>user</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>renderedContent</th>\n",
       "      <th>place</th>\n",
       "      <th>tcooutlinks</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>lang</th>\n",
       "      <th>inReplyToTweetId</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>katyperry</td>\n",
       "      <td>KATY PERRY</td>\n",
       "      <td>Vote #YesOn28 Arts and Music in Schools betwee...</td>\n",
       "      <td>https://twitter.com/katyperry/status/158861991...</td>\n",
       "      <td>snscrape.modules.twitter.Tweet</td>\n",
       "      <td>1627</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'_type': 'snscrape.modules.twitter.User', 'us...</td>\n",
       "      <td>153</td>\n",
       "      <td>Vote #YesOn28 Arts and Music in Schools betwee...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>1.588620e+18</td>\n",
       "      <td>2022-11-04 19:51:17+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>katyperry</td>\n",
       "      <td>KATY PERRY</td>\n",
       "      <td>I believe the arts open children’s minds + pro...</td>\n",
       "      <td>https://twitter.com/katyperry/status/158861985...</td>\n",
       "      <td>snscrape.modules.twitter.Tweet</td>\n",
       "      <td>1926</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'_type': 'snscrape.modules.twitter.User', 'us...</td>\n",
       "      <td>179</td>\n",
       "      <td>I believe the arts open children’s minds + pro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>1.588620e+18</td>\n",
       "      <td>2022-11-04 19:51:04+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>katyperry</td>\n",
       "      <td>KATY PERRY</td>\n",
       "      <td>Music helped open my narrow perspective on lif...</td>\n",
       "      <td>https://twitter.com/katyperry/status/158861950...</td>\n",
       "      <td>snscrape.modules.twitter.Tweet</td>\n",
       "      <td>4551</td>\n",
       "      <td>44</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>203</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'_type': 'snscrape.modules.twitter.User', 'us...</td>\n",
       "      <td>487</td>\n",
       "      <td>Music helped open my narrow perspective on lif...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-04 19:49:40+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>katyperry</td>\n",
       "      <td>KATY PERRY</td>\n",
       "      <td>I answer all the hard hitting questions from m...</td>\n",
       "      <td>https://twitter.com/katyperry/status/158818728...</td>\n",
       "      <td>snscrape.modules.twitter.Tweet</td>\n",
       "      <td>4496</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>199</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'_type': 'snscrape.modules.twitter.User', 'us...</td>\n",
       "      <td>686</td>\n",
       "      <td>I answer all the hard hitting questions from m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-03 15:12:10+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>katyperry</td>\n",
       "      <td>KATY PERRY</td>\n",
       "      <td>Going back to Nashville WHERE WE STARTED 🤠 Tun...</td>\n",
       "      <td>https://twitter.com/katyperry/status/158791151...</td>\n",
       "      <td>snscrape.modules.twitter.Tweet</td>\n",
       "      <td>5468</td>\n",
       "      <td>46</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>240</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'_type': 'snscrape.modules.twitter.User', 'us...</td>\n",
       "      <td>778</td>\n",
       "      <td>Going back to Nashville WHERE WE STARTED 🤠 Tun...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-02 20:56:20+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497395</th>\n",
       "      <td>manugavassi</td>\n",
       "      <td>Manu Gavassi</td>\n",
       "      <td>Slow down, you’re doing fine ❤️</td>\n",
       "      <td>https://twitter.com/manugavassi/status/1311162...</td>\n",
       "      <td>snscrape.modules.twitter.Tweet</td>\n",
       "      <td>13170</td>\n",
       "      <td>287</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1218</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'_type': 'snscrape.modules.twitter.User', 'us...</td>\n",
       "      <td>1225</td>\n",
       "      <td>Slow down, you’re doing fine ❤️</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-09-30 04:33:31+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497432</th>\n",
       "      <td>manugavassi</td>\n",
       "      <td>Manu Gavassi</td>\n",
       "      <td>Mood. https://t.co/ASPcyoRTbG</td>\n",
       "      <td>https://twitter.com/manugavassi/status/1301376...</td>\n",
       "      <td>snscrape.modules.twitter.Tweet</td>\n",
       "      <td>5515</td>\n",
       "      <td>5</td>\n",
       "      <td>[https://twitter.com/firstrenegxde/status/1301...</td>\n",
       "      <td>{'_type': 'snscrape.modules.twitter.Tweet', 'u...</td>\n",
       "      <td>413</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'_type': 'snscrape.modules.twitter.User', 'us...</td>\n",
       "      <td>297</td>\n",
       "      <td>Mood. twitter.com/firstrenegxde/…</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[https://t.co/ASPcyoRTbG]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-09-03 04:26:57+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497481</th>\n",
       "      <td>manugavassi</td>\n",
       "      <td>Manu Gavassi</td>\n",
       "      <td>Fiz o big brother. 😯 https://t.co/Y2Vw9whMBu</td>\n",
       "      <td>https://twitter.com/manugavassi/status/1293204...</td>\n",
       "      <td>snscrape.modules.twitter.Tweet</td>\n",
       "      <td>2171</td>\n",
       "      <td>5</td>\n",
       "      <td>[https://twitter.com/thabienoff/status/1293203...</td>\n",
       "      <td>{'_type': 'snscrape.modules.twitter.Tweet', 'u...</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'_type': 'snscrape.modules.twitter.User', 'us...</td>\n",
       "      <td>82</td>\n",
       "      <td>Fiz o big brother. 😯 twitter.com/thabienoff/sta…</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[https://t.co/Y2Vw9whMBu]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-11 15:14:47+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497487</th>\n",
       "      <td>manugavassi</td>\n",
       "      <td>Manu Gavassi</td>\n",
       "      <td>Save the cat !!!!!!! https://t.co/tQug1gSCuC</td>\n",
       "      <td>https://twitter.com/manugavassi/status/1293203...</td>\n",
       "      <td>snscrape.modules.twitter.Tweet</td>\n",
       "      <td>1386</td>\n",
       "      <td>3</td>\n",
       "      <td>[https://twitter.com/ManuBlackStar/status/1293...</td>\n",
       "      <td>{'_type': 'snscrape.modules.twitter.Tweet', 'u...</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'_type': 'snscrape.modules.twitter.User', 'us...</td>\n",
       "      <td>64</td>\n",
       "      <td>Save the cat !!!!!!! twitter.com/ManuBlackStar/…</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[https://t.co/tQug1gSCuC]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-11 15:11:07+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497493</th>\n",
       "      <td>manugavassi</td>\n",
       "      <td>Manu Gavassi</td>\n",
       "      <td>Plot twist. https://t.co/JXZBE2uKIx</td>\n",
       "      <td>https://twitter.com/manugavassi/status/1293202...</td>\n",
       "      <td>snscrape.modules.twitter.Tweet</td>\n",
       "      <td>2708</td>\n",
       "      <td>6</td>\n",
       "      <td>[https://twitter.com/cabmms/status/12931885185...</td>\n",
       "      <td>{'_type': 'snscrape.modules.twitter.Tweet', 'u...</td>\n",
       "      <td>93</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'_type': 'snscrape.modules.twitter.User', 'us...</td>\n",
       "      <td>76</td>\n",
       "      <td>Plot twist. twitter.com/cabmms/status/…</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[https://t.co/JXZBE2uKIx]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-11 15:06:46+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246412 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             handle          name  \\\n",
       "0         katyperry    KATY PERRY   \n",
       "1         katyperry    KATY PERRY   \n",
       "2         katyperry    KATY PERRY   \n",
       "3         katyperry    KATY PERRY   \n",
       "4         katyperry    KATY PERRY   \n",
       "...             ...           ...   \n",
       "497395  manugavassi  Manu Gavassi   \n",
       "497432  manugavassi  Manu Gavassi   \n",
       "497481  manugavassi  Manu Gavassi   \n",
       "497487  manugavassi  Manu Gavassi   \n",
       "497493  manugavassi  Manu Gavassi   \n",
       "\n",
       "                                                  content  \\\n",
       "0       Vote #YesOn28 Arts and Music in Schools betwee...   \n",
       "1       I believe the arts open children’s minds + pro...   \n",
       "2       Music helped open my narrow perspective on lif...   \n",
       "3       I answer all the hard hitting questions from m...   \n",
       "4       Going back to Nashville WHERE WE STARTED 🤠 Tun...   \n",
       "...                                                   ...   \n",
       "497395                    Slow down, you’re doing fine ❤️   \n",
       "497432                      Mood. https://t.co/ASPcyoRTbG   \n",
       "497481       Fiz o big brother. 😯 https://t.co/Y2Vw9whMBu   \n",
       "497487       Save the cat !!!!!!! https://t.co/tQug1gSCuC   \n",
       "497493                Plot twist. https://t.co/JXZBE2uKIx   \n",
       "\n",
       "                                                      url  \\\n",
       "0       https://twitter.com/katyperry/status/158861991...   \n",
       "1       https://twitter.com/katyperry/status/158861985...   \n",
       "2       https://twitter.com/katyperry/status/158861950...   \n",
       "3       https://twitter.com/katyperry/status/158818728...   \n",
       "4       https://twitter.com/katyperry/status/158791151...   \n",
       "...                                                   ...   \n",
       "497395  https://twitter.com/manugavassi/status/1311162...   \n",
       "497432  https://twitter.com/manugavassi/status/1301376...   \n",
       "497481  https://twitter.com/manugavassi/status/1293204...   \n",
       "497487  https://twitter.com/manugavassi/status/1293203...   \n",
       "497493  https://twitter.com/manugavassi/status/1293202...   \n",
       "\n",
       "                                 _type  likeCount  quoteCount  \\\n",
       "0       snscrape.modules.twitter.Tweet       1627           5   \n",
       "1       snscrape.modules.twitter.Tweet       1926           4   \n",
       "2       snscrape.modules.twitter.Tweet       4551          44   \n",
       "3       snscrape.modules.twitter.Tweet       4496          32   \n",
       "4       snscrape.modules.twitter.Tweet       5468          46   \n",
       "...                                ...        ...         ...   \n",
       "497395  snscrape.modules.twitter.Tweet      13170         287   \n",
       "497432  snscrape.modules.twitter.Tweet       5515           5   \n",
       "497481  snscrape.modules.twitter.Tweet       2171           5   \n",
       "497487  snscrape.modules.twitter.Tweet       1386           3   \n",
       "497493  snscrape.modules.twitter.Tweet       2708           6   \n",
       "\n",
       "                                                 outlinks  \\\n",
       "0                                                    None   \n",
       "1                                                    None   \n",
       "2                                                    None   \n",
       "3                                                    None   \n",
       "4                                                    None   \n",
       "...                                                   ...   \n",
       "497395                                               None   \n",
       "497432  [https://twitter.com/firstrenegxde/status/1301...   \n",
       "497481  [https://twitter.com/thabienoff/status/1293203...   \n",
       "497487  [https://twitter.com/ManuBlackStar/status/1293...   \n",
       "497493  [https://twitter.com/cabmms/status/12931885185...   \n",
       "\n",
       "                                              quotedTweet  replyCount  ...  \\\n",
       "0                                                    None          41  ...   \n",
       "1                                                    None          31  ...   \n",
       "2                                                    None         203  ...   \n",
       "3                                                    None         199  ...   \n",
       "4                                                    None         240  ...   \n",
       "...                                                   ...         ...  ...   \n",
       "497395                                               None        1218  ...   \n",
       "497432  {'_type': 'snscrape.modules.twitter.Tweet', 'u...         413  ...   \n",
       "497481  {'_type': 'snscrape.modules.twitter.Tweet', 'u...          63  ...   \n",
       "497487  {'_type': 'snscrape.modules.twitter.Tweet', 'u...          42  ...   \n",
       "497493  {'_type': 'snscrape.modules.twitter.Tweet', 'u...          93  ...   \n",
       "\n",
       "        cashtags                                               user  \\\n",
       "0            NaN  {'_type': 'snscrape.modules.twitter.User', 'us...   \n",
       "1            NaN  {'_type': 'snscrape.modules.twitter.User', 'us...   \n",
       "2            NaN  {'_type': 'snscrape.modules.twitter.User', 'us...   \n",
       "3            NaN  {'_type': 'snscrape.modules.twitter.User', 'us...   \n",
       "4            NaN  {'_type': 'snscrape.modules.twitter.User', 'us...   \n",
       "...          ...                                                ...   \n",
       "497395       NaN  {'_type': 'snscrape.modules.twitter.User', 'us...   \n",
       "497432       NaN  {'_type': 'snscrape.modules.twitter.User', 'us...   \n",
       "497481       NaN  {'_type': 'snscrape.modules.twitter.User', 'us...   \n",
       "497487       NaN  {'_type': 'snscrape.modules.twitter.User', 'us...   \n",
       "497493       NaN  {'_type': 'snscrape.modules.twitter.User', 'us...   \n",
       "\n",
       "       retweetCount                                    renderedContent  place  \\\n",
       "0               153  Vote #YesOn28 Arts and Music in Schools betwee...    NaN   \n",
       "1               179  I believe the arts open children’s minds + pro...    NaN   \n",
       "2               487  Music helped open my narrow perspective on lif...    NaN   \n",
       "3               686  I answer all the hard hitting questions from m...    NaN   \n",
       "4               778  Going back to Nashville WHERE WE STARTED 🤠 Tun...    NaN   \n",
       "...             ...                                                ...    ...   \n",
       "497395         1225                    Slow down, you’re doing fine ❤️    NaN   \n",
       "497432          297                  Mood. twitter.com/firstrenegxde/…    NaN   \n",
       "497481           82   Fiz o big brother. 😯 twitter.com/thabienoff/sta…    NaN   \n",
       "497487           64   Save the cat !!!!!!! twitter.com/ManuBlackStar/…    NaN   \n",
       "497493           76            Plot twist. twitter.com/cabmms/status/…    NaN   \n",
       "\n",
       "                      tcooutlinks  coordinates lang inReplyToTweetId  \\\n",
       "0                            None          NaN   en     1.588620e+18   \n",
       "1                            None          NaN   en     1.588620e+18   \n",
       "2                            None          NaN   en              NaN   \n",
       "3                            None          NaN   en              NaN   \n",
       "4                            None          NaN   en              NaN   \n",
       "...                           ...          ...  ...              ...   \n",
       "497395                       None          NaN   en              NaN   \n",
       "497432  [https://t.co/ASPcyoRTbG]          NaN   en              NaN   \n",
       "497481  [https://t.co/Y2Vw9whMBu]          NaN   en              NaN   \n",
       "497487  [https://t.co/tQug1gSCuC]          NaN   en              NaN   \n",
       "497493  [https://t.co/JXZBE2uKIx]          NaN   en              NaN   \n",
       "\n",
       "                            date  \n",
       "0      2022-11-04 19:51:17+00:00  \n",
       "1      2022-11-04 19:51:04+00:00  \n",
       "2      2022-11-04 19:49:40+00:00  \n",
       "3      2022-11-03 15:12:10+00:00  \n",
       "4      2022-11-02 20:56:20+00:00  \n",
       "...                          ...  \n",
       "497395 2020-09-30 04:33:31+00:00  \n",
       "497432 2020-09-03 04:26:57+00:00  \n",
       "497481 2020-08-11 15:14:47+00:00  \n",
       "497487 2020-08-11 15:11:07+00:00  \n",
       "497493 2020-08-11 15:06:46+00:00  \n",
       "\n",
       "[246412 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataframe=dataframe[dataframe.lang=='en']\n",
    "\n",
    "dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pd.to_pickle(dataframe,\"500perpull.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warning you need to uncomment above to scrape and create the pickle. \n",
    "\n",
    "## Your speed my vary but it took 45 mins for the scrape\n",
    "\n",
    "## The code below directly below is to the big scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from the pickle and then display the unique file\n",
    "\n",
    "dataframe_a=pd.read_pickle(\"./fivezerominpull.pkl\")\n",
    "dataframe_b=pd.read_pickle(\"500perpull.pkl\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50762"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "246412"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "297174"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataframe_a=dataframe_a[dataframe_a.lang=='en']\n",
    "display(len(dataframe_a))\n",
    "display(len(dataframe_b))\n",
    "merged=pd.concat([dataframe_a,dataframe_b])\n",
    "display(len(merged))\n",
    "merged.name=merged.name.str.lower()\n",
    "dataframe=merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>handle</th>\n",
       "      <th>name</th>\n",
       "      <th>content</th>\n",
       "      <th>quotedTweet</th>\n",
       "      <th>outlinks</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>sourceLabel</th>\n",
       "      <th>sourceUrl</th>\n",
       "      <th>tcooutlinks</th>\n",
       "      <th>...</th>\n",
       "      <th>mentionedUsers</th>\n",
       "      <th>quoteCount</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>id</th>\n",
       "      <th>cashtags</th>\n",
       "      <th>inReplyToTweetId</th>\n",
       "      <th>user</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>renderedContent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>katyperry</td>\n",
       "      <td>katy perry</td>\n",
       "      <td>if you wanna know why any human is they way th...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4575</td>\n",
       "      <td>None</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>http://twitter.com/download/iphone</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1210</td>\n",
       "      <td>1586844179363250176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'_type': 'snscrape.modules.twitter.User', 'us...</td>\n",
       "      <td>29840</td>\n",
       "      <td>if you wanna know why any human is they way th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>katyperry</td>\n",
       "      <td>katy perry</td>\n",
       "      <td>wait, if it’s called a “feed” are we literally...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>881</td>\n",
       "      <td>None</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>http://twitter.com/download/iphone</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>179</td>\n",
       "      <td>NaN</td>\n",
       "      <td>603</td>\n",
       "      <td>1586251933479739393</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'_type': 'snscrape.modules.twitter.User', 'us...</td>\n",
       "      <td>10502</td>\n",
       "      <td>wait, if it’s called a “feed” are we literally...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>katyperry</td>\n",
       "      <td>katy perry</td>\n",
       "      <td>heck I pour beer out of my tits (that’s a part...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>297</td>\n",
       "      <td>[chainedtothealgorithm, therealproblemlolhaha]</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>http://twitter.com/download/iphone</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>1585709853367930881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.585710e+18</td>\n",
       "      <td>{'_type': 'snscrape.modules.twitter.User', 'us...</td>\n",
       "      <td>3042</td>\n",
       "      <td>heck I pour beer out of my tits (that’s a part...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>katyperry</td>\n",
       "      <td>katy perry</td>\n",
       "      <td>The show’s set list is a fun 🎢  through memory...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>336</td>\n",
       "      <td>None</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>http://twitter.com/download/iphone</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69</td>\n",
       "      <td>1585709755779072000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.585709e+18</td>\n",
       "      <td>{'_type': 'snscrape.modules.twitter.User', 'us...</td>\n",
       "      <td>3654</td>\n",
       "      <td>The show’s set list is a fun 🎢  through memory...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>katyperry</td>\n",
       "      <td>katy perry</td>\n",
       "      <td>Welcoming all my #flatearthers #spaceisfakers ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[http://axs.com/katyinvegas]</td>\n",
       "      <td>2318</td>\n",
       "      <td>[flatearthers, spaceisfakers, birdsarentrealer...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>http://twitter.com/download/iphone</td>\n",
       "      <td>[https://t.co/eux5dOL6Ve]</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>839</td>\n",
       "      <td>1585709277305372673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'_type': 'snscrape.modules.twitter.User', 'us...</td>\n",
       "      <td>20819</td>\n",
       "      <td>Welcoming all my #flatearthers #spaceisfakers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497395</th>\n",
       "      <td>manugavassi</td>\n",
       "      <td>manu gavassi</td>\n",
       "      <td>Slow down, you’re doing fine ❤️</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1225</td>\n",
       "      <td>None</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>https://mobile.twitter.com</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>287</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1218</td>\n",
       "      <td>1311162235369205760</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'_type': 'snscrape.modules.twitter.User', 'us...</td>\n",
       "      <td>13170</td>\n",
       "      <td>Slow down, you’re doing fine ❤️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497432</th>\n",
       "      <td>manugavassi</td>\n",
       "      <td>manu gavassi</td>\n",
       "      <td>Mood. https://t.co/ASPcyoRTbG</td>\n",
       "      <td>{'_type': 'snscrape.modules.twitter.Tweet', 'u...</td>\n",
       "      <td>[https://twitter.com/firstrenegxde/status/1301...</td>\n",
       "      <td>297</td>\n",
       "      <td>None</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>https://mobile.twitter.com</td>\n",
       "      <td>[https://t.co/ASPcyoRTbG]</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>413</td>\n",
       "      <td>1301376109578256384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'_type': 'snscrape.modules.twitter.User', 'us...</td>\n",
       "      <td>5515</td>\n",
       "      <td>Mood. twitter.com/firstrenegxde/…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497481</th>\n",
       "      <td>manugavassi</td>\n",
       "      <td>manu gavassi</td>\n",
       "      <td>Fiz o big brother. 😯 https://t.co/Y2Vw9whMBu</td>\n",
       "      <td>{'_type': 'snscrape.modules.twitter.Tweet', 'u...</td>\n",
       "      <td>[https://twitter.com/thabienoff/status/1293203...</td>\n",
       "      <td>82</td>\n",
       "      <td>None</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>https://mobile.twitter.com</td>\n",
       "      <td>[https://t.co/Y2Vw9whMBu]</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63</td>\n",
       "      <td>1293204218925514752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'_type': 'snscrape.modules.twitter.User', 'us...</td>\n",
       "      <td>2171</td>\n",
       "      <td>Fiz o big brother. 😯 twitter.com/thabienoff/sta…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497487</th>\n",
       "      <td>manugavassi</td>\n",
       "      <td>manu gavassi</td>\n",
       "      <td>Save the cat !!!!!!! https://t.co/tQug1gSCuC</td>\n",
       "      <td>{'_type': 'snscrape.modules.twitter.Tweet', 'u...</td>\n",
       "      <td>[https://twitter.com/ManuBlackStar/status/1293...</td>\n",
       "      <td>64</td>\n",
       "      <td>None</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>https://mobile.twitter.com</td>\n",
       "      <td>[https://t.co/tQug1gSCuC]</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>1293203299437555716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'_type': 'snscrape.modules.twitter.User', 'us...</td>\n",
       "      <td>1386</td>\n",
       "      <td>Save the cat !!!!!!! twitter.com/ManuBlackStar/…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497493</th>\n",
       "      <td>manugavassi</td>\n",
       "      <td>manu gavassi</td>\n",
       "      <td>Plot twist. https://t.co/JXZBE2uKIx</td>\n",
       "      <td>{'_type': 'snscrape.modules.twitter.Tweet', 'u...</td>\n",
       "      <td>[https://twitter.com/cabmms/status/12931885185...</td>\n",
       "      <td>76</td>\n",
       "      <td>None</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>https://mobile.twitter.com</td>\n",
       "      <td>[https://t.co/JXZBE2uKIx]</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93</td>\n",
       "      <td>1293202205349208064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'_type': 'snscrape.modules.twitter.User', 'us...</td>\n",
       "      <td>2708</td>\n",
       "      <td>Plot twist. twitter.com/cabmms/status/…</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297174 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             handle          name  \\\n",
       "0         katyperry    katy perry   \n",
       "1         katyperry    katy perry   \n",
       "3         katyperry    katy perry   \n",
       "4         katyperry    katy perry   \n",
       "5         katyperry    katy perry   \n",
       "...             ...           ...   \n",
       "497395  manugavassi  manu gavassi   \n",
       "497432  manugavassi  manu gavassi   \n",
       "497481  manugavassi  manu gavassi   \n",
       "497487  manugavassi  manu gavassi   \n",
       "497493  manugavassi  manu gavassi   \n",
       "\n",
       "                                                  content  \\\n",
       "0       if you wanna know why any human is they way th...   \n",
       "1       wait, if it’s called a “feed” are we literally...   \n",
       "3       heck I pour beer out of my tits (that’s a part...   \n",
       "4       The show’s set list is a fun 🎢  through memory...   \n",
       "5       Welcoming all my #flatearthers #spaceisfakers ...   \n",
       "...                                                   ...   \n",
       "497395                    Slow down, you’re doing fine ❤️   \n",
       "497432                      Mood. https://t.co/ASPcyoRTbG   \n",
       "497481       Fiz o big brother. 😯 https://t.co/Y2Vw9whMBu   \n",
       "497487       Save the cat !!!!!!! https://t.co/tQug1gSCuC   \n",
       "497493                Plot twist. https://t.co/JXZBE2uKIx   \n",
       "\n",
       "                                              quotedTweet  \\\n",
       "0                                                    None   \n",
       "1                                                    None   \n",
       "3                                                    None   \n",
       "4                                                    None   \n",
       "5                                                    None   \n",
       "...                                                   ...   \n",
       "497395                                               None   \n",
       "497432  {'_type': 'snscrape.modules.twitter.Tweet', 'u...   \n",
       "497481  {'_type': 'snscrape.modules.twitter.Tweet', 'u...   \n",
       "497487  {'_type': 'snscrape.modules.twitter.Tweet', 'u...   \n",
       "497493  {'_type': 'snscrape.modules.twitter.Tweet', 'u...   \n",
       "\n",
       "                                                 outlinks  retweetCount  \\\n",
       "0                                                    None          4575   \n",
       "1                                                    None           881   \n",
       "3                                                    None           297   \n",
       "4                                                    None           336   \n",
       "5                            [http://axs.com/katyinvegas]          2318   \n",
       "...                                                   ...           ...   \n",
       "497395                                               None          1225   \n",
       "497432  [https://twitter.com/firstrenegxde/status/1301...           297   \n",
       "497481  [https://twitter.com/thabienoff/status/1293203...            82   \n",
       "497487  [https://twitter.com/ManuBlackStar/status/1293...            64   \n",
       "497493  [https://twitter.com/cabmms/status/12931885185...            76   \n",
       "\n",
       "                                                 hashtags         sourceLabel  \\\n",
       "0                                                    None  Twitter for iPhone   \n",
       "1                                                    None  Twitter for iPhone   \n",
       "3          [chainedtothealgorithm, therealproblemlolhaha]  Twitter for iPhone   \n",
       "4                                                    None  Twitter for iPhone   \n",
       "5       [flatearthers, spaceisfakers, birdsarentrealer...  Twitter for iPhone   \n",
       "...                                                   ...                 ...   \n",
       "497395                                               None     Twitter Web App   \n",
       "497432                                               None     Twitter Web App   \n",
       "497481                                               None     Twitter Web App   \n",
       "497487                                               None     Twitter Web App   \n",
       "497493                                               None     Twitter Web App   \n",
       "\n",
       "                                 sourceUrl                tcooutlinks  ...  \\\n",
       "0       http://twitter.com/download/iphone                       None  ...   \n",
       "1       http://twitter.com/download/iphone                       None  ...   \n",
       "3       http://twitter.com/download/iphone                       None  ...   \n",
       "4       http://twitter.com/download/iphone                       None  ...   \n",
       "5       http://twitter.com/download/iphone  [https://t.co/eux5dOL6Ve]  ...   \n",
       "...                                    ...                        ...  ...   \n",
       "497395          https://mobile.twitter.com                       None  ...   \n",
       "497432          https://mobile.twitter.com  [https://t.co/ASPcyoRTbG]  ...   \n",
       "497481          https://mobile.twitter.com  [https://t.co/Y2Vw9whMBu]  ...   \n",
       "497487          https://mobile.twitter.com  [https://t.co/tQug1gSCuC]  ...   \n",
       "497493          https://mobile.twitter.com  [https://t.co/JXZBE2uKIx]  ...   \n",
       "\n",
       "       mentionedUsers  quoteCount coordinates replyCount                   id  \\\n",
       "0                None         623         NaN       1210  1586844179363250176   \n",
       "1                None         179         NaN        603  1586251933479739393   \n",
       "3                None          34         NaN        100  1585709853367930881   \n",
       "4                None          17         NaN         69  1585709755779072000   \n",
       "5                None         630         NaN        839  1585709277305372673   \n",
       "...               ...         ...         ...        ...                  ...   \n",
       "497395           None         287         NaN       1218  1311162235369205760   \n",
       "497432           None           5         NaN        413  1301376109578256384   \n",
       "497481           None           5         NaN         63  1293204218925514752   \n",
       "497487           None           3         NaN         42  1293203299437555716   \n",
       "497493           None           6         NaN         93  1293202205349208064   \n",
       "\n",
       "       cashtags  inReplyToTweetId  \\\n",
       "0           NaN               NaN   \n",
       "1           NaN               NaN   \n",
       "3           NaN      1.585710e+18   \n",
       "4           NaN      1.585709e+18   \n",
       "5           NaN               NaN   \n",
       "...         ...               ...   \n",
       "497395      NaN               NaN   \n",
       "497432      NaN               NaN   \n",
       "497481      NaN               NaN   \n",
       "497487      NaN               NaN   \n",
       "497493      NaN               NaN   \n",
       "\n",
       "                                                     user likeCount  \\\n",
       "0       {'_type': 'snscrape.modules.twitter.User', 'us...     29840   \n",
       "1       {'_type': 'snscrape.modules.twitter.User', 'us...     10502   \n",
       "3       {'_type': 'snscrape.modules.twitter.User', 'us...      3042   \n",
       "4       {'_type': 'snscrape.modules.twitter.User', 'us...      3654   \n",
       "5       {'_type': 'snscrape.modules.twitter.User', 'us...     20819   \n",
       "...                                                   ...       ...   \n",
       "497395  {'_type': 'snscrape.modules.twitter.User', 'us...     13170   \n",
       "497432  {'_type': 'snscrape.modules.twitter.User', 'us...      5515   \n",
       "497481  {'_type': 'snscrape.modules.twitter.User', 'us...      2171   \n",
       "497487  {'_type': 'snscrape.modules.twitter.User', 'us...      1386   \n",
       "497493  {'_type': 'snscrape.modules.twitter.User', 'us...      2708   \n",
       "\n",
       "                                          renderedContent  \n",
       "0       if you wanna know why any human is they way th...  \n",
       "1       wait, if it’s called a “feed” are we literally...  \n",
       "3       heck I pour beer out of my tits (that’s a part...  \n",
       "4       The show’s set list is a fun 🎢  through memory...  \n",
       "5       Welcoming all my #flatearthers #spaceisfakers ...  \n",
       "...                                                   ...  \n",
       "497395                    Slow down, you’re doing fine ❤️  \n",
       "497432                  Mood. twitter.com/firstrenegxde/…  \n",
       "497481   Fiz o big brother. 😯 twitter.com/thabienoff/sta…  \n",
       "497487   Save the cat !!!!!!! twitter.com/ManuBlackStar/…  \n",
       "497493            Plot twist. twitter.com/cabmms/status/…  \n",
       "\n",
       "[297174 rows x 30 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptypeurl='https://raw.githubusercontent.com/twitter-personality-predictor/twitter-personality-predictor/main/twitter_handles.csv'\n",
    "\n",
    "ptypes=pd.read_csv(ptypeurl);ptypes\n",
    "newcols=[]\n",
    "for x in ptypes.columns.to_list():\n",
    "    y=x.lower()\n",
    "    newcols.append(y)\n",
    "\n",
    "ptypes.columns=newcols\n",
    "ptypes['handle']=ptypes.twitter\n",
    "ptypes.drop(columns='twitter',inplace=True)\n",
    "ptypes.name=ptypes.name.str.lower();ptypes\n",
    "\n",
    "dataframe.name=dataframe.name.str.lower();dataframe\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Twitter for iPhone             182809\n",
       "Twitter Web App                 40047\n",
       "Instagram                       21757\n",
       "Twitter Web Client              11279\n",
       "Twitter for Android              9750\n",
       "                                ...  \n",
       "Triller - Music Video Maker         1\n",
       "Global Citizen Mobile App           1\n",
       "Safari on iOS                       1\n",
       "TweetList!                          1\n",
       "NationBuilder                       1\n",
       "Name: sourceLabel, Length: 139, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.sourceLabel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tc/rqcbqynd6g96v17vbqppznm40000gn/T/ipykernel_87349/3421587410.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.dropna(axis=0,inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>583</th>\n",
       "      <th>584</th>\n",
       "      <th>585</th>\n",
       "      <th>586</th>\n",
       "      <th>587</th>\n",
       "      <th>588</th>\n",
       "      <th>589</th>\n",
       "      <th>590</th>\n",
       "      <th>591</th>\n",
       "      <th>592</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>katy perry</td>\n",
       "      <td>justin bieber</td>\n",
       "      <td>taylor swift</td>\n",
       "      <td>rihanna</td>\n",
       "      <td>the countess</td>\n",
       "      <td>justin timberlake</td>\n",
       "      <td>ellen degeneres</td>\n",
       "      <td>britney spears</td>\n",
       "      <td>cristiano ronaldo</td>\n",
       "      <td>kim kardashian west</td>\n",
       "      <td>...</td>\n",
       "      <td>tito el bambino</td>\n",
       "      <td>eser yenenler</td>\n",
       "      <td>sertab erener</td>\n",
       "      <td>andreu buenafuente</td>\n",
       "      <td>nicolas vazquez</td>\n",
       "      <td>cyril hanouna</td>\n",
       "      <td>sebastian rulli</td>\n",
       "      <td>carlos baute</td>\n",
       "      <td>adal ramones</td>\n",
       "      <td>manu gavassi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 593 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0              1             2        3             4    \\\n",
       "0  katy perry  justin bieber  taylor swift  rihanna  the countess   \n",
       "\n",
       "                 5                6               7                  8    \\\n",
       "0  justin timberlake  ellen degeneres  britney spears  cristiano ronaldo   \n",
       "\n",
       "                   9    ...              583            584            585  \\\n",
       "0  kim kardashian west  ...  tito el bambino  eser yenenler  sertab erener   \n",
       "\n",
       "                  586              587            588              589  \\\n",
       "0  andreu buenafuente  nicolas vazquez  cyril hanouna  sebastian rulli   \n",
       "\n",
       "            590           591           592  \n",
       "0  carlos baute  adal ramones  manu gavassi  \n",
       "\n",
       "[1 rows x 593 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>type</th>\n",
       "      <th>ENFJ</th>\n",
       "      <th>ENFP</th>\n",
       "      <th>ENTJ</th>\n",
       "      <th>ENTP</th>\n",
       "      <th>ESFJ</th>\n",
       "      <th>ESFP</th>\n",
       "      <th>ESTJ</th>\n",
       "      <th>ESTP</th>\n",
       "      <th>INFJ</th>\n",
       "      <th>INFP</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>INTP</th>\n",
       "      <th>ISFJ</th>\n",
       "      <th>ISFP</th>\n",
       "      <th>ISTJ</th>\n",
       "      <th>ISTP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>37</td>\n",
       "      <td>59</td>\n",
       "      <td>21</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>103</td>\n",
       "      <td>23</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>49</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "type  ENFJ  ENFP  ENTJ  ENTP  ESFJ  ESFP  ESTJ  ESTP  INFJ  INFP  INTJ  INTP  \\\n",
       "name    37    59    21    50    65   103    23    50    25    15    11    11   \n",
       "\n",
       "type  ISFJ  ISFP  ISTJ  ISTP  \n",
       "name    32    49    12    30  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "a=ptypes.name.values.tolist()\n",
    "b=ptypes.type.values.tolist()\n",
    "ptypemap=dict(zip(a,b))\n",
    "ptypemap\n",
    "dataframe.dropna(axis=1,inplace=True)\n",
    "dataframe['type']=dataframe.name.map(ptypemap)\n",
    "\n",
    "\n",
    "\n",
    "cols=list(set(dataframe.columns)-{'name','handle','type'})\n",
    "cols.insert(0,'handle')\n",
    "cols.insert(0,'name')\n",
    "cols.insert(0,'type')\n",
    "\n",
    "dataframe=dataframe[cols]\n",
    "dataframe.dropna(axis=0,inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "display(pd.DataFrame((dataframe['name'].unique()),index=range(0,len(dataframe['name'].unique()))).T)\n",
    "display(dataframe[['type','name']].groupby(['type']).nunique().T)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>handle</th>\n",
       "      <th>content</th>\n",
       "      <th>url</th>\n",
       "      <th>_type</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>quoteCount</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>conversationId</th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>sourceLabel</th>\n",
       "      <th>sourceUrl</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>user</th>\n",
       "      <th>renderedContent</th>\n",
       "      <th>lang</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>type</td>\n",
       "      <td>name</td>\n",
       "      <td>handle</td>\n",
       "      <td>content</td>\n",
       "      <td>url</td>\n",
       "      <td>_type</td>\n",
       "      <td>likeCount</td>\n",
       "      <td>quoteCount</td>\n",
       "      <td>replyCount</td>\n",
       "      <td>conversationId</td>\n",
       "      <td>source</td>\n",
       "      <td>id</td>\n",
       "      <td>sourceLabel</td>\n",
       "      <td>sourceUrl</td>\n",
       "      <td>retweetCount</td>\n",
       "      <td>user</td>\n",
       "      <td>renderedContent</td>\n",
       "      <td>lang</td>\n",
       "      <td>date</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  name  handle  content  url  _type  likeCount  quoteCount  replyCount  \\\n",
       "0  type  name  handle  content  url  _type  likeCount  quoteCount  replyCount   \n",
       "\n",
       "   conversationId  source  id  sourceLabel  sourceUrl  retweetCount  user  \\\n",
       "0  conversationId  source  id  sourceLabel  sourceUrl  retweetCount  user   \n",
       "\n",
       "   renderedContent  lang  date  \n",
       "0  renderedContent  lang  date  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "227746"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "227746"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dataframe.columns.to_frame().T)\n",
    "cols=['type','name','renderedContent','content','handle','date','lang','likeCount','retweetCount']\n",
    "keep=dataframe[cols];display(len(keep))\n",
    "keep=keep[keep['lang']=='en'];display(len(keep))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aquire is done \n",
    "\n",
    "\n",
    "## Prep is below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "group1=keep[['type','name','content']].groupby(by=['type','name'])\n",
    "lista=set(group1.groups.keys())\n",
    "group2=keep[['type','name']].groupby(by=['type'])\n",
    "listb=list(set(group2.groups.keys()))\n",
    "group3=keep[['name','content']].groupby(by=['name'])   \n",
    "indexbyperson={}\n",
    "for b in listb:\n",
    "    g=list(group2.get_group(b).index)\n",
    "    n=list(group2.get_group(b).name.unique())\n",
    "    \n",
    "    ndict={}\n",
    "    for i in n:\n",
    "        k=list(group3.get_group(i).index)\n",
    "        c=list(group3.get_group(i).content)\n",
    "        ndict.update({i:{'index':k,'content':c}})\n",
    "    indexbyperson.update({b:{'index':g,'name':ndict}})\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# namegroups=allthewaydown.groupby('name')\n",
    "# keys=namegroups.groups.keys()\n",
    "# for k in keys:\n",
    "#     print(len(namegroups.get_group(k)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "\n",
    "#pdf plumber\n",
    "#csv.preview\n",
    "import pandas as pd\n",
    "#import unicode character database\n",
    "import unicodedata\n",
    "#import regular expression operations\n",
    "import re\n",
    "\n",
    "#import natural language toolkit\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "#import our aquire\n",
    "\n",
    "\n",
    "#import our stopwords list\n",
    "from nltk.corpus import stopwords\n",
    "from copy import deepcopy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_stopwords = ['like', 'im', 'think', 'dont', 'people', 'know', 'one', 'get', 'really','thing',\n",
    "                  'would', 'time', 'type', 'make', 'friend', 'ive', 'much',\n",
    "                 'say', 'way', 'see', 'thing', 'want', 'thing', 'good', 'something', 'lot',\n",
    "                  'also', 'go', 'always', 'even', 'well', 'someone','https','http','com','co',',',\"'\"]\n",
    "\n",
    "\n",
    "\n",
    "stops=stopwords.words(['french','german','english','spanish','portuguese'])+ more_stopwords\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pd.to_pickle(stops,'stopwords.pkl')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def stopfilter(text,stop_words_extend_reduce=[\"'\"]):\n",
    "    'we use symmetric difference so if a is already in stop words then it will be added to our third set else our third set will be missing it'\n",
    "    #create oujr english stopwords list\n",
    "    stops = set(pd.read_pickle('stopwords.pkl'))\n",
    "\n",
    "   \n",
    "    stop_words_extend_reduce=set(stop_words_extend_reduce)\n",
    "    stops=stops.symmetric_difference(stop_words_extend_reduce)\n",
    "\n",
    "    # stops=(stops|stop_words_extend)-exclude_words\n",
    "    #another way\n",
    "    \n",
    "    filtered=list(filter((lambda x: x not in stops and len(x)>=2), text.split()))\n",
    "    filtered=' '.join(filtered)\n",
    " \n",
    "\n",
    "    return filtered\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def basic_clean(text,regexfilter=r'[^a-z0-9\\'\\s]'):\n",
    "    '''   \n",
    "    Filters out all special characters if you need to edit then supply a new regex filter \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    #make a copy and begin to transform it\n",
    "    newtext = text.lower()\n",
    "\n",
    "    #encode into ascii then decode\n",
    "    newtext = unicodedata.normalize('NFKD', newtext)\\\n",
    "    .encode('ascii', 'ignore')\\\n",
    "    .decode('utf-8')\n",
    "\n",
    "    #use re.sub to remove special characters\n",
    "    newtext = re.sub(fr'{regexfilter}', ' ', newtext)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    return newtext\n",
    "\n",
    "    \n",
    "def lemmatizor(text,regexfilter=r'[^a-z0-9\\'\\s]'):\n",
    "    '''    \n",
    "    \n",
    "      Takes text, tokenizes it, lemmatizes it\n",
    "      lemmafiltered=list(filter(lambda x: (len(x)>1 and len(x)<9 and x.isalpha()==True),  lemmatized.split()))\n",
    "      needs to be commented out after the first run (up to modeling)\n",
    "      # lemmafiltered=list(filter(lambda x: (len(x)>1 and len(x)<9 and x.isalpha()==True and (x in  total)), lemmatized.split()))\n",
    "      needs to be un commented commented\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    total=list(pd.read_pickle('words.pkl'))\n",
    "    \n",
    "\n",
    "    #make ready the lemmatizer object\n",
    "    newtext=tokenizer(text,regexfilter=regexfilter)\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    lemmatized=split_apply_join(wnl.lemmatize,newtext)\n",
    "\n",
    "    # since the average word lenght in English is 4.7 characters we will apply a conservative estimate and drop any word that is larger than 8 characters as it is likely not a word\n",
    "    # we also recursivley took the set of all words generated then compared that to nltk.corpus.words.words() and used that list as filter this is where total comes from\n",
    "\n",
    "    # lemmafiltered=list(filter(lambda x: (len(x)>1 and len(x)<9 and x.isalpha()==True and (x in  total)), lemmatized.split()))\n",
    "\n",
    "    lemmafiltered=list(filter(lambda x: (len(x)>1 and len(x)<9 and x.isalpha()==True),  lemmatized.split()))\n",
    "\n",
    "    lemmafiltered=' '.join(lemmafiltered)\n",
    "  \n",
    "    lemmafiltered=basic_clean(lemmafiltered,regexfilter=regexfilter)\n",
    "\n",
    "    return lemmafiltered\n",
    "    \n",
    "    \n",
    "def split_apply_join(funct,listobj):\n",
    "    'helperfuction letters'\n",
    "\n",
    "    mapped=map(funct, listobj)\n",
    "    mapped=list(mapped)\n",
    "    mapped=''.join(mapped)\n",
    "  \n",
    "    return mapped\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def tokenizer(text,regexfilter=r'[^a-z0-9\\'\\s]'):\n",
    "    ''' \n",
    "    For a large file just save it locally\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    newtext=basic_clean(text,regexfilter=regexfilter)\n",
    "    #make ready tokenizer object\n",
    "    tokenize = nltk.tokenize.ToktokTokenizer()\n",
    "    #use the tokenizer\n",
    "    newtext = tokenize.tokenize(newtext, return_str=True)\n",
    "    return newtext\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tc/rqcbqynd6g96v17vbqppznm40000gn/T/ipykernel_87349/4015161157.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tryagain.type=tryagain.type.str.lower()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>content</th>\n",
       "      <th>handle</th>\n",
       "      <th>date</th>\n",
       "      <th>lang</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>domain</th>\n",
       "      <th>i|e</th>\n",
       "      <th>n|s</th>\n",
       "      <th>t|f</th>\n",
       "      <th>j|p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enfj</td>\n",
       "      <td>katy perry</td>\n",
       "      <td>if you wanna know why any human is they way th...</td>\n",
       "      <td>katyperry</td>\n",
       "      <td>2022-10-30 22:15:09+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>29840</td>\n",
       "      <td>4575</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>enfj</td>\n",
       "      <td>katy perry</td>\n",
       "      <td>wait, if it’s called a “feed” are we literally...</td>\n",
       "      <td>katyperry</td>\n",
       "      <td>2022-10-29 07:01:46+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>10502</td>\n",
       "      <td>881</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enfj</td>\n",
       "      <td>katy perry</td>\n",
       "      <td>heck I pour beer out of my tits (that’s a part...</td>\n",
       "      <td>katyperry</td>\n",
       "      <td>2022-10-27 19:07:44+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>3042</td>\n",
       "      <td>297</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>enfj</td>\n",
       "      <td>katy perry</td>\n",
       "      <td>The show’s set list is a fun 🎢  through memory...</td>\n",
       "      <td>katyperry</td>\n",
       "      <td>2022-10-27 19:07:21+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>3654</td>\n",
       "      <td>336</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>enfj</td>\n",
       "      <td>katy perry</td>\n",
       "      <td>Welcoming all my #flatearthers #spaceisfakers ...</td>\n",
       "      <td>katyperry</td>\n",
       "      <td>2022-10-27 19:05:27+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>20819</td>\n",
       "      <td>2318</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497395</th>\n",
       "      <td>enfp</td>\n",
       "      <td>manu gavassi</td>\n",
       "      <td>Slow down, you’re doing fine ❤️</td>\n",
       "      <td>manugavassi</td>\n",
       "      <td>2020-09-30 04:33:31+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>13170</td>\n",
       "      <td>1225</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497432</th>\n",
       "      <td>enfp</td>\n",
       "      <td>manu gavassi</td>\n",
       "      <td>Mood. twitter.com/firstrenegxde/…</td>\n",
       "      <td>manugavassi</td>\n",
       "      <td>2020-09-03 04:26:57+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>5515</td>\n",
       "      <td>297</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497481</th>\n",
       "      <td>enfp</td>\n",
       "      <td>manu gavassi</td>\n",
       "      <td>Fiz o big brother. 😯 twitter.com/thabienoff/sta…</td>\n",
       "      <td>manugavassi</td>\n",
       "      <td>2020-08-11 15:14:47+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>2171</td>\n",
       "      <td>82</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497487</th>\n",
       "      <td>enfp</td>\n",
       "      <td>manu gavassi</td>\n",
       "      <td>Save the cat !!!!!!! twitter.com/ManuBlackStar/…</td>\n",
       "      <td>manugavassi</td>\n",
       "      <td>2020-08-11 15:11:07+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>1386</td>\n",
       "      <td>64</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497493</th>\n",
       "      <td>enfp</td>\n",
       "      <td>manu gavassi</td>\n",
       "      <td>Plot twist. twitter.com/cabmms/status/…</td>\n",
       "      <td>manugavassi</td>\n",
       "      <td>2020-08-11 15:06:46+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>2708</td>\n",
       "      <td>76</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214613 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        type          name                                            content  \\\n",
       "0       enfj    katy perry  if you wanna know why any human is they way th...   \n",
       "1       enfj    katy perry  wait, if it’s called a “feed” are we literally...   \n",
       "3       enfj    katy perry  heck I pour beer out of my tits (that’s a part...   \n",
       "4       enfj    katy perry  The show’s set list is a fun 🎢  through memory...   \n",
       "5       enfj    katy perry  Welcoming all my #flatearthers #spaceisfakers ...   \n",
       "...      ...           ...                                                ...   \n",
       "497395  enfp  manu gavassi                    Slow down, you’re doing fine ❤️   \n",
       "497432  enfp  manu gavassi                  Mood. twitter.com/firstrenegxde/…   \n",
       "497481  enfp  manu gavassi   Fiz o big brother. 😯 twitter.com/thabienoff/sta…   \n",
       "497487  enfp  manu gavassi   Save the cat !!!!!!! twitter.com/ManuBlackStar/…   \n",
       "497493  enfp  manu gavassi            Plot twist. twitter.com/cabmms/status/…   \n",
       "\n",
       "             handle                      date lang  likeCount  retweetCount  \\\n",
       "0         katyperry 2022-10-30 22:15:09+00:00   en      29840          4575   \n",
       "1         katyperry 2022-10-29 07:01:46+00:00   en      10502           881   \n",
       "3         katyperry 2022-10-27 19:07:44+00:00   en       3042           297   \n",
       "4         katyperry 2022-10-27 19:07:21+00:00   en       3654           336   \n",
       "5         katyperry 2022-10-27 19:05:27+00:00   en      20819          2318   \n",
       "...             ...                       ...  ...        ...           ...   \n",
       "497395  manugavassi 2020-09-30 04:33:31+00:00   en      13170          1225   \n",
       "497432  manugavassi 2020-09-03 04:26:57+00:00   en       5515           297   \n",
       "497481  manugavassi 2020-08-11 15:14:47+00:00   en       2171            82   \n",
       "497487  manugavassi 2020-08-11 15:11:07+00:00   en       1386            64   \n",
       "497493  manugavassi 2020-08-11 15:06:46+00:00   en       2708            76   \n",
       "\n",
       "          domain i|e n|s t|f j|p  \n",
       "0       diplomat   e   n   f   j  \n",
       "1       diplomat   e   n   f   j  \n",
       "3       diplomat   e   n   f   j  \n",
       "4       diplomat   e   n   f   j  \n",
       "5       diplomat   e   n   f   j  \n",
       "...          ...  ..  ..  ..  ..  \n",
       "497395  diplomat   e   n   f   p  \n",
       "497432  diplomat   e   n   f   p  \n",
       "497481  diplomat   e   n   f   p  \n",
       "497487  diplomat   e   n   f   p  \n",
       "497493  diplomat   e   n   f   p  \n",
       "\n",
       "[214613 rows x 13 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# new_list = []\n",
    "def domainmapper(spot):\n",
    "        if (spot == 'intj') | (spot == 'entj') | (spot == 'intp') | (spot == 'entp'):\n",
    "            return 'analyst'\n",
    "        elif (spot == 'infj') | (spot == 'enfj') | (spot == 'infp') | (spot == 'enfp'):\n",
    "            return 'diplomat'\n",
    "        elif (spot == 'istj') | (spot == 'estj') | (spot == 'isfj') | (spot == 'esfj'):\n",
    "            return 'sentinel'\n",
    "        elif (spot == 'istp') | (spot == 'estp') | (spot == 'isfp') | (spot == 'esfp'):\n",
    "            return 'explorer'\n",
    "        # else:\n",
    "        #     new_list.append('other')\n",
    "\n",
    "\n",
    "\n",
    "def pairwiseattributemapper(df):\n",
    "    x=df['type']\n",
    "    i_e={}\n",
    "\n",
    "    n_s={}\n",
    "\n",
    "    t_f={}\n",
    "\n",
    "    j_p={}\n",
    "\n",
    "\n",
    "    for spot in x:\n",
    "        if (spot[0]=='i')|(spot[0]=='e'):\n",
    "            if spot[0]=='i':\n",
    "                i_e.update({spot:'i'})\n",
    "            else:\n",
    "                i_e.update({spot:'e'})    \n",
    "        if (spot[1]=='n')|(spot[1]=='s'):\n",
    "            if spot[1]=='n':\n",
    "                n_s.update({spot:'n'})\n",
    "            else:\n",
    "                n_s.update({spot:'s'})    \n",
    "        if (spot[2]=='t')|(spot[2]=='f'):\n",
    "            if spot[2]=='t':\n",
    "                t_f.update({spot:'t'})\n",
    "            else:\n",
    "                t_f.update({spot:'f'})    \n",
    "        if (spot[3]=='j')|(spot[3]=='p'):\n",
    "            if spot[3]=='j':\n",
    "                j_p.update({spot:'j'})\n",
    "            else:\n",
    "                j_p.update({spot:'p'})    \n",
    "    df['i|e']=x.map(i_e)\n",
    "    df['n|s']=x.map(n_s)\n",
    "    df['t|f']=x.map(t_f)\n",
    "    df['j|p']=x.map(j_p)\n",
    "    return df\n",
    "    \n",
    "       \n",
    "        # else:\n",
    "        #     new_list.append('other')\n",
    "\n",
    "\n",
    "tryagain=keep[['type','name','renderedContent','handle','date','lang','likeCount','retweetCount']]\n",
    "tryagain.type=tryagain.type.str.lower()        \n",
    "\n",
    "tryagain['content']=tryagain['renderedContent']\n",
    "tryagain=tryagain[['type','name','content','handle','date','lang','likeCount','retweetCount']]\n",
    "tryagain['domain'] = tryagain['type'].apply(domainmapper)\n",
    "tryagain=pairwiseattributemapper(tryagain)\n",
    "tryagain=tryagain.drop_duplicates()\n",
    "\n",
    "\n",
    "tryagain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test for the big prep loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>content</th>\n",
       "      <th>handle</th>\n",
       "      <th>date</th>\n",
       "      <th>lang</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>domain</th>\n",
       "      <th>i|e</th>\n",
       "      <th>n|s</th>\n",
       "      <th>t|f</th>\n",
       "      <th>j|p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49610</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>LAS 12 con @AnaMenaMusic OUT NOW 🔥 youtube.com...</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2022-06-16 22:48:24+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>2019</td>\n",
       "      <td>593</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49618</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>COLORBLIND 🎧 orcd.co/belinda_colorb… https://t...</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2022-05-16 16:42:34+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>4154</td>\n",
       "      <td>606</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49632</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>Love me COLORBLIND 👁️</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2022-05-02 17:03:05+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>2864</td>\n",
       "      <td>398</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49634</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>I'm here holding on ♫</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2022-04-29 21:11:08+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>2928</td>\n",
       "      <td>391</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49635</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>End this f*ckng game 🦋</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2022-04-28 04:40:45+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>3944</td>\n",
       "      <td>532</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49652</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>Livin' the dream. Nothing's ever gonna come be...</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2022-03-29 20:34:48+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>2112</td>\n",
       "      <td>332</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248000</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>Demon to some. Angel to others. Halloween 2022...</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2022-11-01 05:54:07+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>8530</td>\n",
       "      <td>637</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248011</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>LAS 12 con @AnaMenaMusic OUT NOW 🔥 youtube.com...</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2022-06-16 22:48:24+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>2021</td>\n",
       "      <td>594</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248019</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>COLORBLIND 🎧 orcd.co/belinda_colorb… https://t...</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2022-05-16 16:42:34+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>4154</td>\n",
       "      <td>607</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248033</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>Love me COLORBLIND 👁️</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2022-05-02 17:03:05+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>2862</td>\n",
       "      <td>398</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248035</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>I'm here holding on ♫</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2022-04-29 21:11:08+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>2925</td>\n",
       "      <td>391</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248036</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>End this f*ckng game 🦋</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2022-04-28 04:40:45+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>3940</td>\n",
       "      <td>532</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248053</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>Livin' the dream. Nothing's ever gonna come be...</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2022-03-29 20:34:48+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>2111</td>\n",
       "      <td>332</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248104</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>P L A Y ▶️ #LaNiñaDeLaEscuela @lolaindigomusic...</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2021-07-18 20:02:28+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>3624</td>\n",
       "      <td>551</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248128</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>Jigglypuff 😍</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2021-06-21 02:57:51+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>5642</td>\n",
       "      <td>359</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248139</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>Bona nit!! 🐭</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2021-06-15 03:59:46+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>2524</td>\n",
       "      <td>195</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248189</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>Why wait?</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2021-04-07 16:07:45+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>3180</td>\n",
       "      <td>325</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248205</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>Glow @PriceShoes https://t.co/Bukjx05vzb</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2021-01-21 16:54:25+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>2571</td>\n",
       "      <td>265</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248220</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>#UnaMamacita like me</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2020-11-12 02:26:10+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>5347</td>\n",
       "      <td>324</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248222</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>Bona nit!!</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2020-11-05 05:54:29+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>4655</td>\n",
       "      <td>232</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248242</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>Breathe https://t.co/EN6B5hqCfV</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2020-08-25 03:50:16+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>29989</td>\n",
       "      <td>989</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248254</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>Dark side 🖤🤍 instagram.com/p/CD1vph6JtkD/</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2020-08-13 23:54:05+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>1190</td>\n",
       "      <td>133</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248271</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>Bona nit!!</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2020-08-12 06:21:50+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>4202</td>\n",
       "      <td>224</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248292</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>And I know you... https://t.co/7G8w9NWIXK</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2020-07-24 16:58:07+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>18911</td>\n",
       "      <td>1063</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248306</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>Bona nit!! 🐭</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2020-06-26 05:57:54+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>3144</td>\n",
       "      <td>209</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248331</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>Bona nit!! 🐭</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2020-06-04 05:31:31+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>2993</td>\n",
       "      <td>219</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248347</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>Jigglypuff.</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2020-05-27 22:44:57+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>7135</td>\n",
       "      <td>765</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248349</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>{caption this} 👉 instagram.com/p/CAnvYquJMHw/ ...</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2020-05-27 02:26:43+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>12407</td>\n",
       "      <td>717</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248352</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>I let the melody shine, let it cleanse my mind...</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2020-05-24 16:29:45+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>7371</td>\n",
       "      <td>490</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248378</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>Let everything happen to you \\nBeauty and terr...</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2020-04-12 20:18:41+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>3690</td>\n",
       "      <td>293</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248386</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>Bona nit!!🐭</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2020-02-07 08:20:01+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>1874</td>\n",
       "      <td>166</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248414</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>If we were 🖤💛🖤 instagram.com/p/B3dPMqqJF1v/ ht...</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2019-10-11 18:35:46+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>11275</td>\n",
       "      <td>550</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248422</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>Day by day stronger and stronger... https://t....</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2019-09-30 16:40:58+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>12654</td>\n",
       "      <td>593</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248423</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>Bona nit!! 🐭 instagram.com/p/B29vHgSpFWb/ http...</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2019-09-30 04:35:11+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>9807</td>\n",
       "      <td>390</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248444</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>But I still get lonely... https://t.co/NVOiGWpnV1</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2019-07-20 02:25:20+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>41706</td>\n",
       "      <td>3206</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248474</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>My Saturday rainy day... ☔️ https://t.co/CVzY8...</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2019-06-23 02:24:30+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>9591</td>\n",
       "      <td>1195</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248484</th>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>Yeahhhhh!!! twitter.com/anggiefan/stat…</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>2019-06-14 06:03:51+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>342</td>\n",
       "      <td>67</td>\n",
       "      <td>diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        type     name                                            content  \\\n",
       "49610   enfj  belinda  LAS 12 con @AnaMenaMusic OUT NOW 🔥 youtube.com...   \n",
       "49618   enfj  belinda  COLORBLIND 🎧 orcd.co/belinda_colorb… https://t...   \n",
       "49632   enfj  belinda                              Love me COLORBLIND 👁️   \n",
       "49634   enfj  belinda                              I'm here holding on ♫   \n",
       "49635   enfj  belinda                             End this f*ckng game 🦋   \n",
       "49652   enfj  belinda  Livin' the dream. Nothing's ever gonna come be...   \n",
       "248000  enfj  belinda  Demon to some. Angel to others. Halloween 2022...   \n",
       "248011  enfj  belinda  LAS 12 con @AnaMenaMusic OUT NOW 🔥 youtube.com...   \n",
       "248019  enfj  belinda  COLORBLIND 🎧 orcd.co/belinda_colorb… https://t...   \n",
       "248033  enfj  belinda                              Love me COLORBLIND 👁️   \n",
       "248035  enfj  belinda                              I'm here holding on ♫   \n",
       "248036  enfj  belinda                             End this f*ckng game 🦋   \n",
       "248053  enfj  belinda  Livin' the dream. Nothing's ever gonna come be...   \n",
       "248104  enfj  belinda  P L A Y ▶️ #LaNiñaDeLaEscuela @lolaindigomusic...   \n",
       "248128  enfj  belinda                                       Jigglypuff 😍   \n",
       "248139  enfj  belinda                                       Bona nit!! 🐭   \n",
       "248189  enfj  belinda                                          Why wait?   \n",
       "248205  enfj  belinda           Glow @PriceShoes https://t.co/Bukjx05vzb   \n",
       "248220  enfj  belinda                               #UnaMamacita like me   \n",
       "248222  enfj  belinda                                         Bona nit!!   \n",
       "248242  enfj  belinda                    Breathe https://t.co/EN6B5hqCfV   \n",
       "248254  enfj  belinda          Dark side 🖤🤍 instagram.com/p/CD1vph6JtkD/   \n",
       "248271  enfj  belinda                                         Bona nit!!   \n",
       "248292  enfj  belinda          And I know you... https://t.co/7G8w9NWIXK   \n",
       "248306  enfj  belinda                                       Bona nit!! 🐭   \n",
       "248331  enfj  belinda                                       Bona nit!! 🐭   \n",
       "248347  enfj  belinda                                        Jigglypuff.   \n",
       "248349  enfj  belinda  {caption this} 👉 instagram.com/p/CAnvYquJMHw/ ...   \n",
       "248352  enfj  belinda  I let the melody shine, let it cleanse my mind...   \n",
       "248378  enfj  belinda  Let everything happen to you \\nBeauty and terr...   \n",
       "248386  enfj  belinda                                        Bona nit!!🐭   \n",
       "248414  enfj  belinda  If we were 🖤💛🖤 instagram.com/p/B3dPMqqJF1v/ ht...   \n",
       "248422  enfj  belinda  Day by day stronger and stronger... https://t....   \n",
       "248423  enfj  belinda  Bona nit!! 🐭 instagram.com/p/B29vHgSpFWb/ http...   \n",
       "248444  enfj  belinda  But I still get lonely... https://t.co/NVOiGWpnV1   \n",
       "248474  enfj  belinda  My Saturday rainy day... ☔️ https://t.co/CVzY8...   \n",
       "248484  enfj  belinda            Yeahhhhh!!! twitter.com/anggiefan/stat…   \n",
       "\n",
       "            handle                      date lang  likeCount  retweetCount  \\\n",
       "49610   belindapop 2022-06-16 22:48:24+00:00   en       2019           593   \n",
       "49618   belindapop 2022-05-16 16:42:34+00:00   en       4154           606   \n",
       "49632   belindapop 2022-05-02 17:03:05+00:00   en       2864           398   \n",
       "49634   belindapop 2022-04-29 21:11:08+00:00   en       2928           391   \n",
       "49635   belindapop 2022-04-28 04:40:45+00:00   en       3944           532   \n",
       "49652   belindapop 2022-03-29 20:34:48+00:00   en       2112           332   \n",
       "248000  belindapop 2022-11-01 05:54:07+00:00   en       8530           637   \n",
       "248011  belindapop 2022-06-16 22:48:24+00:00   en       2021           594   \n",
       "248019  belindapop 2022-05-16 16:42:34+00:00   en       4154           607   \n",
       "248033  belindapop 2022-05-02 17:03:05+00:00   en       2862           398   \n",
       "248035  belindapop 2022-04-29 21:11:08+00:00   en       2925           391   \n",
       "248036  belindapop 2022-04-28 04:40:45+00:00   en       3940           532   \n",
       "248053  belindapop 2022-03-29 20:34:48+00:00   en       2111           332   \n",
       "248104  belindapop 2021-07-18 20:02:28+00:00   en       3624           551   \n",
       "248128  belindapop 2021-06-21 02:57:51+00:00   en       5642           359   \n",
       "248139  belindapop 2021-06-15 03:59:46+00:00   en       2524           195   \n",
       "248189  belindapop 2021-04-07 16:07:45+00:00   en       3180           325   \n",
       "248205  belindapop 2021-01-21 16:54:25+00:00   en       2571           265   \n",
       "248220  belindapop 2020-11-12 02:26:10+00:00   en       5347           324   \n",
       "248222  belindapop 2020-11-05 05:54:29+00:00   en       4655           232   \n",
       "248242  belindapop 2020-08-25 03:50:16+00:00   en      29989           989   \n",
       "248254  belindapop 2020-08-13 23:54:05+00:00   en       1190           133   \n",
       "248271  belindapop 2020-08-12 06:21:50+00:00   en       4202           224   \n",
       "248292  belindapop 2020-07-24 16:58:07+00:00   en      18911          1063   \n",
       "248306  belindapop 2020-06-26 05:57:54+00:00   en       3144           209   \n",
       "248331  belindapop 2020-06-04 05:31:31+00:00   en       2993           219   \n",
       "248347  belindapop 2020-05-27 22:44:57+00:00   en       7135           765   \n",
       "248349  belindapop 2020-05-27 02:26:43+00:00   en      12407           717   \n",
       "248352  belindapop 2020-05-24 16:29:45+00:00   en       7371           490   \n",
       "248378  belindapop 2020-04-12 20:18:41+00:00   en       3690           293   \n",
       "248386  belindapop 2020-02-07 08:20:01+00:00   en       1874           166   \n",
       "248414  belindapop 2019-10-11 18:35:46+00:00   en      11275           550   \n",
       "248422  belindapop 2019-09-30 16:40:58+00:00   en      12654           593   \n",
       "248423  belindapop 2019-09-30 04:35:11+00:00   en       9807           390   \n",
       "248444  belindapop 2019-07-20 02:25:20+00:00   en      41706          3206   \n",
       "248474  belindapop 2019-06-23 02:24:30+00:00   en       9591          1195   \n",
       "248484  belindapop 2019-06-14 06:03:51+00:00   en        342            67   \n",
       "\n",
       "          domain i|e n|s t|f j|p  \n",
       "49610   diplomat   e   n   f   j  \n",
       "49618   diplomat   e   n   f   j  \n",
       "49632   diplomat   e   n   f   j  \n",
       "49634   diplomat   e   n   f   j  \n",
       "49635   diplomat   e   n   f   j  \n",
       "49652   diplomat   e   n   f   j  \n",
       "248000  diplomat   e   n   f   j  \n",
       "248011  diplomat   e   n   f   j  \n",
       "248019  diplomat   e   n   f   j  \n",
       "248033  diplomat   e   n   f   j  \n",
       "248035  diplomat   e   n   f   j  \n",
       "248036  diplomat   e   n   f   j  \n",
       "248053  diplomat   e   n   f   j  \n",
       "248104  diplomat   e   n   f   j  \n",
       "248128  diplomat   e   n   f   j  \n",
       "248139  diplomat   e   n   f   j  \n",
       "248189  diplomat   e   n   f   j  \n",
       "248205  diplomat   e   n   f   j  \n",
       "248220  diplomat   e   n   f   j  \n",
       "248222  diplomat   e   n   f   j  \n",
       "248242  diplomat   e   n   f   j  \n",
       "248254  diplomat   e   n   f   j  \n",
       "248271  diplomat   e   n   f   j  \n",
       "248292  diplomat   e   n   f   j  \n",
       "248306  diplomat   e   n   f   j  \n",
       "248331  diplomat   e   n   f   j  \n",
       "248347  diplomat   e   n   f   j  \n",
       "248349  diplomat   e   n   f   j  \n",
       "248352  diplomat   e   n   f   j  \n",
       "248378  diplomat   e   n   f   j  \n",
       "248386  diplomat   e   n   f   j  \n",
       "248414  diplomat   e   n   f   j  \n",
       "248422  diplomat   e   n   f   j  \n",
       "248423  diplomat   e   n   f   j  \n",
       "248444  diplomat   e   n   f   j  \n",
       "248474  diplomat   e   n   f   j  \n",
       "248484  diplomat   e   n   f   j  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>subgroup</th>\n",
       "      <th>name</th>\n",
       "      <th>docs</th>\n",
       "      <th>lemmatized docs</th>\n",
       "      <th>tf-idf w.r.t name</th>\n",
       "      <th>freq table w.r.t name</th>\n",
       "      <th>handle</th>\n",
       "      <th>date</th>\n",
       "      <th>lang</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>retweetCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>type</td>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>[LAS 12 con @AnaMenaMusic OUT NOW 🔥 youtube.co...</td>\n",
       "      <td>[youtube watch zwzfco, orcd belinda colorb, lo...</td>\n",
       "      <td>{'nit': 4.62, 'bona': 4.62, 'twitter': 3.084, ...</td>\n",
       "      <td>{'nit': 7, 'bona': 7, 'twitter': 3, 'let': 3, ...</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>[2022-06-16T22:48:24.000000000, 2022-05-16T16:...</td>\n",
       "      <td>en</td>\n",
       "      <td>250388</td>\n",
       "      <td>19863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  group subgroup     name                                               docs  \\\n",
       "0  type     enfj  belinda  [LAS 12 con @AnaMenaMusic OUT NOW 🔥 youtube.co...   \n",
       "\n",
       "                                     lemmatized docs  \\\n",
       "0  [youtube watch zwzfco, orcd belinda colorb, lo...   \n",
       "\n",
       "                                   tf-idf w.r.t name  \\\n",
       "0  {'nit': 4.62, 'bona': 4.62, 'twitter': 3.084, ...   \n",
       "\n",
       "                               freq table w.r.t name      handle  \\\n",
       "0  {'nit': 7, 'bona': 7, 'twitter': 3, 'let': 3, ...  belindapop   \n",
       "\n",
       "                                                date lang  likeCount  \\\n",
       "0  [2022-06-16T22:48:24.000000000, 2022-05-16T16:...   en     250388   \n",
       "\n",
       "   retweetCount  \n",
       "0         19863  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# def calc_idf(word,**kwargs):\n",
    "#         documents =kwargs['docs']\n",
    "#         n_occurences = sum([1 for doc in documents if word in doc])\n",
    "#         return len(documents) / n_occurences\n",
    "\t\t\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Get a list of the unique words\n",
    "# def idfDf(documents):\n",
    "#     unique_words = pd.Series(','.join(documents).split()).unique()\n",
    "#     kwargs={'docs':documents}\n",
    "#     # put the unique words into a data frame\n",
    "#     df=(pd.DataFrame(dict(word=unique_words))\n",
    "#      # calculate the idf for each word\n",
    "#      .assign(idf=lambda df: df.word.apply(calc_idf))\n",
    "#      # sort the data for presentation purposes\n",
    "#      .set_index('word')\n",
    "#      .sort_values(by='idf', ascending=False))\n",
    "#     return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "groups=['type', 'domain', 'i|e', 'n|s', 't|f', 'j|p']\n",
    "allthewaydict={'group':{},'subgroup':{},'name':{},'docs':{},'lemmatized docs':{},'tf-idf w.r.t name':{},'freq table w.r.t name':{},'handle':{},'date':{},'lang'\t:{},'likeCount':{},'retweetCount':{}}\n",
    "# groups=(groups[2:4])\n",
    "count=0\n",
    "g=groups[0]\n",
    "print(f'{g}\\n')\n",
    "group=tryagain.groupby(g)\n",
    "keys=group.groups.keys()\n",
    "# for key in keys:\n",
    "key=list(keys)[0]\n",
    "# print(key)\n",
    "kthgroup=group.get_group(key)\n",
    "namegru=kthgroup.groupby('name')\n",
    "subkeys=namegru.groups.keys()\n",
    "# for sk in subkeys:\n",
    "#     count+=\n",
    "curname=namegru.get_group(list(subkeys)[4])\n",
    "display(curname)\n",
    "nm=curname.name.unique()[0]\n",
    "docs=curname.content.values\n",
    "# splitdocs=docs.split('')\n",
    "\n",
    "\n",
    "lemma=[stopfilter(i) for i in [lemmatizor(d) for d in docs]]\n",
    "lemma=[i.strip() for i in lemma if len(i)>=2]\n",
    "fulllist=\" \".join(lemma).split()\n",
    "\n",
    "\n",
    "valcounts=pd.Series(fulllist).value_counts()\n",
    "freq=valcounts.values\n",
    "\n",
    "\n",
    "##TF-IDF calc\n",
    "x=np.log10((len(lemma)/freq))\n",
    "x*=freq\n",
    "x=np.ndarray.round(x,3)\n",
    "tf_idf=(dict(zip((pd.Series(fulllist).value_counts().index),x)))\n",
    "freqtable=dict(valcounts)\n",
    "\n",
    "# df=idfDf(lemma);display(df)\n",
    "allthewaydict['group'].update({count:g})\n",
    "allthewaydict['subgroup'].update({count:key})\n",
    "allthewaydict['name'].update({count:nm})\n",
    "allthewaydict['docs'].update({count:docs})\n",
    "allthewaydict['lemmatized docs'].update({count:lemma})\n",
    "allthewaydict['tf-idf w.r.t name'].update({count:tf_idf})\n",
    "allthewaydict['freq table w.r.t name'].update({count:freqtable})\n",
    "\n",
    "allthewaydict['handle'].update({count:curname.handle.values[0]})\n",
    "allthewaydict['date'].update({count:curname.date.values})\n",
    "allthewaydict['lang'].update({count:curname.lang.values[0]})\n",
    "allthewaydict['likeCount'].update({count:curname.likeCount.values.sum()})\n",
    "allthewaydict['retweetCount'].update({count:curname.retweetCount.values.sum()})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "count+=1\n",
    "\n",
    "pd.DataFrame(allthewaydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tc/rqcbqynd6g96v17vbqppznm40000gn/T/ipykernel_87349/3336441427.py:30: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  valcounts=pd.Series(fulllist).value_counts()\n",
      "/var/folders/tc/rqcbqynd6g96v17vbqppznm40000gn/T/ipykernel_87349/3336441427.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  tf_idf=(dict(zip((pd.Series(fulllist).value_counts().index),x)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "domain\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tc/rqcbqynd6g96v17vbqppznm40000gn/T/ipykernel_87349/3336441427.py:30: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  valcounts=pd.Series(fulllist).value_counts()\n",
      "/var/folders/tc/rqcbqynd6g96v17vbqppznm40000gn/T/ipykernel_87349/3336441427.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  tf_idf=(dict(zip((pd.Series(fulllist).value_counts().index),x)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i|e\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tc/rqcbqynd6g96v17vbqppznm40000gn/T/ipykernel_87349/3336441427.py:30: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  valcounts=pd.Series(fulllist).value_counts()\n",
      "/var/folders/tc/rqcbqynd6g96v17vbqppznm40000gn/T/ipykernel_87349/3336441427.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  tf_idf=(dict(zip((pd.Series(fulllist).value_counts().index),x)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n|s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tc/rqcbqynd6g96v17vbqppznm40000gn/T/ipykernel_87349/3336441427.py:30: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  valcounts=pd.Series(fulllist).value_counts()\n",
      "/var/folders/tc/rqcbqynd6g96v17vbqppznm40000gn/T/ipykernel_87349/3336441427.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  tf_idf=(dict(zip((pd.Series(fulllist).value_counts().index),x)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t|f\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tc/rqcbqynd6g96v17vbqppznm40000gn/T/ipykernel_87349/3336441427.py:30: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  valcounts=pd.Series(fulllist).value_counts()\n",
      "/var/folders/tc/rqcbqynd6g96v17vbqppznm40000gn/T/ipykernel_87349/3336441427.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  tf_idf=(dict(zip((pd.Series(fulllist).value_counts().index),x)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j|p\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tc/rqcbqynd6g96v17vbqppznm40000gn/T/ipykernel_87349/3336441427.py:30: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  valcounts=pd.Series(fulllist).value_counts()\n",
      "/var/folders/tc/rqcbqynd6g96v17vbqppznm40000gn/T/ipykernel_87349/3336441427.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  tf_idf=(dict(zip((pd.Series(fulllist).value_counts().index),x)))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "groups=['type', 'domain', 'i|e', 'n|s', 't|f', 'j|p']\n",
    "\n",
    "\n",
    "allthewaydict={'group':{},'subgroup':{},'name':{},'docs':{},'lemmatized docs':{},'tf-idf w.r.t name':{},'freq table w.r.t name':{},'handle':{},'date':{},'lang'\t:{},'likeCount':{},'retweetCount':{}}\n",
    "# groups=(groups[2:4])\n",
    "count=0\n",
    "for g in groups:\n",
    "    print(f'{g}\\n')\n",
    "    group=tryagain.groupby(g)\n",
    "    keys=group.groups.keys()\n",
    "    for key in keys:\n",
    "        # print(key)\n",
    "        kthgroup=group.get_group(key)\n",
    "        namegru=kthgroup.groupby('name')\n",
    "        subkeys=namegru.groups.keys()\n",
    "        \n",
    "\n",
    "        for sk in subkeys:\n",
    "            curname=namegru.get_group(sk)        \n",
    "            nm=curname.name.unique()[0]\n",
    "            docs=curname.content.values\n",
    "            # splitdocs=docs.split('')\n",
    "\n",
    "\n",
    "            lemma=[stopfilter(i) for i in [lemmatizor(d) for d in docs]]\n",
    "            lemma=[i.strip() for i in lemma if len(i)>=2]\n",
    "            fulllist=\" \".join(lemma).split()\n",
    "\n",
    "\n",
    "            valcounts=pd.Series(fulllist).value_counts()\n",
    "            freq=valcounts.values\n",
    "\n",
    "\n",
    "            ##TF-IDF calc\n",
    "            x=np.log10((len(lemma)/freq))\n",
    "            x*=freq\n",
    "            x=np.ndarray.round(x,3)\n",
    "            tf_idf=(dict(zip((pd.Series(fulllist).value_counts().index),x)))\n",
    "            freqtable=dict(valcounts)\n",
    "\n",
    "            # df=idfDf(lemma);display(df)\n",
    "            allthewaydict['group'].update({count:g})\n",
    "            allthewaydict['subgroup'].update({count:key})\n",
    "            allthewaydict['name'].update({count:nm})\n",
    "            allthewaydict['docs'].update({count:docs})\n",
    "            allthewaydict['lemmatized docs'].update({count:lemma})\n",
    "            allthewaydict['tf-idf w.r.t name'].update({count:tf_idf})\n",
    "            allthewaydict['freq table w.r.t name'].update({count:freqtable})\n",
    "            allthewaydict['handle'].update({count:curname.handle.values[0]})\n",
    "            allthewaydict['date'].update({count:curname.date.values})\n",
    "            allthewaydict['lang'].update({count:curname.lang.values[0]})\n",
    "            allthewaydict['likeCount'].update({count:curname.likeCount.values.sum()})\n",
    "            allthewaydict['retweetCount'].update({count:curname.retweetCount.values.sum()})\n",
    "\n",
    "\n",
    "            count+=1\n",
    "\n",
    "\n",
    "allthewaydown=pd.DataFrame(allthewaydict)\n",
    "\n",
    "\n",
    "allthewaydown\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>subgroup</th>\n",
       "      <th>name</th>\n",
       "      <th>docs</th>\n",
       "      <th>lemmatized docs</th>\n",
       "      <th>tf-idf w.r.t name</th>\n",
       "      <th>freq table w.r.t name</th>\n",
       "      <th>handle</th>\n",
       "      <th>date</th>\n",
       "      <th>lang</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>retweetCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>type</td>\n",
       "      <td>enfj</td>\n",
       "      <td>anggun official</td>\n",
       "      <td>[#EliHallo - Behind the scene photos of the mu...</td>\n",
       "      <td>[elihallo behind scene photos music video elih...</td>\n",
       "      <td>{'amp': 10.294, 'twitter': 10.294, 'world': 10...</td>\n",
       "      <td>{'amp': 10, 'twitter': 10, 'world': 10, 'wait'...</td>\n",
       "      <td>Anggun_Cipta</td>\n",
       "      <td>[2022-09-27T19:40:04.000000000, 2022-09-23T15:...</td>\n",
       "      <td>en</td>\n",
       "      <td>32701</td>\n",
       "      <td>6974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>type</td>\n",
       "      <td>enfj</td>\n",
       "      <td>ansel elgort</td>\n",
       "      <td>[I like u so much more than your social media ...</td>\n",
       "      <td>[social media presence, come caps gotta caps r...</td>\n",
       "      <td>{'tfios': 69.533, 'guys': 48.099, 'unite': 46....</td>\n",
       "      <td>{'tfios': 84, 'guys': 43, 'unite': 41, 'love':...</td>\n",
       "      <td>AnselElgort</td>\n",
       "      <td>[2018-11-02T16:02:32.000000000, 2017-10-03T17:...</td>\n",
       "      <td>en</td>\n",
       "      <td>3689250</td>\n",
       "      <td>1374222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>type</td>\n",
       "      <td>enfj</td>\n",
       "      <td>ashton irwin</td>\n",
       "      <td>[Thanks for listening to these! They share a b...</td>\n",
       "      <td>[thanks share birthday love, drums tracked bas...</td>\n",
       "      <td>{'love': 58.969, 'thank': 45.658, 'new': 41.98...</td>\n",
       "      <td>{'love': 62, 'thank': 40, 'new': 35, 'us': 35,...</td>\n",
       "      <td>Ashton5SOS</td>\n",
       "      <td>[2022-10-23T23:57:48.000000000, 2022-10-23T16:...</td>\n",
       "      <td>en</td>\n",
       "      <td>10665238</td>\n",
       "      <td>1390503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>type</td>\n",
       "      <td>enfj</td>\n",
       "      <td>basti schweinsteiger</td>\n",
       "      <td>[Sunday walk 😉 https://t.co/J9GoT6Ln8b, So pro...</td>\n",
       "      <td>[sunday walk, proud still vote vote twitter, a...</td>\n",
       "      <td>{'fcbayern': 40.331, 'amp': 39.017, 'twitter':...</td>\n",
       "      <td>{'fcbayern': 47, 'amp': 44, 'twitter': 37, 'gr...</td>\n",
       "      <td>BSchweinsteiger</td>\n",
       "      <td>[2022-10-30T10:19:15.000000000, 2022-10-28T11:...</td>\n",
       "      <td>en</td>\n",
       "      <td>3399010</td>\n",
       "      <td>281274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>type</td>\n",
       "      <td>enfj</td>\n",
       "      <td>belinda</td>\n",
       "      <td>[LAS 12 con @AnaMenaMusic OUT NOW 🔥 youtube.co...</td>\n",
       "      <td>[youtube watch zwzfco, orcd belinda colorb, lo...</td>\n",
       "      <td>{'nit': 4.62, 'bona': 4.62, 'twitter': 3.084, ...</td>\n",
       "      <td>{'nit': 7, 'bona': 7, 'twitter': 3, 'let': 3, ...</td>\n",
       "      <td>belindapop</td>\n",
       "      <td>[2022-06-16T22:48:24.000000000, 2022-05-16T16:...</td>\n",
       "      <td>en</td>\n",
       "      <td>250388</td>\n",
       "      <td>19863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3553</th>\n",
       "      <td>j|p</td>\n",
       "      <td>p</td>\n",
       "      <td>willy</td>\n",
       "      <td>[@dojasbreastmilk @AltPress Everyday! They are...</td>\n",
       "      <td>[altpress everyday first faves wake last sleep...</td>\n",
       "      <td>{'gt': 45.093, 'love': 40.53, 'lt': 39.123, 'w...</td>\n",
       "      <td>{'gt': 43, 'love': 36, 'lt': 34, 'willow': 27,...</td>\n",
       "      <td>OfficialWillow</td>\n",
       "      <td>[2022-10-28T18:33:03.000000000, 2022-10-28T18:...</td>\n",
       "      <td>en</td>\n",
       "      <td>1306738</td>\n",
       "      <td>308187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3554</th>\n",
       "      <td>j|p</td>\n",
       "      <td>p</td>\n",
       "      <td>wisin y yandel</td>\n",
       "      <td>[WISIN &amp;amp; YANDEEEEEEL https://t.co/CiiGS0iS...</td>\n",
       "      <td>[wisin amp, dale play youtu, dale play apple n...</td>\n",
       "      <td>{'dale': 4.599, 'play': 4.599, 'wisin': 4.631,...</td>\n",
       "      <td>{'dale': 12, 'play': 12, 'wisin': 11, 'yandel'...</td>\n",
       "      <td>wisinyyandel</td>\n",
       "      <td>[2022-05-27T01:56:56.000000000, 2022-03-08T01:...</td>\n",
       "      <td>en</td>\n",
       "      <td>5957</td>\n",
       "      <td>884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3555</th>\n",
       "      <td>j|p</td>\n",
       "      <td>p</td>\n",
       "      <td>zac efron</td>\n",
       "      <td>[Let’s fix this so we can keep making beautifu...</td>\n",
       "      <td>[lets fix keep making movies together love guy...</td>\n",
       "      <td>{'love': 56.635, 'twitter': 51.473, 'happy': 4...</td>\n",
       "      <td>{'love': 62, 'twitter': 52, 'happy': 47, 'watc...</td>\n",
       "      <td>ZacEfron</td>\n",
       "      <td>[2021-09-25T16:13:04.000000000, 2021-09-08T13:...</td>\n",
       "      <td>en</td>\n",
       "      <td>11743368</td>\n",
       "      <td>1439897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3556</th>\n",
       "      <td>j|p</td>\n",
       "      <td>p</td>\n",
       "      <td>zayn</td>\n",
       "      <td>[😂🤘🏽 come on brav @stylebender #UFC276, Thank ...</td>\n",
       "      <td>[come brav, thank love support today last day,...</td>\n",
       "      <td>{'twitter': 51.746, 'love': 40.365, 'thanks': ...</td>\n",
       "      <td>{'twitter': 70, 'love': 42, 'thanks': 34, 'zay...</td>\n",
       "      <td>zaynmalik</td>\n",
       "      <td>[2022-07-03T04:33:48.000000000, 2022-07-01T14:...</td>\n",
       "      <td>en</td>\n",
       "      <td>53419499</td>\n",
       "      <td>12551373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3557</th>\n",
       "      <td>j|p</td>\n",
       "      <td>p</td>\n",
       "      <td>zooey deschanel</td>\n",
       "      <td>[Currently in denial that it isn’t long sleeve...</td>\n",
       "      <td>[denial isnt long sleeve weather yet, summer a...</td>\n",
       "      <td>{'day': 49.259, 'happy': 48.64, 'twitter': 44....</td>\n",
       "      <td>{'day': 47, 'happy': 46, 'twitter': 39, 'amp':...</td>\n",
       "      <td>ZooeyDeschanel</td>\n",
       "      <td>[2022-09-02T19:15:40.000000000, 2022-08-31T20:...</td>\n",
       "      <td>en</td>\n",
       "      <td>2853683</td>\n",
       "      <td>236950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3558 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     group subgroup                  name  \\\n",
       "0     type     enfj       anggun official   \n",
       "1     type     enfj          ansel elgort   \n",
       "2     type     enfj          ashton irwin   \n",
       "3     type     enfj  basti schweinsteiger   \n",
       "4     type     enfj               belinda   \n",
       "...    ...      ...                   ...   \n",
       "3553   j|p        p                 willy   \n",
       "3554   j|p        p        wisin y yandel   \n",
       "3555   j|p        p             zac efron   \n",
       "3556   j|p        p                  zayn   \n",
       "3557   j|p        p       zooey deschanel   \n",
       "\n",
       "                                                   docs  \\\n",
       "0     [#EliHallo - Behind the scene photos of the mu...   \n",
       "1     [I like u so much more than your social media ...   \n",
       "2     [Thanks for listening to these! They share a b...   \n",
       "3     [Sunday walk 😉 https://t.co/J9GoT6Ln8b, So pro...   \n",
       "4     [LAS 12 con @AnaMenaMusic OUT NOW 🔥 youtube.co...   \n",
       "...                                                 ...   \n",
       "3553  [@dojasbreastmilk @AltPress Everyday! They are...   \n",
       "3554  [WISIN &amp; YANDEEEEEEL https://t.co/CiiGS0iS...   \n",
       "3555  [Let’s fix this so we can keep making beautifu...   \n",
       "3556  [😂🤘🏽 come on brav @stylebender #UFC276, Thank ...   \n",
       "3557  [Currently in denial that it isn’t long sleeve...   \n",
       "\n",
       "                                        lemmatized docs  \\\n",
       "0     [elihallo behind scene photos music video elih...   \n",
       "1     [social media presence, come caps gotta caps r...   \n",
       "2     [thanks share birthday love, drums tracked bas...   \n",
       "3     [sunday walk, proud still vote vote twitter, a...   \n",
       "4     [youtube watch zwzfco, orcd belinda colorb, lo...   \n",
       "...                                                 ...   \n",
       "3553  [altpress everyday first faves wake last sleep...   \n",
       "3554  [wisin amp, dale play youtu, dale play apple n...   \n",
       "3555  [lets fix keep making movies together love guy...   \n",
       "3556  [come brav, thank love support today last day,...   \n",
       "3557  [denial isnt long sleeve weather yet, summer a...   \n",
       "\n",
       "                                      tf-idf w.r.t name  \\\n",
       "0     {'amp': 10.294, 'twitter': 10.294, 'world': 10...   \n",
       "1     {'tfios': 69.533, 'guys': 48.099, 'unite': 46....   \n",
       "2     {'love': 58.969, 'thank': 45.658, 'new': 41.98...   \n",
       "3     {'fcbayern': 40.331, 'amp': 39.017, 'twitter':...   \n",
       "4     {'nit': 4.62, 'bona': 4.62, 'twitter': 3.084, ...   \n",
       "...                                                 ...   \n",
       "3553  {'gt': 45.093, 'love': 40.53, 'lt': 39.123, 'w...   \n",
       "3554  {'dale': 4.599, 'play': 4.599, 'wisin': 4.631,...   \n",
       "3555  {'love': 56.635, 'twitter': 51.473, 'happy': 4...   \n",
       "3556  {'twitter': 51.746, 'love': 40.365, 'thanks': ...   \n",
       "3557  {'day': 49.259, 'happy': 48.64, 'twitter': 44....   \n",
       "\n",
       "                                  freq table w.r.t name           handle  \\\n",
       "0     {'amp': 10, 'twitter': 10, 'world': 10, 'wait'...     Anggun_Cipta   \n",
       "1     {'tfios': 84, 'guys': 43, 'unite': 41, 'love':...      AnselElgort   \n",
       "2     {'love': 62, 'thank': 40, 'new': 35, 'us': 35,...       Ashton5SOS   \n",
       "3     {'fcbayern': 47, 'amp': 44, 'twitter': 37, 'gr...  BSchweinsteiger   \n",
       "4     {'nit': 7, 'bona': 7, 'twitter': 3, 'let': 3, ...       belindapop   \n",
       "...                                                 ...              ...   \n",
       "3553  {'gt': 43, 'love': 36, 'lt': 34, 'willow': 27,...   OfficialWillow   \n",
       "3554  {'dale': 12, 'play': 12, 'wisin': 11, 'yandel'...     wisinyyandel   \n",
       "3555  {'love': 62, 'twitter': 52, 'happy': 47, 'watc...         ZacEfron   \n",
       "3556  {'twitter': 70, 'love': 42, 'thanks': 34, 'zay...        zaynmalik   \n",
       "3557  {'day': 47, 'happy': 46, 'twitter': 39, 'amp':...   ZooeyDeschanel   \n",
       "\n",
       "                                                   date lang  likeCount  \\\n",
       "0     [2022-09-27T19:40:04.000000000, 2022-09-23T15:...   en      32701   \n",
       "1     [2018-11-02T16:02:32.000000000, 2017-10-03T17:...   en    3689250   \n",
       "2     [2022-10-23T23:57:48.000000000, 2022-10-23T16:...   en   10665238   \n",
       "3     [2022-10-30T10:19:15.000000000, 2022-10-28T11:...   en    3399010   \n",
       "4     [2022-06-16T22:48:24.000000000, 2022-05-16T16:...   en     250388   \n",
       "...                                                 ...  ...        ...   \n",
       "3553  [2022-10-28T18:33:03.000000000, 2022-10-28T18:...   en    1306738   \n",
       "3554  [2022-05-27T01:56:56.000000000, 2022-03-08T01:...   en       5957   \n",
       "3555  [2021-09-25T16:13:04.000000000, 2021-09-08T13:...   en   11743368   \n",
       "3556  [2022-07-03T04:33:48.000000000, 2022-07-01T14:...   en   53419499   \n",
       "3557  [2022-09-02T19:15:40.000000000, 2022-08-31T20:...   en    2853683   \n",
       "\n",
       "      retweetCount  \n",
       "0             6974  \n",
       "1          1374222  \n",
       "2          1390503  \n",
       "3           281274  \n",
       "4            19863  \n",
       "...            ...  \n",
       "3553        308187  \n",
       "3554           884  \n",
       "3555       1439897  \n",
       "3556      12551373  \n",
       "3557        236950  \n",
       "\n",
       "[3558 rows x 12 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tc/rqcbqynd6g96v17vbqppznm40000gn/T/ipykernel_87349/4115732160.py:16: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  cool=dict(pd.Series(stoped.split()).value_counts())\n"
     ]
    }
   ],
   "source": [
    "num=0\n",
    "bigdict={'type':{},'name':{},'stoped_lemma':{},'freq':{}}\n",
    "for i in list(indexbyperson.keys()):\n",
    "    a=indexbyperson.get(i)\n",
    "    a=a['name']\n",
    "    for i1 in list(a.keys()):\n",
    "        listtonormaliz=str(a[i1]['content'])\n",
    "        newtext=lemmatizor(listtonormaliz,regexfilter=r'[^a-z0-9\\'\\s]')\n",
    "        lemma=newtext\n",
    "       \n",
    "        stoped=stopfilter(lemma)\n",
    "        stoped=stoped.replace('https','').replace('com','').replace('co','').replace(',','').strip()\n",
    "       \n",
    "        a[i1].update({'stopped_lemma':stoped})         \n",
    "     \n",
    "        cool=dict(pd.Series(stoped.split()).value_counts())\n",
    "        a[i1].update({'word freq':cool})\n",
    "        bigdict['type'].update({num:i})\n",
    "        bigdict['stoped_lemma'].update({num:stoped})\n",
    "        bigdict['freq'].update({num:cool})\n",
    "        bigdict['name'].update({num:i1})\n",
    "        num+=1\n",
    "\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ESTP</td>\n",
       "      <td>p!nk</td>\n",
       "      <td>guess whos hitting amas stage dancing shoes su...</td>\n",
       "      <td>{'love': 64, 'thank': 46, 'right': 35, 'day': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESTP</td>\n",
       "      <td>niall horan</td>\n",
       "      <td>excited playing first next year tickets sale f...</td>\n",
       "      <td>{'love': 40, 'great': 27, 'golf': 26, 'back': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ESTP</td>\n",
       "      <td>miley ray cyrus</td>\n",
       "      <td>last night special remember special person for...</td>\n",
       "      <td>{'amp': 101, 'love': 68, 'show': 51, 'live': 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ESTP</td>\n",
       "      <td>salman khan</td>\n",
       "      <td>happy bday hamare boxer bhai wele board happy ...</td>\n",
       "      <td>{'happy': 54, 'best': 46, 'n': 41, 'amp': 38, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESTP</td>\n",
       "      <td>blake shelton</td>\n",
       "      <td>stume thevoice trying thevoice history made to...</td>\n",
       "      <td>{'thevoice': 188, 'team': 134, 'bs': 122, 'yal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>christian bautista</td>\n",
       "      <td>near bgc everyone praying youre ok remember lo...</td>\n",
       "      <td>{'n': 27, 'thank': 24, 'myjaps': 24, 'song': 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>angelica vale</td>\n",
       "      <td>feliz tarde va dia espero nhappy day going hop...</td>\n",
       "      <td>{'besafe': 20, 'feliz': 16, 'day': 15, 'mornin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>nx zero</td>\n",
       "      <td>last show last show tks broooo rec</td>\n",
       "      <td>{'last': 2, 'show': 2, 'tks': 1, 'broooo': 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>depeche mode</td>\n",
       "      <td>french fans due venue issues dates shows lyon ...</td>\n",
       "      <td>{'mode': 102, 'singles': 95, 'depeche': 92, 'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>pedro bial</td>\n",
       "      <td>draaronb entirely honest oneself exercise salv...</td>\n",
       "      <td>{'repost': 4, 'desta': 2, 'must': 2, 'mark': 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>593 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     type                name  \\\n",
       "0    ESTP                p!nk   \n",
       "1    ESTP         niall horan   \n",
       "2    ESTP     miley ray cyrus   \n",
       "3    ESTP         salman khan   \n",
       "4    ESTP       blake shelton   \n",
       "..    ...                 ...   \n",
       "588  INFJ  christian bautista   \n",
       "589  INFJ       angelica vale   \n",
       "590  INFJ             nx zero   \n",
       "591  INFJ        depeche mode   \n",
       "592  INFJ          pedro bial   \n",
       "\n",
       "                                            lemmatized  \\\n",
       "0    guess whos hitting amas stage dancing shoes su...   \n",
       "1    excited playing first next year tickets sale f...   \n",
       "2    last night special remember special person for...   \n",
       "3    happy bday hamare boxer bhai wele board happy ...   \n",
       "4    stume thevoice trying thevoice history made to...   \n",
       "..                                                 ...   \n",
       "588  near bgc everyone praying youre ok remember lo...   \n",
       "589  feliz tarde va dia espero nhappy day going hop...   \n",
       "590                 last show last show tks broooo rec   \n",
       "591  french fans due venue issues dates shows lyon ...   \n",
       "592  draaronb entirely honest oneself exercise salv...   \n",
       "\n",
       "                                                  freq  \n",
       "0    {'love': 64, 'thank': 46, 'right': 35, 'day': ...  \n",
       "1    {'love': 40, 'great': 27, 'golf': 26, 'back': ...  \n",
       "2    {'amp': 101, 'love': 68, 'show': 51, 'live': 4...  \n",
       "3    {'happy': 54, 'best': 46, 'n': 41, 'amp': 38, ...  \n",
       "4    {'thevoice': 188, 'team': 134, 'bs': 122, 'yal...  \n",
       "..                                                 ...  \n",
       "588  {'n': 27, 'thank': 24, 'myjaps': 24, 'song': 2...  \n",
       "589  {'besafe': 20, 'feliz': 16, 'day': 15, 'mornin...  \n",
       "590  {'last': 2, 'show': 2, 'tks': 1, 'broooo': 1, ...  \n",
       "591  {'mode': 102, 'singles': 95, 'depeche': 92, 'd...  \n",
       "592  {'repost': 4, 'desta': 2, 'must': 2, 'mark': 2...  \n",
       "\n",
       "[593 rows x 4 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitterwordslemma=pd.DataFrame(bigdict)\n",
    "twitterwordslemma.columns=['type','name','lemmatized','freq']\n",
    "twitterwordslemma\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>estp</td>\n",
       "      <td>p!nk</td>\n",
       "      <td>guess whos hitting amas stage dancing shoes su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>estp</td>\n",
       "      <td>niall horan</td>\n",
       "      <td>excited playing first next year tickets sale f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>estp</td>\n",
       "      <td>miley ray cyrus</td>\n",
       "      <td>last night special remember special person for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>estp</td>\n",
       "      <td>salman khan</td>\n",
       "      <td>happy bday hamare boxer bhai wele board happy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>estp</td>\n",
       "      <td>blake shelton</td>\n",
       "      <td>stume thevoice trying thevoice history made to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>infj</td>\n",
       "      <td>christian bautista</td>\n",
       "      <td>near bgc everyone praying youre ok remember lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>infj</td>\n",
       "      <td>angelica vale</td>\n",
       "      <td>feliz tarde va dia espero nhappy day going hop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>infj</td>\n",
       "      <td>nx zero</td>\n",
       "      <td>last show last show tks broooo rec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>infj</td>\n",
       "      <td>depeche mode</td>\n",
       "      <td>french fans due venue issues dates shows lyon ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>infj</td>\n",
       "      <td>pedro bial</td>\n",
       "      <td>draaronb entirely honest oneself exercise salv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>593 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     type                name  \\\n",
       "0    estp                p!nk   \n",
       "1    estp         niall horan   \n",
       "2    estp     miley ray cyrus   \n",
       "3    estp         salman khan   \n",
       "4    estp       blake shelton   \n",
       "..    ...                 ...   \n",
       "588  infj  christian bautista   \n",
       "589  infj       angelica vale   \n",
       "590  infj             nx zero   \n",
       "591  infj        depeche mode   \n",
       "592  infj          pedro bial   \n",
       "\n",
       "                                            lemmatized  \n",
       "0    guess whos hitting amas stage dancing shoes su...  \n",
       "1    excited playing first next year tickets sale f...  \n",
       "2    last night special remember special person for...  \n",
       "3    happy bday hamare boxer bhai wele board happy ...  \n",
       "4    stume thevoice trying thevoice history made to...  \n",
       "..                                                 ...  \n",
       "588  near bgc everyone praying youre ok remember lo...  \n",
       "589  feliz tarde va dia espero nhappy day going hop...  \n",
       "590                 last show last show tks broooo rec  \n",
       "591  french fans due venue issues dates shows lyon ...  \n",
       "592  draaronb entirely honest oneself exercise salv...  \n",
       "\n",
       "[593 rows x 3 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitterwordslemma['type']=twitterwordslemma.type.str.lower()\n",
    "\n",
    "pd.to_pickle(twitterwordslemma,'maindalemma.pkl')\n",
    "\n",
    "df=pd.read_pickle('maindalemma.pkl')\n",
    "df=df[[\t'type',\t'name',\t'lemmatized'\t]]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The remaing is explore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>estp</td>\n",
       "      <td>p!nk</td>\n",
       "      <td>guess whos hitting amas stage dancing shoes su...</td>\n",
       "      <td>{'love': 64, 'thank': 46, 'right': 35, 'day': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>estp</td>\n",
       "      <td>niall horan</td>\n",
       "      <td>excited playing first next year tickets sale f...</td>\n",
       "      <td>{'love': 40, 'great': 27, 'golf': 26, 'back': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>estp</td>\n",
       "      <td>miley ray cyrus</td>\n",
       "      <td>last night special remember special person for...</td>\n",
       "      <td>{'amp': 101, 'love': 68, 'show': 51, 'live': 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>estp</td>\n",
       "      <td>salman khan</td>\n",
       "      <td>happy bday hamare boxer bhai wele board happy ...</td>\n",
       "      <td>{'happy': 54, 'best': 46, 'n': 41, 'amp': 38, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>estp</td>\n",
       "      <td>blake shelton</td>\n",
       "      <td>stume thevoice trying thevoice history made to...</td>\n",
       "      <td>{'thevoice': 188, 'team': 134, 'bs': 122, 'yal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>infj</td>\n",
       "      <td>christian bautista</td>\n",
       "      <td>near bgc everyone praying youre ok remember lo...</td>\n",
       "      <td>{'n': 27, 'thank': 24, 'myjaps': 24, 'song': 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>infj</td>\n",
       "      <td>angelica vale</td>\n",
       "      <td>feliz tarde va dia espero nhappy day going hop...</td>\n",
       "      <td>{'besafe': 20, 'feliz': 16, 'day': 15, 'mornin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>infj</td>\n",
       "      <td>nx zero</td>\n",
       "      <td>last show last show tks broooo rec</td>\n",
       "      <td>{'last': 2, 'show': 2, 'tks': 1, 'broooo': 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>infj</td>\n",
       "      <td>depeche mode</td>\n",
       "      <td>french fans due venue issues dates shows lyon ...</td>\n",
       "      <td>{'mode': 102, 'singles': 95, 'depeche': 92, 'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>infj</td>\n",
       "      <td>pedro bial</td>\n",
       "      <td>draaronb entirely honest oneself exercise salv...</td>\n",
       "      <td>{'repost': 4, 'desta': 2, 'must': 2, 'mark': 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>593 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     type                name  \\\n",
       "0    estp                p!nk   \n",
       "1    estp         niall horan   \n",
       "2    estp     miley ray cyrus   \n",
       "3    estp         salman khan   \n",
       "4    estp       blake shelton   \n",
       "..    ...                 ...   \n",
       "588  infj  christian bautista   \n",
       "589  infj       angelica vale   \n",
       "590  infj             nx zero   \n",
       "591  infj        depeche mode   \n",
       "592  infj          pedro bial   \n",
       "\n",
       "                                            lemmatized  \\\n",
       "0    guess whos hitting amas stage dancing shoes su...   \n",
       "1    excited playing first next year tickets sale f...   \n",
       "2    last night special remember special person for...   \n",
       "3    happy bday hamare boxer bhai wele board happy ...   \n",
       "4    stume thevoice trying thevoice history made to...   \n",
       "..                                                 ...   \n",
       "588  near bgc everyone praying youre ok remember lo...   \n",
       "589  feliz tarde va dia espero nhappy day going hop...   \n",
       "590                 last show last show tks broooo rec   \n",
       "591  french fans due venue issues dates shows lyon ...   \n",
       "592  draaronb entirely honest oneself exercise salv...   \n",
       "\n",
       "                                                  freq  \n",
       "0    {'love': 64, 'thank': 46, 'right': 35, 'day': ...  \n",
       "1    {'love': 40, 'great': 27, 'golf': 26, 'back': ...  \n",
       "2    {'amp': 101, 'love': 68, 'show': 51, 'live': 4...  \n",
       "3    {'happy': 54, 'best': 46, 'n': 41, 'amp': 38, ...  \n",
       "4    {'thevoice': 188, 'team': 134, 'bs': 122, 'yal...  \n",
       "..                                                 ...  \n",
       "588  {'n': 27, 'thank': 24, 'myjaps': 24, 'song': 2...  \n",
       "589  {'besafe': 20, 'feliz': 16, 'day': 15, 'mornin...  \n",
       "590  {'last': 2, 'show': 2, 'tks': 1, 'broooo': 1, ...  \n",
       "591  {'mode': 102, 'singles': 95, 'depeche': 92, 'd...  \n",
       "592  {'repost': 4, 'desta': 2, 'must': 2, 'mark': 2...  \n",
       "\n",
       "[593 rows x 4 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitterwordslemma=pd.read_pickle('maindalemma.pkl')\n",
    "twitterwordslemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['stoped_lemma'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/richardmacken/codeup-data-science/capstone-project/richard/wrangle_twitter.ipynb Cell 36\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/richardmacken/codeup-data-science/capstone-project/richard/wrangle_twitter.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m num\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/richardmacken/codeup-data-science/capstone-project/richard/wrangle_twitter.ipynb#X44sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m bigdict_type\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m'\u001b[39m:{},\u001b[39m'\u001b[39m\u001b[39mstoped_lemma\u001b[39m\u001b[39m'\u001b[39m:{},\u001b[39m'\u001b[39m\u001b[39mfreq\u001b[39m\u001b[39m'\u001b[39m:{}}\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/richardmacken/codeup-data-science/capstone-project/richard/wrangle_twitter.ipynb#X44sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m group1\u001b[39m=\u001b[39mtwitterwordslemma[[\u001b[39m'\u001b[39;49m\u001b[39mstoped_lemma\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mtype\u001b[39;49m\u001b[39m'\u001b[39;49m]]\u001b[39m.\u001b[39mgroupby(\u001b[39m'\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/richardmacken/codeup-data-science/capstone-project/richard/wrangle_twitter.ipynb#X44sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m group1\u001b[39m.\u001b[39mgroups\u001b[39m.\u001b[39mkeys()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/richardmacken/codeup-data-science/capstone-project/richard/wrangle_twitter.ipynb#X44sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m group1\u001b[39m.\u001b[39mgroups\u001b[39m.\u001b[39mkeys():\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3509\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3510\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3511\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3513\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3514\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5779\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5782\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   5784\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   5785\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5786\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:5845\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5842\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   5844\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m-> 5845\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['stoped_lemma'] not in index\""
     ]
    }
   ],
   "source": [
    "num=0\n",
    "bigdict_type={'type':{},'stoped_lemma':{},'freq':{}}\n",
    "\n",
    "group1=twitterwordslemma[['stoped_lemma','type']].groupby('type')\n",
    "group1.groups.keys()\n",
    "for i in group1.groups.keys():\n",
    "    \n",
    "    x=(','.join(list(group1.get_group(i).stoped_lemma.values)).strip())\n",
    "  \n",
    "    x=stopfilter(x)\n",
    "    \n",
    "   \n",
    "    y=(pd.Series(x.replace(',',' ').strip().split()).value_counts())\n",
    "    cool=dict(y)\n",
    "    bigdict_type['type'].update({num:i})\n",
    "    bigdict_type['stoped_lemma'].update({num:x})\n",
    "    bigdict_type['freq'].update({num:cool})\n",
    "       \n",
    "\n",
    "    num+=1\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "typeslemma=pd.DataFrame(bigdict_type)\n",
    "x=str(typeslemma.stoped_lemma.values).replace(',',' ').replace('[','').replace(']','').replace('\"','').replace(\"'\",'').replace(',',' ').split()\n",
    "y=dict(pd.Series(x).value_counts())\n",
    "aggregatewordfrreq=y\n",
    "# pd.to_pickle(aggregatewordfrreq,'agglemma.pkl')\n",
    "num=len(typeslemma)\n",
    "\n",
    "\n",
    "z=[i.replace(',',' ') for i in typeslemma.stoped_lemma.values]\n",
    "typeslemma=pd.concat([typeslemma,pd.DataFrame({'type':{num:'COMBINED'},'stoped_lemma':{num:str(z).replace(',',' ').replace('[','').replace(']','').replace('\"','').replace(\"'\",'')},'freq':{num:aggregatewordfrreq}})])\n",
    "pd.to_pickle(typeslemma,'typeslemma.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "typeslemma=pd.read_pickle('typeslemma.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "extroverteddf=typeslemma[['type','stoped_lemma']].iloc[0:7]\n",
    "extroverteddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "introverteddf=typeslemma[['type','stoped_lemma']].iloc[8:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqdict=dict(typeslemma.freq.values[-1])\n",
    "#set stuff\n",
    "setlist=[]\n",
    "for i in typeslemma.freq.values:\n",
    "    setlist.append(set(i.keys()))\n",
    "\n",
    "typelist=[]\n",
    "for i in typeslemma.type.values:\n",
    "    typelist.append(i)\n",
    "\n",
    "typessetdict=dict(zip(typelist,setlist))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "keys=list(typessetdict.keys())\n",
    "combined=keys.pop(-1);combined\n",
    "intersectiondict={}\n",
    "c=set(typessetdict.get(combined))\n",
    "keys.reverse()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordcloud_kwargs=dict(max_font_size=10000, min_font_size=.5)\n",
    "\n",
    "for i,k in enumerate(keys):\n",
    "    keyscopy=deepcopy(keys)\n",
    "    kthset=set(typessetdict.get(k))\n",
    "    int=c&kthset\n",
    "    intersectiondict.update({k:int,'intersection count':len(int)})\n",
    "    kfreq=freqdict.get(k)\n",
    "   \n",
    "    keyscopy.pop(i)\n",
    "    unionwithoutk=set()\n",
    "    fig,ax=plt.subplots(figsize=(25,25))\n",
    "    \n",
    "    [unionwithoutk.update(typessetdict.get(cop))for cop in keyscopy]\n",
    "    print(f'{\"_\":>2}'*45,f'\\n\\n{k:>60}\\n\\n',f'{\"_\":>2}'*45,f'\\n\\nintersection length:\\n{len(int)}',f'\\nintersection combined percent:\\n{(len(int)/len(c))*100:.2f}%')\n",
    "\n",
    "   \n",
    "\n",
    "    print(f'number unique to \\n{len(kthset-unionwithoutk)}\\n',f'percent unique of aggregate union combined:\\n{((len(kthset-unionwithoutk))/len(c))*100:.2f}%')\n",
    "    restint=kthset&unionwithoutk\n",
    "    print(f'intersection with rest length:\\n{len(restint)}',f'\\nintersection with rest percent overlap with combined:\\n{(len(restint)/len(c))*100:.2f}%\\n\\n')\n",
    "    \n",
    "    venn3_wordcloud([kthset,unionwithoutk,kthset-unionwithoutk], set_colors=['lime','c','w'],set_edgecolors=['0', '0','0'],ax=ax,set_labels=[f'{k}',f'Union w/o {k}',f'Unique {k}'],word_to_frequency=freqdict)#\n",
    "    plt.show()\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# wordcloud_kwargs=dict(max_font_size=10000, min_font_size=.5)\n",
    "\n",
    "for i,k in enumerate(keys):\n",
    "    keyscopy=deepcopy(keys)\n",
    "    kthset=set(typessetdict.get(k))\n",
    "    int=c&kthset\n",
    "    intersectiondict.update({k:int,'intersection count':len(int)})\n",
    "    kfreq=freqdict.get(k)\n",
    "   \n",
    "    keyscopy.pop(i)\n",
    "    unionwithoutk=set()\n",
    "    fig,ax=plt.subplots(figsize=(25,25))\n",
    "    \n",
    "    [unionwithoutk.update(typessetdict.get(cop))for cop in keyscopy]\n",
    "    print(f'{\"_\":>2}'*45,f'\\n\\n{k:>60}\\n\\n',f'{\"_\":>2}'*45,f'\\n\\nintersection length:\\n{len(int)}',f'\\nintersection combined percent:\\n{(len(int)/len(c))*100:.2f}%')\n",
    "\n",
    "   \n",
    "\n",
    "    print(f'number unique to \\n{len(kthset-unionwithoutk)}\\n',f'percent unique of aggregate union combined:\\n{((len(kthset-unionwithoutk))/len(c))*100:.2f}%')\n",
    "    restint=kthset&unionwithoutk\n",
    "    print(f'intersection with rest length:\\n{len(restint)}',f'\\nintersection with rest percent overlap with combined:\\n{(len(restint)/len(c))*100:.2f}%\\n\\n')\n",
    "    \n",
    "    venn3_wordcloud([kthset,unionwithoutk,kthset-unionwithoutk], set_colors=['red','c','w'],set_edgecolors=['0', '0','0'],ax=ax,set_labels=[f'{k}',f'Union w/o {k}',f'Unique {k}'],word_to_frequency=freqdict)#\n",
    "    plt.show()\n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigint=deepcopy(c)\n",
    "[bigint.intersection_update(typessetdict.get(key))for key in keys]\n",
    "print(f'We have a total of {len(bigint)} in the aggregate intersection\\nWe remove that intersection to compare')\n",
    "for i,k in enumerate(keys):\n",
    "    keyscopy=deepcopy(keys)\n",
    "    kthset=set(typessetdict.get(k))\n",
    "    kthset=kthset-bigint\n",
    "    int=(c&kthset)-bigint\n",
    "    intersectiondict.update({k:int,'intersection count':len(int)})\n",
    "    kfreq=freqdict.get(k)\n",
    "   \n",
    "    keyscopy.pop(i)\n",
    "    unionwithoutk=set()\n",
    "    fig,ax=plt.subplots(figsize=(25,25))\n",
    "    \n",
    "    [unionwithoutk.update(typessetdict.get(cop))for cop in keyscopy]\n",
    "    unionwithoutk=unionwithoutk-bigint\n",
    "    print(f'{\"_\":>2}'*45,f'\\n\\n{k:>60}\\n\\n',f'{\"_\":>2}'*45,f'\\n\\nintersection length:\\n{len(int)}',f'\\nintersection combined percent:\\n{(len(int)/len(c))*100:.2f}%')\n",
    "\n",
    "    unique=(kthset-unionwithoutk)-bigint\n",
    "\n",
    "    print(f'number unique to {k}\\n{len(unique)}\\n',f'percent unique of aggregate union combined:\\n{(len(unique)/len(c))*100:.2f}%')\n",
    "    restint=(kthset&unionwithoutk)-bigint\n",
    "    print(f'intersection with rest length:\\n{len(restint)}',f'\\nintersection with rest percent overlap with combined:\\n{(len(restint)/len(c))*100:.2f}%\\n\\n')\n",
    "    \n",
    "    venn3_wordcloud([kthset,unionwithoutk,kthset-unionwithoutk], set_colors=['lime','.35','w'],set_edgecolors=['0', '0','0'],ax=ax,set_labels=[f'{k}',f'Union w/o {k}',f'Unique {k}'],word_to_frequency=freqdict)#\n",
    "    plt.show()\n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# from itertools import product \n",
    "  \n",
    "# # Get all permutations of length 2 \n",
    "# # and length 2 \n",
    "# x=[\"\".join(seq) for seq in product(\"01\", repeat=4)]\n",
    "# for i in x:\n",
    "#     print(i[0])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumforavg=dataframe[['type','name']].groupby(['type']).nunique().sum()\n",
    "tochart=(dataframe[['type','name']].groupby(['type']).nunique()/sumforavg)*100\n",
    "\n",
    "tochart=tochart.reset_index()\n",
    "tochart['percent']=tochart['name']\n",
    "\n",
    "tochart.drop(columns='name',inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tochart.index=tochart.type\n",
    "tochart.drop(columns='type',inplace=True)\n",
    "tochart=tochart.sort_values(by='percent',ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "genpoppercent=['13.8% 12.3% 11.6% 8.8% 8.7% 8.5% 8.1% 5.4% 4.4% 4.3% 3.3% 3.2% 2.5% 2.1% 1.8% 1.5%']\n",
    "genpoppercent=str(genpoppercent).replace('%','').split()\n",
    "genpoppercent=[float(i.replace('[','').replace(']','').replace('\"','').strip(\"'\")) for i in genpoppercent]\n",
    "\n",
    "\n",
    "types=['ISFJ ESFI ISTJ ISFP ESTI ESFP ENFP ISTP INFP ESTP INTP ENTP ENFJ INTJ ENTI INFT']\n",
    "types=str(types).split()\n",
    "\n",
    "\n",
    "types=[(i.replace('[','').replace(']','').replace('\"','').strip(\"'\")) for i in types]\n",
    "\n",
    "pop=pd.DataFrame(index=types,data={'pop percentage':genpoppercent})\n",
    "\n",
    "tochart=pd.concat([tochart,pop],axis=1,join='inner')\n",
    "tochart.rename(columns={'percent':'found percent'},inplace=True)\n",
    "cols=['pop percentage','found percent']\n",
    "tochart=tochart[cols]\n",
    "tochart.sort_values(by='pop percentage',ascending=False,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "styleddf=tochart.T.style.background_gradient(cmap='Blues',axis=1).format(lambda x : f'{x:.1f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quad1=[0,0,0,0]\n",
    "quad2=[0,0,0,0]\n",
    "quad3=[0,.25,.35,.25]\n",
    "quad4=[.35,.25,.35,.25]\n",
    "\n",
    "explode = []\n",
    "explode.extend(quad1)\n",
    "explode.extend(quad2)\n",
    "explode.extend(quad3)\n",
    "explode.extend(quad4)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "\n",
    "def format_axes(fig):\n",
    "    for i, ax in enumerate(fig.axes):\n",
    "        ax.text(0.5, 0.5, \"ax%d\" % (i+1), va=\"center\", ha=\"center\")\n",
    "        ax.tick_params(labelbottom=False, labelleft=False)\n",
    "m=1.23\n",
    "fig = plt.figure(constrained_layout=False,figsize=(m*20,m*12.361))\n",
    "\n",
    "gs = GridSpec(2, 2, figure=fig)\n",
    "\n",
    "# identical to ax1 = plt.subplot(gs.new_subplotspec((0, 0), colspan=3))\n",
    "\n",
    "\n",
    "\n",
    "plt.suptitle('MBTI: General Population Vs Twitter',fontsize=16,weight='demibold')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "kwargs1={'title':'General Population (Pie)   ','ax':ax1,'legend':False,'ylabel':'',   'cmap':'Blues'}\n",
    "\n",
    "tochart.plot.pie(y='found percent',**kwargs1)\n",
    "\n",
    "\n",
    "\n",
    "ax2 = fig.add_subplot(gs[1, 1])\n",
    "\n",
    "kwargs2={'title':'  Twitter (Pie)   ','ax':ax2,'legend':False,'ylabel':'',   'cmap':'viridis'}\n",
    "tochart.plot.pie(y='pop percentage',**kwargs2)\n",
    "\n",
    "\n",
    "ax3 = fig.add_subplot(gs[0,1])\n",
    "kwargs3={'ax':ax3,'legend':False,'title':'Twitter (Bar)',   'cmap':'viridis'}\n",
    "\n",
    "tochart.plot.barh(y='found percent',**kwargs3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ax4 = fig.add_subplot(gs[1, 0])\n",
    "kwargs4={'ax':ax4,'legend':False,'title':'General Population (Bar)',   'cmap':'Blues'}\n",
    "tochart.plot.barh(y='pop percentage',**kwargs4)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig.suptitle(\"GridSpec\")\n",
    "format_axes(fig)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "display('Summary',styleddf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything Below was an attempt at Multithreading and Paralellism\n",
    "* ## This can be ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Below are two ways of scraping using CLI commands.\n",
    "# Comment or uncomment as you need. If you currently run the script as is it will scrape both queries\n",
    "# then output two different csv files.\n",
    "\n",
    "# Query by username\n",
    "# Setting variables to be used in format string command below\n",
    "# def parralledindexer():\n",
    "#  #tweet count number is the last n tweets\n",
    "#  # #read in top 1,000 celebs\n",
    "#     url='https://gist.githubusercontent.com/mbejda/9c3353780270e7298763/raw/1bfc4810db4240d85947e6aef85fcae71f475493/Top-1000-Celebrity-Twitter-Accounts.csv'\n",
    "#     tweet_count=100\n",
    "\n",
    "#     celebs=pd.read_csv(url).to_dict()\n",
    "#     count=-1*tweet_count\n",
    "#     celeblen=len(list(celebs.get('twitter').keys()))\n",
    "#     numindex=range(0,tweet_count*celeblen)\n",
    "\n",
    "#     c_with_slice={}\n",
    "#     for c in range(0,celeblen,1):  \n",
    "#             count=count+tweet_count\n",
    "#             maxnum=count+tweet_count     \n",
    "#             cur=numindex[count:maxnum]\n",
    "#             c_with_slice.update({c:cur})\n",
    "           \n",
    "\n",
    "    # mod10={}\n",
    "    # mod9={}\n",
    "    # mod8={}\n",
    "    # mod7={}\n",
    "    # mod6={}\n",
    "    # mod5={}\n",
    "    # mod4={}\n",
    "    # mod3={}\n",
    "    # mod2={}\n",
    "    # keylist=list(c_with_slice.keys())\n",
    "    # for i in keylist:\n",
    "    #     if i%10==0:  \n",
    "    #         mod10.update({i:c_with_slice.get(i)})\n",
    "    #     elif i%9==0:      \n",
    "    #         mod9.update({i:c_with_slice.get(i)})\n",
    "    #     elif i%8==0:       \n",
    "    #         mod8.update({i:c_with_slice.get(i)})\n",
    "    #     elif i%7==0:      \n",
    "    #         mod7.update({i:c_with_slice.get(i)})\n",
    "    #     elif i%6==0:      \n",
    "    #         mod6.update({i:c_with_slice.get(i)})\n",
    "    #     elif i%5==0:      \n",
    "    #         mod5.update({i:c_with_slice.get(i)})\n",
    "    #     elif i%4==0:       \n",
    "    #         mod4.update({i:c_with_slice.get(i)})\n",
    "    #     elif i%3==0:      \n",
    "    #         mod3.update({i:c_with_slice.get(i)})\n",
    "    #     elif i%2==0:     \n",
    "    #         mod2.update({i:c_with_slice.get(i)})\n",
    "#     moddicts=c_with_slice\n",
    "        \n",
    "\n",
    "#     # moddicts={**mod10,**mod9,\n",
    "#     # **mod8,\n",
    "#     # **mod7,\n",
    "#     # **mod6,\n",
    "#     # **mod5,\n",
    "#     # **mod4,\n",
    "#     # **mod3,\n",
    "#     # **mod2}\n",
    "#     return moddicts,celebs\n",
    "\n",
    "# moddicts,celebs=parralledindexer()\n",
    "\n",
    "# ###Think of schem to split then pu\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def actualparrelel():\n",
    "#     '''\n",
    "    \n",
    "#     slow as shit for input output this is for data processing on the comp\n",
    "    \n",
    "    \n",
    "#     '''\n",
    "#     moddicts,celebs=parralledindexer()\n",
    "#     values=[]\n",
    "    \n",
    "    \n",
    "#     # protect the entry point\n",
    "#     if __name__ == '__main__':\n",
    "#         # create and configure the process pool\n",
    "#         with Pool(10) as pool:\n",
    "#             arglist=[]   \n",
    "#             for m in moddicts:\n",
    "#                 arglist.append((m,celebs)) \n",
    "\n",
    "\n",
    "           \n",
    "#             results_async=pool.starmap_async(partitionableTwitterscraper,arglist)\n",
    "#             # get the return values\n",
    "#             try:\n",
    "#                 for value in results_async.get():\n",
    "#                     values.append(value)\n",
    "\n",
    "#             except Exception as e:\n",
    "#                 print(f'Failed with: {e}')\n",
    "#     return values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def actualthreading():\n",
    "#     moddicts,celebs=parralledindexer()\n",
    "#     values=[]\n",
    "    \n",
    "    \n",
    "#     # protect the entry point\n",
    "#     if __name__ == '__main__':\n",
    "#         # create and configure the process pool\n",
    "  \n",
    "#             arglist=[]   \n",
    "#             for m,v in moddicts.items():\n",
    "#                 arglist.append({m:v})\n",
    "#             # print(arglist) #this is fine    \n",
    "\n",
    "#     # We can use a with statement to ensure threads are cleaned up promptly\n",
    "\n",
    "#     threads = min(50, len(moddicts))   \n",
    "#     with concurrent.futures.ThreadPoolExecutor(max_workers=threads) as executor:\n",
    "#         # Start the load operations and mark each future with its URL\n",
    "#         data=[]\n",
    "           \n",
    "\n",
    "#         for arg in arglist:\n",
    "#             for res in executor.submit(partitionableTwitterscraper(arg)):\n",
    "#                 executor.shutdown(wait=True)\n",
    "    \n",
    "#                 try:\n",
    "#                     data.append((res))\n",
    "#                     # print(res[0])\n",
    "#                     # print(res[1])\n",
    "\n",
    "\n",
    "\n",
    "#                 except Exception as exc:\n",
    "#                     pass\n",
    "#                 #  print('%r generated an exception: %s' % (result, exc))\n",
    "#         # else:\n",
    "#         #     # print('%r page is %d bytes' % (result, len(data)))\n",
    "    \n",
    "#     #sets the number of threads to the lesser of 30 or length of urls\n",
    "#     return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import multiprocessing\n",
    "  \n",
    "# # empty list with global scope\n",
    "# result = []\n",
    "# # empty list with global scope\n",
    "\n",
    "# def square_list(mylist):\n",
    "#     \"\"\"\n",
    "#     function to square a given list\n",
    "#     \"\"\"\n",
    "#     global result\n",
    "#     # append squares of mylist to global list result\n",
    "#     for num in mylist:\n",
    "#         result.append(num * num)\n",
    "\n",
    "\n",
    "# def partitionableTwitterscraper(c_with_slice):\n",
    "#     moddicts,celebs=parralledindexer()\n",
    "#     c_with_slice=c_with_slice\n",
    "#     # print(c_with_slice)\n",
    "#     tweet_count =100 \n",
    "#     dictcount=0\n",
    "#     dfdict={}\n",
    "#     errornames=[]\n",
    "\n",
    "\n",
    "    \n",
    "#     print(c_with_slice.keys()) \n",
    "#     print('\\n') \n",
    "#     c=list(c_with_slice.keys())[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     twitter_handle=celebs.get('twitter')\n",
    "#     name=celebs.get('name')\n",
    "#     cur=c_with_slice.get(c)  \n",
    "#     #create Series to append the current handle to the dataframe\n",
    "#     handleseries={i:twitter_handle for i in cur}       \n",
    "#     #create Series to append the current name to dataframe   \n",
    "#     nameseries={i:name for i in cur}\n",
    "    \n",
    "\n",
    "    \n",
    "#     try:\n",
    "#         # Using OS library to call CLI commands in Python\n",
    "#         os.system(\"snscrape --jsonl --max-results {} twitter-search 'from:{}'> user-tweets.json\".format(tweet_count, twitter_handle))\n",
    "\n",
    "#          # Reads the json generated from the CLI command above and creates a pandas dataframe\n",
    "#          #if there is an error then it will just move to the next artist i.e. failsafe \n",
    "#         tweets_df1 = pd.read_json('user-tweets.json', lines=True).set_index(keys=pd.Index(cur)).to_dict()\n",
    "\n",
    "#         if dictcount<=1:\n",
    "#             tweets_df1.update({'name':nameseries})\n",
    "#             tweets_df1.update({'handle':handleseries})\n",
    "#             dfdict={**dfdict,**tweets_df1}\n",
    "#         else:\n",
    "#             for key in dfdict.keys():\n",
    "#                     tweets_df1.update({'name':nameseries})\n",
    "#                     tweets_df1.update({'handle':handleseries})\n",
    "#                     a=tweets_df1.get(key)\n",
    "#                     b=dfdict.get(key)\n",
    "#                     c={**a,**b}\n",
    "#                     dfdict=dfdict.update({key:c})\n",
    "#     except:\n",
    "#         # errornames.append(name)\n",
    "#         # print('errornames:\\n',len(errornames))\n",
    "#         pass \n",
    "\n",
    "\n",
    "#     display(dfdict)\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "  \n",
    "   \n",
    "\n",
    "#     return dfdict\n",
    "\n",
    "\n",
    "  \n",
    "# moddicts,celebs=parralledindexer()\n",
    "# values=[]\n",
    "    \n",
    "    \n",
    "\n",
    "            \n",
    "# if __name__ == \"__main__\":\n",
    "#     # input list\n",
    "#     arglist=[]   \n",
    "#     for m,v in moddicts.items():\n",
    "#         arglist.append({m:v})\n",
    "  \n",
    "    \n",
    "  \n",
    "#     # creating new process\n",
    "#     p1 = multiprocessing.Process(target=partitionableTwitterscraper, args=(arglist,))\n",
    "#     # starting process\n",
    "#     p1.start()\n",
    "#     # wait until process is finished\n",
    "#     p1.join()\n",
    "  \n",
    "#     # print global result list\n",
    "#     print(\"Result(in main program): {}\".format(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maindict=list()\n",
    "\n",
    "# def argcreateator(n=3):\n",
    "#     url='https://gist.githubusercontent.com/mbejda/9c3353780270e7298763/raw/1bfc4810db4240d85947e6aef85fcae71f475493/Top-1000-Celebrity-Twitter-Accounts.csv'\n",
    "#     tweet_count=100\n",
    "\n",
    "#     celebs=pd.read_csv(url).to_dict()\n",
    "\n",
    "#     tweet_count =n #this number is the last n tweets\n",
    "#     dflist=[]\n",
    "#     dfdict={}\n",
    "#     count=-1*tweet_count\n",
    "#     celeblen=len(celebs.get('twitter').keys())\n",
    "#     numindex=list(range(0,tweet_count*celeblen))\n",
    "#     len(numindex)\n",
    "#     arglist=[]\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "#     for c in range(0,celeblen):\n",
    "#         count=count+tweet_count\n",
    "#         maxnum=count+tweet_count\n",
    "\n",
    "#         twitter_handle=(celebs.get('twitter')[c])\n",
    "#         name=(celebs.get('name')[c])\n",
    "\n",
    "#         cur=pd.Index(numindex[count:maxnum])\n",
    "\n",
    "#         #create Series to append the current handle to the dataframe\n",
    "#         handleseries={i:twitter_handle for i in cur}       \n",
    "#         #create Series to append the current name to dataframe   \n",
    "#         nameseries={i:name for i in cur}\n",
    "#         arglist.append([cur,nameseries,handleseries])\n",
    "#     return arglist\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def tweetrip(tweet_count,twitter_handle,nameseries,handleseries,cur):\n",
    "#     global maindict\n",
    "#     os.system(\"snscrape --jsonl --max-results {} twitter-search 'from:{}'> user-tweets.json\".format(tweet_count, twitter_handle))\n",
    "#      # Reads the json generated from the CLI command above and creates a pandas dataframe\n",
    "#      #if there is an error then it will just move to the next  \n",
    "#     tweets_df1 = pd.read_json('user-tweets.json', lines=True).set_index(keys=cur).to_dict()\n",
    "#     tweets_df1.update({'name':nameseries})\n",
    "#     tweets_df1.update({'handle':handleseries})\n",
    "#     maindict.append(pd.DataFrame(tweets_df1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def threader(arglist):\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#     dictcount=0\n",
    "#     errornames=[]\n",
    "\n",
    "   \n",
    "\n",
    "#     # for i in range(0,len(arglist)):\n",
    "#     for i in range(0,len(arglist)):\n",
    "#         tweet_count=len(arglist[i][0]);#display(tweet_count)\n",
    "#         nameseries=arglist[i][1];#display(nameseries)\n",
    "#         handleseries=arglist[i][2];#display(handleseries)\n",
    "#         twitter_handle=list(handleseries.values())[0];#display(twitter_handle)\n",
    "#         cur=arglist[i][0];#display(cur)\n",
    "#         try:\n",
    "#             tweetrip(tweet_count,twitter_handle,nameseries,handleseries,cur)\n",
    "            \n",
    "\n",
    "    \n",
    "#         except:\n",
    "#             errornames.append(twitter_handle)\n",
    "#             print(errornames)\n",
    "#             pass\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # input list\n",
    "#     arglist=argcreateator(n=3)   \n",
    "    \n",
    "    \n",
    "  \n",
    "#     # creating new process\n",
    "#     p1 = multiprocessing.Process(target=threader, args=(arglist,))\n",
    "#     # starting process\n",
    "#     p1.start()\n",
    "#     # wait until process is finished\n",
    "#     p1.join()\n",
    "#     print(maindict)\n",
    "  \n",
    "#     # print global result list\n",
    " \n",
    "\n",
    "  \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
