{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8cb3fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import division\n",
    "import itertools\n",
    "\n",
    "# To get rid of those blocks of red warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Standard Imports\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "import os\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn import metrics\n",
    "from random import randint\n",
    "\n",
    "\n",
    "# Vis Imports\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from wordcloud import WordCloud\n",
    "from PIL import Image\n",
    "\n",
    "# Modeling Imports\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score\n",
    "from sklearn.feature_selection import f_regression \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, RFE\n",
    "import sklearn.preprocessing\n",
    "import statsmodels.api as sm\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# NLP Imports\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Custom Module Imports\n",
    "import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "808c0bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(original):\n",
    "    article = original.lower()\n",
    "    article = unicodedata.normalize('NFKD', article)\\\n",
    "    .encode('ascii', 'ignore')\\\n",
    "    .decode('utf-8')\n",
    "    #use re.sub to remove special characters\n",
    "    article = re.sub(r'[^a-z\\s]', '', article)\n",
    "#   article = re.sub(r'[a-z]{20,}', '', article)\n",
    "#   article = re.sub(r'\\s+', ' ', article)\n",
    "    return article\n",
    "\n",
    "def tokenize(article):\n",
    "    #create the tokenizer\n",
    "    tokenize = nltk.tokenize.ToktokTokenizer()\n",
    "    #use the tokenizer\n",
    "    article = tokenize.tokenize(article, return_str=True)\n",
    "    return article\n",
    "\n",
    "def stem(article):\n",
    "    #create porter stemmer\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    stems = [ps.stem(word) for word in article.split()]\n",
    "    #join words back together\n",
    "    article_stemmed = ' '.join(stems)\n",
    "    return article_stemmed\n",
    "\n",
    "def lemmatize(article):\n",
    "    #create the lemmatizer\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    lemmas = [wnl.lemmatize(word) for word in article.split()]\n",
    "    #join words back together\n",
    "    article_lemmatized = ' '.join(lemmas)\n",
    "    return article_lemmatized\n",
    "\n",
    "more_stopwords = ['like', 'im', 'think', 'dont', 'people', 'know', 'one', 'get', 'really', 'thing',\n",
    "                  'would', 'time', 'type', 'make', 'friend', 'ive', 'feel', 'much', 'love',\n",
    "                 'say', 'way', 'see', 'thing', 'want', 'thing', 'good', 'something', 'lot',\n",
    "                  'also', 'go', 'always', 'even', 'well', 'someone', 'co', 'thing', 'https',\n",
    "                  'could', 'year', 'cant', 'w', 'sent', 'iphone']\n",
    "\n",
    "def remove_stopwords(article):\n",
    "    #save stopwords\n",
    "    stopwords_ls = stopwords.words('english', 'spanish') + more_stopwords\n",
    "    words = article.split()\n",
    "    #remove stopwords from list of words\n",
    "    filtered_words = [word for word in words if word not in stopwords_ls]\n",
    "    #join words back together\n",
    "    article = ' '.join(filtered_words)\n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9c17bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_article(original):\n",
    "    original['stemmed'] = original['posts'].apply(basic_clean).apply(tokenize).apply(remove_stopwords).apply(stem)\n",
    "    original['lemmatized'] = original['posts'].apply(basic_clean).apply(tokenize).apply(remove_stopwords).apply(lemmatize)\n",
    "    original.rename(columns = {'posts':'original'}, inplace = True)\n",
    "    return original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1c0221b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining function filter \n",
    "def filter(x):\n",
    "    if x == 'INTJ' or x == 'INTP' or x == 'ENTJ' or x == 'ENTP':\n",
    "        return 'Analyst'\n",
    "    if x == 'INFJ' or x == 'INFP' or x == 'ENFJ' or x == 'ENFP':\n",
    "        return 'Diplomat'\n",
    "    if x == 'ISTJ' or x == 'ISFJ' or x == 'ESTJ' or x == 'ESFJ':\n",
    "        return 'Sentinel'\n",
    "    if x == 'ISTP' or x == 'ISFP' or x == 'ESTP' or x == 'ESFP':\n",
    "        return 'Explorer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6272ece9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining function filter \n",
    "def filter_alt(x):\n",
    "    if x == 'intj' or x == 'intp' or x == 'entj' or x == 'entp':\n",
    "        return 'Analyst'\n",
    "    if x == 'infj' or x == 'infp' or x == 'enfj' or x == 'enfp':\n",
    "        return 'Diplomat'\n",
    "    if x == 'istj' or x == 'isfj' or x == 'estj' or x == 'esfj':\n",
    "        return 'Sentinel'\n",
    "    if x == 'istp' or x == 'isfp' or x == 'estp' or x == 'esfp':\n",
    "        return 'Explorer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "034fba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining function filter \n",
    "def filter_2(x):\n",
    "    if x == 'INTJ':\n",
    "        return 0\n",
    "    if x == 'INTP':\n",
    "        return 1\n",
    "    if x == 'ENTJ':\n",
    "        return 2\n",
    "    if x == 'ENTP':\n",
    "        return 3\n",
    "    if x == 'INFJ':\n",
    "        return 4\n",
    "    if x == 'INFP':\n",
    "        return 5\n",
    "    if x == 'ENFJ': \n",
    "        return 6\n",
    "    if x == 'ENFP':\n",
    "        return 7\n",
    "    if x == 'ISTJ':\n",
    "        return 8\n",
    "    if x == 'ISFJ': \n",
    "        return 9\n",
    "    if x == 'ESTJ':\n",
    "        return 10\n",
    "    if x == 'ESFJ':\n",
    "        return 11\n",
    "    if x == 'ISTP':\n",
    "        return 12\n",
    "    if x == 'ISFP':\n",
    "        return 13\n",
    "    if x == 'ESTP':\n",
    "        return 14\n",
    "    if x == 'ESFP':\n",
    "        return 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ab5a683",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining function filter \n",
    "def filter_2_alt(x):\n",
    "    if x == 'intj':\n",
    "        return 0\n",
    "    if x == 'intp':\n",
    "        return 1\n",
    "    if x == 'entj':\n",
    "        return 2\n",
    "    if x == 'entp':\n",
    "        return 3\n",
    "    if x == 'infj':\n",
    "        return 4\n",
    "    if x == 'infp':\n",
    "        return 5\n",
    "    if x == 'enfj': \n",
    "        return 6\n",
    "    if x == 'enfp':\n",
    "        return 7\n",
    "    if x == 'istj':\n",
    "        return 8\n",
    "    if x == 'isfj': \n",
    "        return 9\n",
    "    if x == 'estj':\n",
    "        return 10\n",
    "    if x == 'esfj':\n",
    "        return 11\n",
    "    if x == 'istp':\n",
    "        return 12\n",
    "    if x == 'isfp':\n",
    "        return 13\n",
    "    if x == 'estp':\n",
    "        return 14\n",
    "    if x == 'esfp':\n",
    "        return 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14a6b31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining function filter \n",
    "def filter_3(x):\n",
    "    if x == 'Analyst':\n",
    "        return 0\n",
    "    if x == 'Diplomat':\n",
    "        return 1\n",
    "    if x == 'Explorer':\n",
    "        return 2\n",
    "    if x == 'Sentinel':\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "181e4f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kmeans(train, max_centroids=15):\n",
    "    '''\n",
    "    This function takes in the scaled train data set (continuous features only)\n",
    "    and the max number of centroids desired.\n",
    "    \n",
    "    Outputs the seaborn plot of centroids vs inertia to visualize the 'elbow' method.\n",
    "    '''\n",
    "    \n",
    "    n = 1\n",
    "    points = {}\n",
    "    while n <= max_centroids:\n",
    "        km = KMeans(n_clusters = n)\n",
    "        km.fit(train)\n",
    "        points[f'km_{n}'] = {'centroids':n, 'inertia': km.inertia_}\n",
    "        n+=1\n",
    "    \n",
    "    points = pd.DataFrame(points).T\n",
    "    \n",
    "    sns.relplot(data=points, x='centroids', y='inertia').set(title='Elbow Method Plot')\n",
    "    # x = range(0,40,1)\n",
    "    # y = range(0,40,1)\n",
    "    # plt.plot(x,y)\n",
    "    # plt.xlim(0)\n",
    "    # plt.ylim(0)\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c582d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "original = pd.read_pickle('aggName_wo_emojis.pkl')\n",
    "original.rename(columns={'domain': 'personality_domain'}, inplace=True)\n",
    "df1 = original\n",
    "df1 = df1[['type', 'lemmatized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5937121f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original = pd.read_pickle('aggName.pkl')\n",
    "# original['lemmatized'] = [' '.join(map(str, x)) for x in original['lemmatized']]\n",
    "# original.rename(columns={'domain': 'personality_domain'}, inplace=True)\n",
    "# df1 = original\n",
    "# df1 = df1[['type', 'lemmatized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8417f31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "original = pd.read_csv('mbti_1.csv')\n",
    "df0 = prepare_article(original)\n",
    "df0 = df0[['type', 'lemmatized']]\n",
    "df0['type'] = df0['type'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "160f202a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>infj</td>\n",
       "      <td>httpwwwyoutubecomwatchvqsxhcwekrwhttpmediatumb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entp</td>\n",
       "      <td>finding lack post alarmingsex boring position ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>intp</td>\n",
       "      <td>httpswwwyoutubecomwatchvfhigbolffgwof course t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>intj</td>\n",
       "      <td>dear intp enjoyed conversation day esoteric ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entj</td>\n",
       "      <td>youre firedthats another silly misconception a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                         lemmatized\n",
       "0  infj  httpwwwyoutubecomwatchvqsxhcwekrwhttpmediatumb...\n",
       "1  entp  finding lack post alarmingsex boring position ...\n",
       "2  intp  httpswwwyoutubecomwatchvfhigbolffgwof course t...\n",
       "3  intj  dear intp enjoyed conversation day esoteric ga...\n",
       "4  entj  youre firedthats another silly misconception a..."
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e1cff71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enfj</td>\n",
       "      <td>love hearing voice dubbed german artede artefr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>enfj</td>\n",
       "      <td>aaayyyyy could call candy played lazer tag wen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>enfj</td>\n",
       "      <td>yeah laundry lol pennys fan pink sweater skull...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enfj</td>\n",
       "      <td>favorite annoyed uneasy hesitant classic itali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>enfj</td>\n",
       "      <td>nice meet loved chatting best annoyed uneasy h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                         lemmatized\n",
       "0  enfj  love hearing voice dubbed german artede artefr...\n",
       "1  enfj  aaayyyyy could call candy played lazer tag wen...\n",
       "2  enfj  yeah laundry lol pennys fan pink sweater skull...\n",
       "3  enfj  favorite annoyed uneasy hesitant classic itali...\n",
       "4  enfj  nice meet loved chatting best annoyed uneasy h..."
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c613bcb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type          0\n",
       "lemmatized    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df0, df1])\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d62b95e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "infp    1844\n",
       "infj    1491\n",
       "intp    1312\n",
       "intj    1102\n",
       "entp     726\n",
       "enfp     723\n",
       "istp     364\n",
       "isfp     310\n",
       "entj     251\n",
       "enfj     219\n",
       "istj     215\n",
       "isfj     194\n",
       "esfp     135\n",
       "estp     131\n",
       "esfj      87\n",
       "estj      56\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "887d3e6d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>personality_domain</th>\n",
       "      <th>I_E</th>\n",
       "      <th>N_S</th>\n",
       "      <th>T_F</th>\n",
       "      <th>J_P</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>infj</td>\n",
       "      <td>Diplomat</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "      <td>httpwwwyoutubecomwatchvqsxhcwekrwhttpmediatumb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entp</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>finding lack post alarmingsex boring position ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>intp</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>httpswwwyoutubecomwatchvfhigbolffgwof course t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>intj</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>j</td>\n",
       "      <td>dear intp enjoyed conversation day esoteric ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entj</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>j</td>\n",
       "      <td>youre firedthats another silly misconception a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type personality_domain I_E N_S T_F J_P  \\\n",
       "0  infj           Diplomat   i   n   f   j   \n",
       "1  entp            Analyst   e   n   t   p   \n",
       "2  intp            Analyst   i   n   t   p   \n",
       "3  intj            Analyst   i   n   t   j   \n",
       "4  entj            Analyst   e   n   t   j   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  httpwwwyoutubecomwatchvqsxhcwekrwhttpmediatumb...  \n",
       "1  finding lack post alarmingsex boring position ...  \n",
       "2  httpswwwyoutubecomwatchvfhigbolffgwof course t...  \n",
       "3  dear intp enjoyed conversation day esoteric ga...  \n",
       "4  youre firedthats another silly misconception a...  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['personality_domain'] = df['type'].apply(filter_alt)\n",
    "df['I_E'] = df['type'].astype(str).str[0]\n",
    "df['N_S'] = df['type'].astype(str).str[1]\n",
    "df['T_F'] = df['type'].astype(str).str[2]\n",
    "df['J_P'] = df['type'].astype(str).str[3]\n",
    "df = df[['type', 'personality_domain', 'I_E', 'N_S', 'T_F', 'J_P', 'lemmatized']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0c81a2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diplomat    4277\n",
       "Analyst     3391\n",
       "Explorer     940\n",
       "Sentinel     552\n",
       "Name: personality_domain, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.personality_domain.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "56f96218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['type'] = df['type'].str.lower()\n",
    "# df['personality_domain'] = df['personality_domain'].str.lower()\n",
    "# df['I_E'] = df['I_E'].str.lower()\n",
    "# df['N_S'] = df['N_S'].str.lower()\n",
    "# df['T_F'] = df['T_F'].str.lower()\n",
    "# df['J_P'] = df['J_P'].str.lower()\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb137ec2",
   "metadata": {},
   "source": [
    "## 16 types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e8416041",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words Logistic Regression 16 Personalities Train Accuracy: 99.71%\n",
      "-------------\n",
      "Bag of Words Logistic Regression 16 Personalities Validate Accuracy: 58.13%\n",
      "-------------\n",
      "Bag of Words MultinomialNB 16 Personalities Train Accuracy: 55.39%\n",
      "-------------\n",
      "Bag of Words MultinomialNB 16 Personalities Validate Accuracy: 25.00%\n",
      "-------------\n",
      "TF-IDF MultinomialNB Train 16 Personalities Accuracy: 20.51%\n",
      "-------------\n",
      "TF-IDF MultinomialNB 16 Personalities Validate Accuracy: 20.14%\n",
      "-------------\n",
      "TF-IDF Logistic Regression 16 Personalities Train Accuracy: 79.00%\n",
      "-------------\n",
      "TF-IDF Logistic Regression 16 Personalities Validate Accuracy: 55.84%\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "# Make the object\n",
    "tfidf = TfidfVectorizer()\n",
    "# Fit/Transform\n",
    "X = tfidf.fit_transform(df.lemmatized)\n",
    "# What we are predicting\n",
    "y = df.type\n",
    "# Split X and y into train, validate, and test \n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, stratify=y, test_size=.2, random_state=123)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_val, y_train_val, stratify=y_train_val, test_size=.25, random_state=123)\n",
    "# Make train and validate a dataframe\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "# Make the object and fit it\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "# Make columns for the predictions\n",
    "train['predicted_lm'] = lm.predict(X_train)\n",
    "validate['predicted_lm'] = lm.predict(X_validate)\n",
    "# Make the object and fit it\n",
    "MNBclf = MultinomialNB()\n",
    "MNBclf.fit(X_train, y_train)\n",
    "# Make columns for the predictions\n",
    "train['predicted_MNBclf'] = MNBclf.predict(X_train)\n",
    "validate['predicted_MNBclf'] = MNBclf.predict(X_validate)\n",
    "\n",
    "# Make the object and fit/transform it\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df.lemmatized)\n",
    "# Split X and y into train, validate, and test.\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, stratify=y, test_size=.2, random_state=123)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_val, y_train_val, stratify=y_train_val, test_size=.25, random_state=123)\n",
    "# Make the object and fit it\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "# Make columns for the predictions\n",
    "train['bow_predicted_lm'] = lm.predict(X_train)\n",
    "validate['bow_predicted_lm'] = lm.predict(X_validate)\n",
    "# Make the object and fit it\n",
    "MNBclf = MultinomialNB()\n",
    "MNBclf.fit(X_train, y_train)\n",
    "# Make columns for the predictions\n",
    "train['bow_predicted_MNBclf'] = MNBclf.predict(X_train)\n",
    "validate['bow_predicted_MNBclf'] = MNBclf.predict(X_validate)\n",
    "\n",
    "# Print out the results\n",
    "print('Bag of Words Logistic Regression 16 Personalities Train Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.bow_predicted_lm)))\n",
    "print('-------------')\n",
    "print('Bag of Words Logistic Regression 16 Personalities Validate Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.bow_predicted_lm)))\n",
    "print('-------------')\n",
    "print('Bag of Words MultinomialNB 16 Personalities Train Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.bow_predicted_MNBclf)))\n",
    "print('-------------')\n",
    "print('Bag of Words MultinomialNB 16 Personalities Validate Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.bow_predicted_MNBclf)))\n",
    "print('-------------')\n",
    "print('TF-IDF MultinomialNB Train 16 Personalities Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted_MNBclf)))\n",
    "print('-------------')\n",
    "print('TF-IDF MultinomialNB 16 Personalities Validate Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.predicted_MNBclf)))\n",
    "print('-------------')\n",
    "print('TF-IDF Logistic Regression 16 Personalities Train Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted_lm)))\n",
    "print('-------------')\n",
    "print('TF-IDF Logistic Regression 16 Personalities Validate Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.predicted_lm)))\n",
    "print('-------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "11afa34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60/20/20 Train, Validate, Test split\n",
    "train_val, test = train_test_split(df, stratify=df.type, test_size=.2, random_state=123)\n",
    "train, validate = train_test_split(train_val, stratify=train_val.type, test_size=.25, random_state=123)\n",
    "\n",
    "# Make the object\n",
    "tfidf = TfidfVectorizer()\n",
    "# Fit/Transform\n",
    "X = tfidf.fit_transform(train.lemmatized)\n",
    "# run_kmeans(X, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e96edda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Logistic Regression 16 Personalities Train Accuracy: 28.73%\n",
      "-------------\n",
      "Cluster Logistic Regression 16 Personalities Validate Accuracy: 6.06%\n",
      "-------------\n",
      "Cluster MultinomialNB 16 Personalities Train Accuracy: 28.73%\n",
      "-------------\n",
      "Cluster MultinomialNB 16 Personalities Validate Accuracy: 6.06%\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "# Make the object\n",
    "tfidf = TfidfVectorizer()\n",
    "# Fit/Transform\n",
    "X = tfidf.fit_transform(train.lemmatized)\n",
    "\n",
    "cluster = KMeans(init = 'k-means++', n_clusters=8, n_init=15, random_state=123)\n",
    "cluster.fit(X)\n",
    "yhat = cluster.predict(X)\n",
    "train['cluster'] = cluster.labels_\n",
    "dummies = pd.get_dummies(train.cluster, prefix='clust')\n",
    "train = pd.concat([train, dummies], axis=1)\n",
    "\n",
    "# Transform\n",
    "X = tfidf.transform(validate.lemmatized)\n",
    "\n",
    "cluster = KMeans(init = 'k-means++', n_clusters=8, n_init=15, random_state=123)\n",
    "cluster.fit(X)\n",
    "yhat = cluster.predict(X)\n",
    "validate['cluster'] = cluster.labels_\n",
    "dummies = pd.get_dummies(validate.cluster, prefix='clust')\n",
    "validate = pd.concat([validate, dummies], axis=1)\n",
    "\n",
    "# Transform\n",
    "X = tfidf.transform(test.lemmatized)\n",
    "\n",
    "cluster = KMeans(init = 'k-means++', n_clusters=8, n_init=15, random_state=123)\n",
    "cluster.fit(X)\n",
    "yhat = cluster.predict(X)\n",
    "test['cluster'] = cluster.labels_\n",
    "dummies = pd.get_dummies(test.cluster, prefix='clust')\n",
    "test = pd.concat([test, dummies], axis=1)\n",
    "\n",
    "# Features\n",
    "X_train = train[['clust_0', 'clust_1', 'clust_2', 'clust_3', 'clust_4', 'clust_5', 'clust_6', 'clust_7']]\n",
    "# What we are predicting\n",
    "y_train = train.type\n",
    "\n",
    "# Features\n",
    "X_validate = validate[['clust_0', 'clust_1', 'clust_2', 'clust_3', 'clust_4', 'clust_5', 'clust_6', 'clust_7']]\n",
    "# What we are predicting\n",
    "y_validate = validate.type\n",
    "\n",
    "# Features\n",
    "X_test = test[['clust_0', 'clust_1', 'clust_2', 'clust_3', 'clust_4', 'clust_5', 'clust_6', 'clust_7']]\n",
    "# What we are predicting\n",
    "y_test = test.type\n",
    "\n",
    "# Make train and validate a dataframe\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "# Make the object and fit it\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "# Make columns for the predictions\n",
    "train['predicted_lm'] = lm.predict(X_train)\n",
    "validate['predicted_lm'] = lm.predict(X_validate)\n",
    "# Make the object and fit it\n",
    "MNBclf = MultinomialNB()\n",
    "MNBclf.fit(X_train, y_train)\n",
    "# Make columns for the predictions\n",
    "train['predicted_MNBclf'] = MNBclf.predict(X_train)\n",
    "validate['predicted_MNBclf'] = MNBclf.predict(X_validate)\n",
    "\n",
    "\n",
    "# Print out the results\n",
    "print('Cluster Logistic Regression 16 Personalities Train Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted_lm)))\n",
    "print('-------------')\n",
    "print('Cluster Logistic Regression 16 Personalities Validate Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.predicted_lm)))\n",
    "print('-------------')\n",
    "print('Cluster MultinomialNB 16 Personalities Train Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted_MNBclf)))\n",
    "print('-------------')\n",
    "print('Cluster MultinomialNB 16 Personalities Validate Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.predicted_MNBclf)))\n",
    "print('-------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e437c9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type                  0\n",
       "personality_domain    0\n",
       "I_E                   0\n",
       "N_S                   0\n",
       "T_F                   0\n",
       "J_P                   0\n",
       "lemmatized            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "172cd6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.05\n",
      "Accuracy score (training): 0.204\n",
      "Accuracy score (validation): 0.201\n",
      "Learning rate:  0.075\n",
      "Accuracy score (training): 0.208\n",
      "Accuracy score (validation): 0.201\n",
      "Learning rate:  0.1\n",
      "Accuracy score (training): 0.210\n",
      "Accuracy score (validation): 0.201\n",
      "Learning rate:  0.25\n",
      "Accuracy score (training): 0.213\n",
      "Accuracy score (validation): 0.200\n",
      "Learning rate:  0.5\n",
      "Accuracy score (training): 0.214\n",
      "Accuracy score (validation): 0.198\n",
      "Learning rate:  0.75\n",
      "Accuracy score (training): 0.215\n",
      "Accuracy score (validation): 0.199\n",
      "Learning rate:  1\n",
      "Accuracy score (training): 0.215\n",
      "Accuracy score (validation): 0.199\n"
     ]
    }
   ],
   "source": [
    "df['type_encoded'] = df['type'].apply(filter_2_alt)\n",
    "\n",
    "# 60/20/20 Train, Validate, Test split\n",
    "train_val, test = train_test_split(df, stratify=df.type, test_size=.2, random_state=123)\n",
    "train, validate = train_test_split(train_val, stratify=train_val.type, test_size=.25, random_state=123)\n",
    "\n",
    "# Make the object\n",
    "tfidf = TfidfVectorizer()\n",
    "# Fit/Transform\n",
    "X = tfidf.fit_transform(df.lemmatized)\n",
    "# What we are predicting\n",
    "y = df.type_encoded\n",
    "# Split X and y into train, validate, and test \n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, stratify=y, test_size=.2, random_state=123)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_val, y_train_val, stratify=y_train_val, test_size=.25, random_state=123)\n",
    "\n",
    "lr_list = [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "\n",
    "for learning_rate in lr_list:\n",
    "    gb_clf = GradientBoostingClassifier(n_estimators=20, learning_rate=learning_rate, max_features=2, max_depth=2, random_state=123)\n",
    "    gb_clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(gb_clf.score(X_train, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(gb_clf.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8ac35016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XBG TF-IDF 16 Personalities Validate Accuracy: 0.6080786026200873 %\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier()\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "score = xgb_clf.score(X_validate, y_validate)\n",
    "print('XBG TF-IDF 16 Personalities Validate Accuracy:', score, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7b1e3a",
   "metadata": {},
   "source": [
    "## Personality domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b9138c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words Logistic Regression Personality Domain Train Accuracy: 99.95%\n",
      "-------------\n",
      "Bag of Words Logistic Regression Personality Domain Validate Accuracy: 73.64%\n",
      "-------------\n",
      "Bag of Words MultinomialNB Personality Domain Train Accuracy: 83.37%\n",
      "-------------\n",
      "Bag of Words MultinomialNB Personality Domain Validate Accuracy: 61.68%\n",
      "-------------\n",
      "TF-IDF MultinomialNB Personality Domain Train Accuracy: 47.31%\n",
      "-------------\n",
      "TF-IDF MultinomialNB Personality Domain Validate Accuracy: 46.67%\n",
      "-------------\n",
      "TF-IDF Logistic Regression Personality Domain Train Accuracy: 88.21%\n",
      "-------------\n",
      "TF-IDF Logistic Regression Personality Domain Validate Accuracy: 73.69%\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "# Make the object\n",
    "tfidf = TfidfVectorizer()\n",
    "# Fit/Transform\n",
    "X = tfidf.fit_transform(df.lemmatized)\n",
    "# What we are predicting\n",
    "y = df.personality_domain\n",
    "# Split X and y into train, validate, and test \n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, stratify=y, test_size=.2, random_state=123)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_val, y_train_val, stratify=y_train_val, test_size=.25, random_state=123)\n",
    "# Make train and validate a dataframe\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "# Make the object and fit it\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "# Make columns for the predictions\n",
    "train['predicted_lm'] = lm.predict(X_train)\n",
    "validate['predicted_lm'] = lm.predict(X_validate)\n",
    "# Make the object and fit it\n",
    "MNBclf = MultinomialNB()\n",
    "MNBclf.fit(X_train, y_train)\n",
    "# Make columns for the predictions\n",
    "train['predicted_MNBclf'] = MNBclf.predict(X_train)\n",
    "validate['predicted_MNBclf'] = MNBclf.predict(X_validate)\n",
    "\n",
    "# Make the object and fit/transform it\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df.lemmatized)\n",
    "# Split X and y into train, validate, and test.\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, stratify=y, test_size=.2, random_state=123)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_val, y_train_val, stratify=y_train_val, test_size=.25, random_state=123)\n",
    "# Make the object and fit it\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "# Make columns for the predictions\n",
    "train['bow_predicted_lm'] = lm.predict(X_train)\n",
    "validate['bow_predicted_lm'] = lm.predict(X_validate)\n",
    "# Make the object and fit it\n",
    "MNBclf = MultinomialNB()\n",
    "MNBclf.fit(X_train, y_train)\n",
    "# Make columns for the predictions\n",
    "train['bow_predicted_MNBclf'] = MNBclf.predict(X_train)\n",
    "validate['bow_predicted_MNBclf'] = MNBclf.predict(X_validate)\n",
    "\n",
    "# Print out the results\n",
    "print('Bag of Words Logistic Regression Personality Domain Train Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.bow_predicted_lm)))\n",
    "print('-------------')\n",
    "print('Bag of Words Logistic Regression Personality Domain Validate Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.bow_predicted_lm)))\n",
    "print('-------------')\n",
    "print('Bag of Words MultinomialNB Personality Domain Train Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.bow_predicted_MNBclf)))\n",
    "print('-------------')\n",
    "print('Bag of Words MultinomialNB Personality Domain Validate Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.bow_predicted_MNBclf)))\n",
    "print('-------------')\n",
    "print('TF-IDF MultinomialNB Personality Domain Train Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted_MNBclf)))\n",
    "print('-------------')\n",
    "print('TF-IDF MultinomialNB Personality Domain Validate Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.predicted_MNBclf)))\n",
    "print('-------------')\n",
    "print('TF-IDF Logistic Regression Personality Domain Train Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted_lm)))\n",
    "print('-------------')\n",
    "print('TF-IDF Logistic Regression Personality Domain Validate Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.predicted_lm)))\n",
    "print('-------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8b7103a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60/20/20 Train, Validate, Test split\n",
    "train_val, test = train_test_split(df, stratify=df.type, test_size=.2, random_state=123)\n",
    "train, validate = train_test_split(train_val, stratify=train_val.type, test_size=.25, random_state=123)\n",
    "\n",
    "# Make the object\n",
    "tfidf = TfidfVectorizer()\n",
    "# Fit/Transform\n",
    "X = tfidf.fit_transform(train.lemmatized)\n",
    "# run_kmeans(X, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7b2f0f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Logistic Regression Personality Domain Train Accuracy: 22.82%\n",
      "-------------\n",
      "Cluster Logistic Regression Personality Domain Validate Accuracy: 13.76%\n",
      "-------------\n",
      "Cluster MultinomialNB Personality Domain Train Accuracy: 22.82%\n",
      "-------------\n",
      "Cluster MultinomialNB Personality Domain Validate Accuracy: 13.76%\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "# Make the object\n",
    "tfidf = TfidfVectorizer()\n",
    "# Fit/Transform\n",
    "X = tfidf.fit_transform(train.lemmatized)\n",
    "\n",
    "cluster = KMeans(init = 'k-means++', n_clusters=4, n_init=15, random_state=123)\n",
    "cluster.fit(X)\n",
    "yhat = cluster.predict(X)\n",
    "train['cluster'] = cluster.labels_\n",
    "dummies = pd.get_dummies(train.cluster, prefix='clust')\n",
    "train = pd.concat([train, dummies], axis=1)\n",
    "\n",
    "# Transform\n",
    "X = tfidf.transform(validate.lemmatized)\n",
    "\n",
    "cluster = KMeans(init = 'k-means++', n_clusters=4, n_init=15, random_state=123)\n",
    "cluster.fit(X)\n",
    "yhat = cluster.predict(X)\n",
    "validate['cluster'] = cluster.labels_\n",
    "dummies = pd.get_dummies(validate.cluster, prefix='clust')\n",
    "validate = pd.concat([validate, dummies], axis=1)\n",
    "\n",
    "# Transform\n",
    "X = tfidf.transform(test.lemmatized)\n",
    "\n",
    "cluster = KMeans(init = 'k-means++', n_clusters=4, n_init=15, random_state=123)\n",
    "cluster.fit(X)\n",
    "yhat = cluster.predict(X)\n",
    "test['cluster'] = cluster.labels_\n",
    "dummies = pd.get_dummies(test.cluster, prefix='clust')\n",
    "test = pd.concat([test, dummies], axis=1)\n",
    "\n",
    "# Features\n",
    "X_train = train[['clust_0', 'clust_1', 'clust_2', 'clust_3']]\n",
    "# What we are predicting\n",
    "y_train = train.type\n",
    "\n",
    "# Features\n",
    "X_validate = validate[['clust_0', 'clust_1', 'clust_2', 'clust_3']]\n",
    "# What we are predicting\n",
    "y_validate = validate.type\n",
    "\n",
    "# Features\n",
    "X_test = test[['clust_0', 'clust_1', 'clust_2', 'clust_3']]\n",
    "# What we are predicting\n",
    "y_test = test.type\n",
    "\n",
    "# Make train and validate a dataframe\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "# Make the object and fit it\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "# Make columns for the predictions\n",
    "train['predicted_lm'] = lm.predict(X_train)\n",
    "validate['predicted_lm'] = lm.predict(X_validate)\n",
    "# Make the object and fit it\n",
    "MNBclf = MultinomialNB()\n",
    "MNBclf.fit(X_train, y_train)\n",
    "# Make columns for the predictions\n",
    "train['predicted_MNBclf'] = MNBclf.predict(X_train)\n",
    "validate['predicted_MNBclf'] = MNBclf.predict(X_validate)\n",
    "\n",
    "\n",
    "# Print out the results\n",
    "print('Cluster Logistic Regression Personality Domain Train Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted_lm)))\n",
    "print('-------------')\n",
    "print('Cluster Logistic Regression Personality Domain Validate Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.predicted_lm)))\n",
    "print('-------------')\n",
    "print('Cluster MultinomialNB Personality Domain Train Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted_MNBclf)))\n",
    "print('-------------')\n",
    "print('Cluster MultinomialNB Personality Domain Validate Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.predicted_MNBclf)))\n",
    "print('-------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b9316371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.05\n",
      "Accuracy score (training): 0.467\n",
      "Accuracy score (validation): 0.467\n",
      "Learning rate:  0.075\n",
      "Accuracy score (training): 0.467\n",
      "Accuracy score (validation): 0.467\n",
      "Learning rate:  0.1\n",
      "Accuracy score (training): 0.467\n",
      "Accuracy score (validation): 0.467\n",
      "Learning rate:  0.25\n",
      "Accuracy score (training): 0.482\n",
      "Accuracy score (validation): 0.467\n",
      "Learning rate:  0.5\n",
      "Accuracy score (training): 0.482\n",
      "Accuracy score (validation): 0.466\n",
      "Learning rate:  0.75\n",
      "Accuracy score (training): 0.488\n",
      "Accuracy score (validation): 0.464\n",
      "Learning rate:  1\n",
      "Accuracy score (training): 0.488\n",
      "Accuracy score (validation): 0.464\n"
     ]
    }
   ],
   "source": [
    "df['personality_domain_encoded'] = df['personality_domain'].apply(filter_3)\n",
    "\n",
    "# 60/20/20 Train, Validate, Test split\n",
    "train_val, test = train_test_split(df, stratify=df.type, test_size=.2, random_state=123)\n",
    "train, validate = train_test_split(train_val, stratify=train_val.type, test_size=.25, random_state=123)\n",
    "\n",
    "# Make the object\n",
    "tfidf = TfidfVectorizer()\n",
    "# Fit/Transform\n",
    "X = tfidf.fit_transform(df.lemmatized)\n",
    "# What we are predicting\n",
    "y = df.personality_domain_encoded\n",
    "# Split X and y into train, validate, and test \n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, stratify=y, test_size=.2, random_state=123)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_val, y_train_val, stratify=y_train_val, test_size=.25, random_state=123)\n",
    "\n",
    "lr_list = [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "\n",
    "for learning_rate in lr_list:\n",
    "    gb_clf = GradientBoostingClassifier(n_estimators=20, learning_rate=learning_rate, max_features=2, max_depth=2, random_state=123)\n",
    "    gb_clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(gb_clf.score(X_train, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(gb_clf.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "03a60b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XBG TF-IDF Personality Domain Validate Accuracy: 0.7581877729257642 %\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier()\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "score = xgb_clf.score(X_validate, y_validate)\n",
    "print('XBG TF-IDF Personality Domain Validate Accuracy:', score, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "196fbe1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XBG TF-IDF Personality Domain Test Accuracy: 0.7352620087336245 %\n"
     ]
    }
   ],
   "source": [
    "score = xgb_clf.score(X_test, y_test)\n",
    "print('XBG TF-IDF Personality Domain Test Accuracy:', score, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ec78e3",
   "metadata": {},
   "source": [
    "## Pairwise I vs E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1d8942e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>personality_domain</th>\n",
       "      <th>I_E</th>\n",
       "      <th>N_S</th>\n",
       "      <th>T_F</th>\n",
       "      <th>J_P</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>type_encoded</th>\n",
       "      <th>personality_domain_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>infj</td>\n",
       "      <td>Diplomat</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "      <td>httpwwwyoutubecomwatchvqsxhcwekrwhttpmediatumb...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entp</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>finding lack post alarmingsex boring position ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>intp</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>httpswwwyoutubecomwatchvfhigbolffgwof course t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>intj</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>j</td>\n",
       "      <td>dear intp enjoyed conversation day esoteric ga...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entj</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>j</td>\n",
       "      <td>youre firedthats another silly misconception a...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type personality_domain I_E N_S T_F J_P  \\\n",
       "0  infj           Diplomat   i   n   f   j   \n",
       "1  entp            Analyst   e   n   t   p   \n",
       "2  intp            Analyst   i   n   t   p   \n",
       "3  intj            Analyst   i   n   t   j   \n",
       "4  entj            Analyst   e   n   t   j   \n",
       "\n",
       "                                          lemmatized  type_encoded  \\\n",
       "0  httpwwwyoutubecomwatchvqsxhcwekrwhttpmediatumb...             4   \n",
       "1  finding lack post alarmingsex boring position ...             3   \n",
       "2  httpswwwyoutubecomwatchvfhigbolffgwof course t...             1   \n",
       "3  dear intp enjoyed conversation day esoteric ga...             0   \n",
       "4  youre firedthats another silly misconception a...             2   \n",
       "\n",
       "   personality_domain_encoded  \n",
       "0                           1  \n",
       "1                           0  \n",
       "2                           0  \n",
       "3                           0  \n",
       "4                           0  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "55f6b9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words Logistic Regression Train Accuracy: 100.00%\n",
      "-------------\n",
      "Bag of Words Logistic Regression Validate Accuracy: 80.35%\n",
      "-------------\n",
      "Bag of Words MultinomialNB Train Accuracy: 77.49%\n",
      "-------------\n",
      "Bag of Words MultinomialNB Validate Accuracy: 75.87%\n",
      "-------------\n",
      "TF-IDF MultinomialNB Train Accuracy: 74.62%\n",
      "-------------\n",
      "TF-IDF MultinomialNB Validate Accuracy: 74.56%\n",
      "-------------\n",
      "TF-IDF Logistic Regression Train Accuracy: 85.19%\n",
      "-------------\n",
      "TF-IDF Logistic Regression Validate Accuracy: 79.53%\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "# Make the object\n",
    "tfidf = TfidfVectorizer()\n",
    "# Fit/Transform\n",
    "X = tfidf.fit_transform(df.lemmatized)\n",
    "# What we are predicting\n",
    "y = df.I_E\n",
    "# Split X and y into train, validate, and test \n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, stratify=y, test_size=.2, random_state=123)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_val, y_train_val, stratify=y_train_val, test_size=.25, random_state=123)\n",
    "# Make train and validate a dataframe\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "# Make the object and fit it\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "# Make columns for the predictions\n",
    "train['predicted_lm'] = lm.predict(X_train)\n",
    "validate['predicted_lm'] = lm.predict(X_validate)\n",
    "# Make the object and fit it\n",
    "MNBclf = MultinomialNB()\n",
    "MNBclf.fit(X_train, y_train)\n",
    "# Make columns for the predictions\n",
    "train['predicted_MNBclf'] = MNBclf.predict(X_train)\n",
    "validate['predicted_MNBclf'] = MNBclf.predict(X_validate)\n",
    "\n",
    "# Make the object and fit/transform it\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df.lemmatized)\n",
    "# Split X and y into train, validate, and test.\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, stratify=y, test_size=.2, random_state=123)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_val, y_train_val, stratify=y_train_val, test_size=.25, random_state=123)\n",
    "# Make the object and fit it\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "# Make columns for the predictions\n",
    "train['bow_predicted_lm'] = lm.predict(X_train)\n",
    "validate['bow_predicted_lm'] = lm.predict(X_validate)\n",
    "# Make the object and fit it\n",
    "MNBclf = MultinomialNB()\n",
    "MNBclf.fit(X_train, y_train)\n",
    "# Make columns for the predictions\n",
    "train['bow_predicted_MNBclf'] = MNBclf.predict(X_train)\n",
    "validate['bow_predicted_MNBclf'] = MNBclf.predict(X_validate)\n",
    "\n",
    "# Print out the results\n",
    "print('Bag of Words Logistic Regression Train Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.bow_predicted_lm)))\n",
    "print('-------------')\n",
    "print('Bag of Words Logistic Regression Validate Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.bow_predicted_lm)))\n",
    "print('-------------')\n",
    "print('Bag of Words MultinomialNB Train Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.bow_predicted_MNBclf)))\n",
    "print('-------------')\n",
    "print('Bag of Words MultinomialNB Validate Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.bow_predicted_MNBclf)))\n",
    "print('-------------')\n",
    "print('TF-IDF MultinomialNB Train Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted_MNBclf)))\n",
    "print('-------------')\n",
    "print('TF-IDF MultinomialNB Validate Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.predicted_MNBclf)))\n",
    "print('-------------')\n",
    "print('TF-IDF Logistic Regression Train Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted_lm)))\n",
    "print('-------------')\n",
    "print('TF-IDF Logistic Regression Validate Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.predicted_lm)))\n",
    "print('-------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3beef6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60/20/20 Train, Validate, Test split\n",
    "train_val, test = train_test_split(df, stratify=df.type, test_size=.2, random_state=123)\n",
    "train, validate = train_test_split(train_val, stratify=train_val.type, test_size=.25, random_state=123)\n",
    "\n",
    "# Make the object\n",
    "tfidf = TfidfVectorizer()\n",
    "# Fit/Transform\n",
    "X = tfidf.fit_transform(train.lemmatized)\n",
    "# run_kmeans(X, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7979d9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Logistic Regression Train Accuracy: 22.82%\n",
      "-------------\n",
      "Cluster Logistic Regression Validate Accuracy: 13.76%\n",
      "-------------\n",
      "Cluster MultinomialNB Train Accuracy: 22.82%\n",
      "-------------\n",
      "Cluster MultinomialNB Validate Accuracy: 13.76%\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "# Make the object\n",
    "tfidf = TfidfVectorizer()\n",
    "# Fit/Transform\n",
    "X = tfidf.fit_transform(train.lemmatized)\n",
    "\n",
    "cluster = KMeans(init = 'k-means++', n_clusters=4, n_init=15, random_state=123)\n",
    "cluster.fit(X)\n",
    "yhat = cluster.predict(X)\n",
    "train['cluster'] = cluster.labels_\n",
    "dummies = pd.get_dummies(train.cluster, prefix='clust')\n",
    "train = pd.concat([train, dummies], axis=1)\n",
    "\n",
    "# Transform\n",
    "X = tfidf.transform(validate.lemmatized)\n",
    "\n",
    "cluster = KMeans(init = 'k-means++', n_clusters=4, n_init=15, random_state=123)\n",
    "cluster.fit(X)\n",
    "yhat = cluster.predict(X)\n",
    "validate['cluster'] = cluster.labels_\n",
    "dummies = pd.get_dummies(validate.cluster, prefix='clust')\n",
    "validate = pd.concat([validate, dummies], axis=1)\n",
    "\n",
    "# Transform\n",
    "X = tfidf.transform(test.lemmatized)\n",
    "\n",
    "cluster = KMeans(init = 'k-means++', n_clusters=4, n_init=15, random_state=123)\n",
    "cluster.fit(X)\n",
    "yhat = cluster.predict(X)\n",
    "test['cluster'] = cluster.labels_\n",
    "dummies = pd.get_dummies(test.cluster, prefix='clust')\n",
    "test = pd.concat([test, dummies], axis=1)\n",
    "\n",
    "# Features\n",
    "X_train = train[['clust_0', 'clust_1', 'clust_2', 'clust_3']]\n",
    "# What we are predicting\n",
    "y_train = train.type\n",
    "\n",
    "# Features\n",
    "X_validate = validate[['clust_0', 'clust_1', 'clust_2', 'clust_3']]\n",
    "# What we are predicting\n",
    "y_validate = validate.type\n",
    "\n",
    "# Features\n",
    "X_test = test[['clust_0', 'clust_1', 'clust_2', 'clust_3']]\n",
    "# What we are predicting\n",
    "y_test = test.type\n",
    "\n",
    "# Make train and validate a dataframe\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "# Make the object and fit it\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "# Make columns for the predictions\n",
    "train['predicted_lm'] = lm.predict(X_train)\n",
    "validate['predicted_lm'] = lm.predict(X_validate)\n",
    "# Make the object and fit it\n",
    "MNBclf = MultinomialNB()\n",
    "MNBclf.fit(X_train, y_train)\n",
    "# Make columns for the predictions\n",
    "train['predicted_MNBclf'] = MNBclf.predict(X_train)\n",
    "validate['predicted_MNBclf'] = MNBclf.predict(X_validate)\n",
    "\n",
    "\n",
    "# Print out the results\n",
    "print('Cluster Logistic Regression Train Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted_lm)))\n",
    "print('-------------')\n",
    "print('Cluster Logistic Regression Validate Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.predicted_lm)))\n",
    "print('-------------')\n",
    "print('Cluster MultinomialNB Train Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted_MNBclf)))\n",
    "print('-------------')\n",
    "print('Cluster MultinomialNB Validate Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.predicted_MNBclf)))\n",
    "print('-------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93f0374",
   "metadata": {},
   "source": [
    "## Pairwise N vs S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3808b3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words Logistic Regression Train Accuracy: 100.00%\n",
      "-------------\n",
      "Bag of Words Logistic Regression Validate Accuracy: 87.39%\n",
      "-------------\n",
      "Bag of Words MultinomialNB Train Accuracy: 85.61%\n",
      "-------------\n",
      "Bag of Words MultinomialNB Validate Accuracy: 84.66%\n",
      "-------------\n",
      "TF-IDF MultinomialNB Train Accuracy: 83.70%\n",
      "-------------\n",
      "TF-IDF MultinomialNB Validate Accuracy: 83.73%\n",
      "-------------\n",
      "TF-IDF Logistic Regression Train Accuracy: 86.72%\n",
      "-------------\n",
      "TF-IDF Logistic Regression Validate Accuracy: 84.93%\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "# Make the object\n",
    "tfidf = TfidfVectorizer()\n",
    "# Fit/Transform\n",
    "X = tfidf.fit_transform(df.lemmatized)\n",
    "# What we are predicting\n",
    "y = df.N_S\n",
    "# Split X and y into train, validate, and test \n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, stratify=y, test_size=.2, random_state=123)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_val, y_train_val, stratify=y_train_val, test_size=.25, random_state=123)\n",
    "# Make train and validate a dataframe\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "# Make the object and fit it\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "# Make columns for the predictions\n",
    "train['predicted_lm'] = lm.predict(X_train)\n",
    "validate['predicted_lm'] = lm.predict(X_validate)\n",
    "# Make the object and fit it\n",
    "MNBclf = MultinomialNB()\n",
    "MNBclf.fit(X_train, y_train)\n",
    "# Make columns for the predictions\n",
    "train['predicted_MNBclf'] = MNBclf.predict(X_train)\n",
    "validate['predicted_MNBclf'] = MNBclf.predict(X_validate)\n",
    "\n",
    "# Make the object and fit/transform it\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df.lemmatized)\n",
    "# Split X and y into train, validate, and test.\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, stratify=y, test_size=.2, random_state=123)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_val, y_train_val, stratify=y_train_val, test_size=.25, random_state=123)\n",
    "# Make the object and fit it\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "# Make columns for the predictions\n",
    "train['bow_predicted_lm'] = lm.predict(X_train)\n",
    "validate['bow_predicted_lm'] = lm.predict(X_validate)\n",
    "# Make the object and fit it\n",
    "MNBclf = MultinomialNB()\n",
    "MNBclf.fit(X_train, y_train)\n",
    "# Make columns for the predictions\n",
    "train['bow_predicted_MNBclf'] = MNBclf.predict(X_train)\n",
    "validate['bow_predicted_MNBclf'] = MNBclf.predict(X_validate)\n",
    "\n",
    "# Print out the results\n",
    "print('Bag of Words Logistic Regression Train Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.bow_predicted_lm)))\n",
    "print('-------------')\n",
    "print('Bag of Words Logistic Regression Validate Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.bow_predicted_lm)))\n",
    "print('-------------')\n",
    "print('Bag of Words MultinomialNB Train Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.bow_predicted_MNBclf)))\n",
    "print('-------------')\n",
    "print('Bag of Words MultinomialNB Validate Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.bow_predicted_MNBclf)))\n",
    "print('-------------')\n",
    "print('TF-IDF MultinomialNB Train Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted_MNBclf)))\n",
    "print('-------------')\n",
    "print('TF-IDF MultinomialNB Validate Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.predicted_MNBclf)))\n",
    "print('-------------')\n",
    "print('TF-IDF Logistic Regression Train Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted_lm)))\n",
    "print('-------------')\n",
    "print('TF-IDF Logistic Regression Validate Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.predicted_lm)))\n",
    "print('-------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9db36b",
   "metadata": {},
   "source": [
    "## Pairwise T vs F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cf907eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words Logistic Regression Train Accuracy: 100.00%\n",
      "-------------\n",
      "Bag of Words Logistic Regression Validate Accuracy: 80.90%\n",
      "-------------\n",
      "Bag of Words MultinomialNB Train Accuracy: 98.85%\n",
      "-------------\n",
      "Bag of Words MultinomialNB Validate Accuracy: 79.48%\n",
      "-------------\n",
      "TF-IDF MultinomialNB Train Accuracy: 56.73%\n",
      "-------------\n",
      "TF-IDF MultinomialNB Validate Accuracy: 54.69%\n",
      "-------------\n",
      "TF-IDF Logistic Regression Train Accuracy: 93.56%\n",
      "-------------\n",
      "TF-IDF Logistic Regression Validate Accuracy: 84.88%\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "# Make the object\n",
    "tfidf = TfidfVectorizer()\n",
    "# Fit/Transform\n",
    "X = tfidf.fit_transform(df.lemmatized)\n",
    "# What we are predicting\n",
    "y = df.T_F\n",
    "# Split X and y into train, validate, and test \n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, stratify=y, test_size=.2, random_state=123)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_val, y_train_val, stratify=y_train_val, test_size=.25, random_state=123)\n",
    "# Make train and validate a dataframe\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "# Make the object and fit it\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "# Make columns for the predictions\n",
    "train['predicted_lm'] = lm.predict(X_train)\n",
    "validate['predicted_lm'] = lm.predict(X_validate)\n",
    "# Make the object and fit it\n",
    "MNBclf = MultinomialNB()\n",
    "MNBclf.fit(X_train, y_train)\n",
    "# Make columns for the predictions\n",
    "train['predicted_MNBclf'] = MNBclf.predict(X_train)\n",
    "validate['predicted_MNBclf'] = MNBclf.predict(X_validate)\n",
    "\n",
    "# Make the object and fit/transform it\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df.lemmatized)\n",
    "# Split X and y into train, validate, and test.\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, stratify=y, test_size=.2, random_state=123)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_val, y_train_val, stratify=y_train_val, test_size=.25, random_state=123)\n",
    "# Make the object and fit it\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "# Make columns for the predictions\n",
    "train['bow_predicted_lm'] = lm.predict(X_train)\n",
    "validate['bow_predicted_lm'] = lm.predict(X_validate)\n",
    "# Make the object and fit it\n",
    "MNBclf = MultinomialNB()\n",
    "MNBclf.fit(X_train, y_train)\n",
    "# Make columns for the predictions\n",
    "train['bow_predicted_MNBclf'] = MNBclf.predict(X_train)\n",
    "validate['bow_predicted_MNBclf'] = MNBclf.predict(X_validate)\n",
    "\n",
    "# Print out the results\n",
    "print('Bag of Words Logistic Regression Train Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.bow_predicted_lm)))\n",
    "print('-------------')\n",
    "print('Bag of Words Logistic Regression Validate Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.bow_predicted_lm)))\n",
    "print('-------------')\n",
    "print('Bag of Words MultinomialNB Train Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.bow_predicted_MNBclf)))\n",
    "print('-------------')\n",
    "print('Bag of Words MultinomialNB Validate Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.bow_predicted_MNBclf)))\n",
    "print('-------------')\n",
    "print('TF-IDF MultinomialNB Train Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted_MNBclf)))\n",
    "print('-------------')\n",
    "print('TF-IDF MultinomialNB Validate Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.predicted_MNBclf)))\n",
    "print('-------------')\n",
    "print('TF-IDF Logistic Regression Train Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted_lm)))\n",
    "print('-------------')\n",
    "print('TF-IDF Logistic Regression Validate Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.predicted_lm)))\n",
    "print('-------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1892206",
   "metadata": {},
   "source": [
    "## Pairwise J vs P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e3eff470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words Logistic Regression Train Accuracy: 99.98%\n",
      "-------------\n",
      "Bag of Words Logistic Regression Validate Accuracy: 73.64%\n",
      "-------------\n",
      "Bag of Words MultinomialNB Train Accuracy: 97.65%\n",
      "-------------\n",
      "Bag of Words MultinomialNB Validate Accuracy: 62.23%\n",
      "-------------\n",
      "TF-IDF MultinomialNB Train Accuracy: 60.61%\n",
      "-------------\n",
      "TF-IDF MultinomialNB Validate Accuracy: 60.53%\n",
      "-------------\n",
      "TF-IDF Logistic Regression Train Accuracy: 88.70%\n",
      "-------------\n",
      "TF-IDF Logistic Regression Validate Accuracy: 76.09%\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "# Make the object\n",
    "tfidf = TfidfVectorizer()\n",
    "# Fit/Transform\n",
    "X = tfidf.fit_transform(df.lemmatized)\n",
    "# What we are predicting\n",
    "y = df.J_P\n",
    "# Split X and y into train, validate, and test \n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, stratify=y, test_size=.2, random_state=123)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_val, y_train_val, stratify=y_train_val, test_size=.25, random_state=123)\n",
    "# Make train and validate a dataframe\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "# Make the object and fit it\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "# Make columns for the predictions\n",
    "train['predicted_lm'] = lm.predict(X_train)\n",
    "validate['predicted_lm'] = lm.predict(X_validate)\n",
    "# Make the object and fit it\n",
    "MNBclf = MultinomialNB()\n",
    "MNBclf.fit(X_train, y_train)\n",
    "# Make columns for the predictions\n",
    "train['predicted_MNBclf'] = MNBclf.predict(X_train)\n",
    "validate['predicted_MNBclf'] = MNBclf.predict(X_validate)\n",
    "\n",
    "# Make the object and fit/transform it\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df.lemmatized)\n",
    "# Split X and y into train, validate, and test.\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, stratify=y, test_size=.2, random_state=123)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_val, y_train_val, stratify=y_train_val, test_size=.25, random_state=123)\n",
    "# Make the object and fit it\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "# Make columns for the predictions\n",
    "train['bow_predicted_lm'] = lm.predict(X_train)\n",
    "validate['bow_predicted_lm'] = lm.predict(X_validate)\n",
    "# Make the object and fit it\n",
    "MNBclf = MultinomialNB()\n",
    "MNBclf.fit(X_train, y_train)\n",
    "# Make columns for the predictions\n",
    "train['bow_predicted_MNBclf'] = MNBclf.predict(X_train)\n",
    "validate['bow_predicted_MNBclf'] = MNBclf.predict(X_validate)\n",
    "\n",
    "# Print out the results\n",
    "print('Bag of Words Logistic Regression Train Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.bow_predicted_lm)))\n",
    "print('-------------')\n",
    "print('Bag of Words Logistic Regression Validate Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.bow_predicted_lm)))\n",
    "print('-------------')\n",
    "print('Bag of Words MultinomialNB Train Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.bow_predicted_MNBclf)))\n",
    "print('-------------')\n",
    "print('Bag of Words MultinomialNB Validate Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.bow_predicted_MNBclf)))\n",
    "print('-------------')\n",
    "print('TF-IDF MultinomialNB Train Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted_MNBclf)))\n",
    "print('-------------')\n",
    "print('TF-IDF MultinomialNB Validate Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.predicted_MNBclf)))\n",
    "print('-------------')\n",
    "print('TF-IDF Logistic Regression Train Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted_lm)))\n",
    "print('-------------')\n",
    "print('TF-IDF Logistic Regression Validate Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.predicted_lm)))\n",
    "print('-------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222b2342",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4a39ed85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "I vs E TF-IDF Logistic Regression Train Accuracy: 85.19%\n",
      "-------------\n",
      "I vs E TF-IDF Logistic Regression Validate Accuracy: 79.53%\n",
      "-------------\n",
      "N vs S TF-IDF Logistic Regression Train Accuracy: 86.72%\n",
      "-------------\n",
      "N vs S TF-IDF Logistic Regression Validate Accuracy: 84.93%\n",
      "-------------\n",
      "T vs F TF-IDF Logistic Regression Train Accuracy: 93.56%\n",
      "-------------\n",
      "T vs F TF-IDF Logistic Regression Validate Accuracy: 84.88%\n",
      "-------------\n",
      "J vs P TF-IDF Logistic Regression Train Accuracy: 88.70%\n",
      "-------------\n",
      "J vs P TF-IDF Logistic Regression Validate Accuracy: 76.09%\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "# 60/20/20 Train, Validate, Test split\n",
    "train_val, test = train_test_split(df, stratify=df.type, test_size=.2, random_state=123)\n",
    "train, validate = train_test_split(train_val, stratify=train_val.type, test_size=.25, random_state=123)\n",
    "\n",
    "# Make the object\n",
    "tfidf = TfidfVectorizer()\n",
    "# Fit/Transform\n",
    "X = tfidf.fit_transform(df.lemmatized)\n",
    "# What we are predicting\n",
    "y = df.I_E\n",
    "# Split X and y into train, validate, and test \n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, stratify=y, test_size=.2, random_state=123)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_val, y_train_val, stratify=y_train_val, test_size=.25, random_state=123)\n",
    "# Make train and validate a dataframe\n",
    "train_1 = pd.DataFrame(dict(actual=y_train))\n",
    "validate_1 = pd.DataFrame(dict(actual=y_validate))\n",
    "# Make the object and fit it\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "# Make columns for the predictions\n",
    "train_1['i_e_predicted_lm'] = lm.predict(X_train)\n",
    "validate_1['i_e_predicted_lm'] = lm.predict(X_validate)\n",
    "\n",
    "# Fit/Transform\n",
    "X = tfidf.fit_transform(df.lemmatized)\n",
    "# What we are predicting\n",
    "y = df.N_S\n",
    "# Split X and y into train, validate, and test \n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, stratify=y, test_size=.2, random_state=123)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_val, y_train_val, stratify=y_train_val, test_size=.25, random_state=123)\n",
    "# Make train and validate a dataframe\n",
    "train_2 = pd.DataFrame(dict(actual=y_train))\n",
    "validate_2 = pd.DataFrame(dict(actual=y_validate))\n",
    "# Make the object and fit it\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "# Make columns for the predictions\n",
    "train_2['n_s_predicted_lm'] = lm.predict(X_train)\n",
    "validate_2['n_s_predicted_lm'] = lm.predict(X_validate)\n",
    "\n",
    "# Fit/Transform\n",
    "X = tfidf.fit_transform(df.lemmatized)\n",
    "# What we are predicting\n",
    "y = df.T_F\n",
    "# Split X and y into train, validate, and test \n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, stratify=y, test_size=.2, random_state=123)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_val, y_train_val, stratify=y_train_val, test_size=.25, random_state=123)\n",
    "# Make train and validate a dataframe\n",
    "train_3 = pd.DataFrame(dict(actual=y_train))\n",
    "validate_3 = pd.DataFrame(dict(actual=y_validate))\n",
    "# Make the object and fit it\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "# Make columns for the predictions\n",
    "train_3['t_f_predicted_lm'] = lm.predict(X_train)\n",
    "validate_3['t_f_predicted_lm'] = lm.predict(X_validate)\n",
    "\n",
    "# Fit/Transform\n",
    "X = tfidf.fit_transform(df.lemmatized)\n",
    "# What we are predicting\n",
    "y = df.J_P\n",
    "# Split X and y into train, validate, and test \n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, stratify=y, test_size=.2, random_state=123)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_val, y_train_val, stratify=y_train_val, test_size=.25, random_state=123)\n",
    "# Make train and validate a dataframe\n",
    "train_4 = pd.DataFrame(dict(actual=y_train))\n",
    "validate_4 = pd.DataFrame(dict(actual=y_validate))\n",
    "# Make the object and fit it\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "# Make columns for the predictions\n",
    "train_4['j_p_predicted_lm'] = lm.predict(X_train)\n",
    "validate_4['j_p_predicted_lm'] = lm.predict(X_validate)\n",
    "\n",
    "# Print out the results\n",
    "print('-------------')\n",
    "print('I vs E TF-IDF Logistic Regression Train Accuracy: {:.2%}'.format(accuracy_score(train_1.actual, train_1.i_e_predicted_lm)))\n",
    "print('-------------')\n",
    "print('I vs E TF-IDF Logistic Regression Validate Accuracy: {:.2%}'.format(accuracy_score(validate_1.actual, validate_1.i_e_predicted_lm)))\n",
    "print('-------------')\n",
    "print('N vs S TF-IDF Logistic Regression Train Accuracy: {:.2%}'.format(accuracy_score(train_2.actual, train_2.n_s_predicted_lm)))\n",
    "print('-------------')\n",
    "print('N vs S TF-IDF Logistic Regression Validate Accuracy: {:.2%}'.format(accuracy_score(validate_2.actual, validate_2.n_s_predicted_lm)))\n",
    "print('-------------')\n",
    "print('T vs F TF-IDF Logistic Regression Train Accuracy: {:.2%}'.format(accuracy_score(train_3.actual, train_3.t_f_predicted_lm)))\n",
    "print('-------------')\n",
    "print('T vs F TF-IDF Logistic Regression Validate Accuracy: {:.2%}'.format(accuracy_score(validate_3.actual, validate_3.t_f_predicted_lm)))\n",
    "print('-------------')\n",
    "print('J vs P TF-IDF Logistic Regression Train Accuracy: {:.2%}'.format(accuracy_score(train_4.actual, train_4.j_p_predicted_lm)))\n",
    "print('-------------')\n",
    "print('J vs P TF-IDF Logistic Regression Validate Accuracy: {:.2%}'.format(accuracy_score(validate_4.actual, validate_4.j_p_predicted_lm)))\n",
    "print('-------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c6181ae8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train = train.reset_index()\n",
    "train_1 = train_1.reset_index()\n",
    "train_2 = train_2.reset_index()\n",
    "train_3 = train_3.reset_index()\n",
    "train_4 = train_4.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fa7330ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate = validate.reset_index()\n",
    "validate_1 = validate_1.reset_index()\n",
    "validate_2 = validate_2.reset_index()\n",
    "validate_3 = validate_3.reset_index()\n",
    "validate_4 = validate_4.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "25e831e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['i_e_predicted_lm'] = train_1['i_e_predicted_lm']\n",
    "train['n_s_predicted_lm'] = train_2['n_s_predicted_lm']\n",
    "train['t_f_predicted_lm'] = train_3['t_f_predicted_lm']\n",
    "train['j_p_predicted_lm'] = train_4['j_p_predicted_lm']\n",
    "validate['i_e_predicted_lm'] = validate_1['i_e_predicted_lm']\n",
    "validate['n_s_predicted_lm'] = validate_2['n_s_predicted_lm']\n",
    "validate['t_f_predicted_lm'] = validate_3['t_f_predicted_lm']\n",
    "validate['j_p_predicted_lm'] = validate_4['j_p_predicted_lm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f5fd8127",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results = train[['type', 'i_e_predicted_lm', 'n_s_predicted_lm', 't_f_predicted_lm', 'j_p_predicted_lm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "db694b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>i_e_predicted_lm</th>\n",
       "      <th>n_s_predicted_lm</th>\n",
       "      <th>t_f_predicted_lm</th>\n",
       "      <th>j_p_predicted_lm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>istp</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>enfp</td>\n",
       "      <td>i</td>\n",
       "      <td>s</td>\n",
       "      <td>t</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>intj</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>infp</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>infp</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type i_e_predicted_lm n_s_predicted_lm t_f_predicted_lm j_p_predicted_lm\n",
       "0  istp                i                n                t                j\n",
       "1  enfp                i                s                t                j\n",
       "2  intj                i                n                f                p\n",
       "3  infp                e                n                t                p\n",
       "4  infp                i                n                f                p"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3f976c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results[\"predicted_type\"] = train_results[\"i_e_predicted_lm\"] + train_results[\"n_s_predicted_lm\"] + train_results[\"t_f_predicted_lm\"] + train_results[\"j_p_predicted_lm\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cabed163",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results = train_results[['type', 'predicted_type', 'i_e_predicted_lm', 'n_s_predicted_lm', 't_f_predicted_lm', 'j_p_predicted_lm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6b6db205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>predicted_type</th>\n",
       "      <th>i_e_predicted_lm</th>\n",
       "      <th>n_s_predicted_lm</th>\n",
       "      <th>t_f_predicted_lm</th>\n",
       "      <th>j_p_predicted_lm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>istp</td>\n",
       "      <td>intj</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>enfp</td>\n",
       "      <td>istj</td>\n",
       "      <td>i</td>\n",
       "      <td>s</td>\n",
       "      <td>t</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>intj</td>\n",
       "      <td>infp</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>infp</td>\n",
       "      <td>entp</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>infp</td>\n",
       "      <td>infp</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type predicted_type i_e_predicted_lm n_s_predicted_lm t_f_predicted_lm  \\\n",
       "0  istp           intj                i                n                t   \n",
       "1  enfp           istj                i                s                t   \n",
       "2  intj           infp                i                n                f   \n",
       "3  infp           entp                e                n                t   \n",
       "4  infp           infp                i                n                f   \n",
       "\n",
       "  j_p_predicted_lm  \n",
       "0                j  \n",
       "1                j  \n",
       "2                p  \n",
       "3                p  \n",
       "4                p  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "39a85407",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_reults = validate[['type', 'i_e_predicted_lm', 'n_s_predicted_lm', 't_f_predicted_lm', 'j_p_predicted_lm']]\n",
    "validate_reults[\"predicted_type\"] = validate_reults[\"i_e_predicted_lm\"] + validate_reults[\"n_s_predicted_lm\"] + validate_reults[\"t_f_predicted_lm\"] + validate_reults[\"j_p_predicted_lm\"]\n",
    "validate_reults = validate_reults[['type', 'predicted_type', 'i_e_predicted_lm', 'n_s_predicted_lm', 't_f_predicted_lm', 'j_p_predicted_lm']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "120ab5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Pairwise Logistic Regression Train Accuracy: 14.77 %\n",
      "TF-IDF Pairwise Logistic Regression Validate Accuracy: 14.9 %\n"
     ]
    }
   ],
   "source": [
    "print('TF-IDF Pairwise Logistic Regression Train Accuracy:', round(((train_results.type == train_results.predicted_type).sum()/ (train_results.shape[0]) * 100), 2), '%')\n",
    "print('TF-IDF Pairwise Logistic Regression Validate Accuracy:', round(((validate_reults.type == validate_reults.predicted_type).sum()/ (validate_reults.shape[0]) * 100), 2), '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "052ebfc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diplomat    4277\n",
       "Analyst     3391\n",
       "Explorer     940\n",
       "Sentinel     552\n",
       "Name: personality_domain, dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.personality_domain.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0a520f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9160, 9)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "730ec5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 Personality Baseline Accuracy: 20.13 %\n",
      "-------------\n",
      "Personality Domain Baseline Accuracy: 46.69 %\n"
     ]
    }
   ],
   "source": [
    "print('16 Personality Baseline Accuracy:',round((1844/9160) * 100, 2),'%')\n",
    "print('-------------')\n",
    "print('Personality Domain Baseline Accuracy:',round((4277/9160) * 100, 2),'%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbe841f",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c73cd5b",
   "metadata": {},
   "source": [
    "## Personality Domain into Pairwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "68c5624f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XBG TF-IDF Personality Domain Validate Accuracy: 76.15 %\n"
     ]
    }
   ],
   "source": [
    "df['personality_domain_encoded'] = df['personality_domain'].apply(filter_3)\n",
    "\n",
    "# 60/20/20 Train, Validate, Test split\n",
    "train_val, test = train_test_split(df, stratify=df.type, test_size=.2, random_state=123)\n",
    "train, validate = train_test_split(train_val, stratify=train_val.type, test_size=.25, random_state=123)\n",
    "\n",
    "# Make the object\n",
    "tfidf = TfidfVectorizer()\n",
    "# Fit/Transform\n",
    "X = tfidf.fit_transform(df.lemmatized)\n",
    "# What we are predicting\n",
    "y = df.personality_domain_encoded\n",
    "# Split X and y into train, validate, and test \n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, stratify=y, test_size=.2, random_state=123)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_val, y_train_val, stratify=y_train_val, test_size=.25, random_state=123)\n",
    "\n",
    "xgb_clf = XGBClassifier()\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "score = xgb_clf.score(X_validate, y_validate)\n",
    "print('XBG TF-IDF Personality Domain Validate Accuracy:', round(score * 100, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "758712c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predict = xgb_clf.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e11370d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8a947a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate['personality_domain_encoded_predicted'] = val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "55d2aea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>personality_domain</th>\n",
       "      <th>I_E</th>\n",
       "      <th>N_S</th>\n",
       "      <th>T_F</th>\n",
       "      <th>J_P</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>type_encoded</th>\n",
       "      <th>personality_domain_encoded</th>\n",
       "      <th>personality_domain_encoded_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2945</th>\n",
       "      <td>infj</td>\n",
       "      <td>Diplomat</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "      <td>disorder rating information paranoid moderate ...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8054</th>\n",
       "      <td>enfp</td>\n",
       "      <td>Diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>p</td>\n",
       "      <td>requires getting point respectably discus matt...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>infj</td>\n",
       "      <td>Diplomat</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "      <td>memory first year overall image hazy couple me...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>infp</td>\n",
       "      <td>Diplomat</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>p</td>\n",
       "      <td>ever blondhaired blueeyed intp alice alice won...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4367</th>\n",
       "      <td>infj</td>\n",
       "      <td>Diplomat</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "      <td>parent responsive need child develop guide pro...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>istj</td>\n",
       "      <td>Sentinel</td>\n",
       "      <td>i</td>\n",
       "      <td>s</td>\n",
       "      <td>t</td>\n",
       "      <td>j</td>\n",
       "      <td>thank done wrong love abhishek pride may ef ad...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>infj</td>\n",
       "      <td>Diplomat</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "      <td>sup brah keep great work help many cani last p...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517</th>\n",
       "      <td>entp</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>curiosity turn outlol oh opinion changed recko...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5920</th>\n",
       "      <td>intp</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>haha actually bit worried highly doubt definit...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4150</th>\n",
       "      <td>infj</td>\n",
       "      <td>Diplomat</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "      <td>id travel whole world hug every person perc es...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1832 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type personality_domain I_E N_S T_F J_P  \\\n",
       "2945  infj           Diplomat   i   n   f   j   \n",
       "8054  enfp           Diplomat   e   n   f   p   \n",
       "2795  infj           Diplomat   i   n   f   j   \n",
       "1182  infp           Diplomat   i   n   f   p   \n",
       "4367  infj           Diplomat   i   n   f   j   \n",
       "...    ...                ...  ..  ..  ..  ..   \n",
       "449   istj           Sentinel   i   s   t   j   \n",
       "1129  infj           Diplomat   i   n   f   j   \n",
       "2517  entp            Analyst   e   n   t   p   \n",
       "5920  intp            Analyst   i   n   t   p   \n",
       "4150  infj           Diplomat   i   n   f   j   \n",
       "\n",
       "                                             lemmatized  type_encoded  \\\n",
       "2945  disorder rating information paranoid moderate ...             4   \n",
       "8054  requires getting point respectably discus matt...             7   \n",
       "2795  memory first year overall image hazy couple me...             4   \n",
       "1182  ever blondhaired blueeyed intp alice alice won...             5   \n",
       "4367  parent responsive need child develop guide pro...             4   \n",
       "...                                                 ...           ...   \n",
       "449   thank done wrong love abhishek pride may ef ad...             8   \n",
       "1129  sup brah keep great work help many cani last p...             4   \n",
       "2517  curiosity turn outlol oh opinion changed recko...             3   \n",
       "5920  haha actually bit worried highly doubt definit...             1   \n",
       "4150  id travel whole world hug every person perc es...             4   \n",
       "\n",
       "      personality_domain_encoded  personality_domain_encoded_predicted  \n",
       "2945                           1                                     1  \n",
       "8054                           1                                     1  \n",
       "2795                           1                                     0  \n",
       "1182                           1                                     1  \n",
       "4367                           1                                     0  \n",
       "...                          ...                                   ...  \n",
       "449                            3                                     0  \n",
       "1129                           1                                     1  \n",
       "2517                           0                                     1  \n",
       "5920                           0                                     0  \n",
       "4150                           1                                     0  \n",
       "\n",
       "[1832 rows x 10 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9b03a453",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining function filter \n",
    "def filter_3_r(x):\n",
    "    if x == 0:\n",
    "        return 'Analyst'\n",
    "    if x == 1:\n",
    "        return 'Diplomat'\n",
    "    if x == 2:\n",
    "        return 'Explorer'\n",
    "    if x == 3:\n",
    "        return 'Sentinel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9c943f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate['personality_domain_predicted'] = validate['personality_domain_encoded_predicted'].apply(filter_3_r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ceb68136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>personality_domain</th>\n",
       "      <th>I_E</th>\n",
       "      <th>N_S</th>\n",
       "      <th>T_F</th>\n",
       "      <th>J_P</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>type_encoded</th>\n",
       "      <th>personality_domain_encoded</th>\n",
       "      <th>personality_domain_encoded_predicted</th>\n",
       "      <th>personality_domain_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2945</th>\n",
       "      <td>infj</td>\n",
       "      <td>Diplomat</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "      <td>disorder rating information paranoid moderate ...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Diplomat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8054</th>\n",
       "      <td>enfp</td>\n",
       "      <td>Diplomat</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>p</td>\n",
       "      <td>requires getting point respectably discus matt...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Diplomat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>infj</td>\n",
       "      <td>Diplomat</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "      <td>memory first year overall image hazy couple me...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>infp</td>\n",
       "      <td>Diplomat</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>p</td>\n",
       "      <td>ever blondhaired blueeyed intp alice alice won...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Diplomat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4367</th>\n",
       "      <td>infj</td>\n",
       "      <td>Diplomat</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "      <td>parent responsive need child develop guide pro...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>istj</td>\n",
       "      <td>Sentinel</td>\n",
       "      <td>i</td>\n",
       "      <td>s</td>\n",
       "      <td>t</td>\n",
       "      <td>j</td>\n",
       "      <td>thank done wrong love abhishek pride may ef ad...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>infj</td>\n",
       "      <td>Diplomat</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "      <td>sup brah keep great work help many cani last p...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Diplomat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517</th>\n",
       "      <td>entp</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>curiosity turn outlol oh opinion changed recko...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Diplomat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5920</th>\n",
       "      <td>intp</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>haha actually bit worried highly doubt definit...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4150</th>\n",
       "      <td>infj</td>\n",
       "      <td>Diplomat</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "      <td>id travel whole world hug every person perc es...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Analyst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1832 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type personality_domain I_E N_S T_F J_P  \\\n",
       "2945  infj           Diplomat   i   n   f   j   \n",
       "8054  enfp           Diplomat   e   n   f   p   \n",
       "2795  infj           Diplomat   i   n   f   j   \n",
       "1182  infp           Diplomat   i   n   f   p   \n",
       "4367  infj           Diplomat   i   n   f   j   \n",
       "...    ...                ...  ..  ..  ..  ..   \n",
       "449   istj           Sentinel   i   s   t   j   \n",
       "1129  infj           Diplomat   i   n   f   j   \n",
       "2517  entp            Analyst   e   n   t   p   \n",
       "5920  intp            Analyst   i   n   t   p   \n",
       "4150  infj           Diplomat   i   n   f   j   \n",
       "\n",
       "                                             lemmatized  type_encoded  \\\n",
       "2945  disorder rating information paranoid moderate ...             4   \n",
       "8054  requires getting point respectably discus matt...             7   \n",
       "2795  memory first year overall image hazy couple me...             4   \n",
       "1182  ever blondhaired blueeyed intp alice alice won...             5   \n",
       "4367  parent responsive need child develop guide pro...             4   \n",
       "...                                                 ...           ...   \n",
       "449   thank done wrong love abhishek pride may ef ad...             8   \n",
       "1129  sup brah keep great work help many cani last p...             4   \n",
       "2517  curiosity turn outlol oh opinion changed recko...             3   \n",
       "5920  haha actually bit worried highly doubt definit...             1   \n",
       "4150  id travel whole world hug every person perc es...             4   \n",
       "\n",
       "      personality_domain_encoded  personality_domain_encoded_predicted  \\\n",
       "2945                           1                                     1   \n",
       "8054                           1                                     1   \n",
       "2795                           1                                     0   \n",
       "1182                           1                                     1   \n",
       "4367                           1                                     0   \n",
       "...                          ...                                   ...   \n",
       "449                            3                                     0   \n",
       "1129                           1                                     1   \n",
       "2517                           0                                     1   \n",
       "5920                           0                                     0   \n",
       "4150                           1                                     0   \n",
       "\n",
       "     personality_domain_predicted  \n",
       "2945                     Diplomat  \n",
       "8054                     Diplomat  \n",
       "2795                      Analyst  \n",
       "1182                     Diplomat  \n",
       "4367                      Analyst  \n",
       "...                           ...  \n",
       "449                       Analyst  \n",
       "1129                     Diplomat  \n",
       "2517                     Diplomat  \n",
       "5920                      Analyst  \n",
       "4150                      Analyst  \n",
       "\n",
       "[1832 rows x 11 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1582fc15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>personality_domain</th>\n",
       "      <th>I_E</th>\n",
       "      <th>N_S</th>\n",
       "      <th>T_F</th>\n",
       "      <th>J_P</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>type_encoded</th>\n",
       "      <th>personality_domain_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>infj</td>\n",
       "      <td>Diplomat</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>j</td>\n",
       "      <td>httpwwwyoutubecomwatchvqsxhcwekrwhttpmediatumb...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entp</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>finding lack post alarmingsex boring position ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>intp</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>httpswwwyoutubecomwatchvfhigbolffgwof course t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>intj</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>j</td>\n",
       "      <td>dear intp enjoyed conversation day esoteric ga...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entj</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>j</td>\n",
       "      <td>youre firedthats another silly misconception a...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type personality_domain I_E N_S T_F J_P  \\\n",
       "0  infj           Diplomat   i   n   f   j   \n",
       "1  entp            Analyst   e   n   t   p   \n",
       "2  intp            Analyst   i   n   t   p   \n",
       "3  intj            Analyst   i   n   t   j   \n",
       "4  entj            Analyst   e   n   t   j   \n",
       "\n",
       "                                          lemmatized  type_encoded  \\\n",
       "0  httpwwwyoutubecomwatchvqsxhcwekrwhttpmediatumb...             4   \n",
       "1  finding lack post alarmingsex boring position ...             3   \n",
       "2  httpswwwyoutubecomwatchvfhigbolffgwof course t...             1   \n",
       "3  dear intp enjoyed conversation day esoteric ga...             0   \n",
       "4  youre firedthats another silly misconception a...             2   \n",
       "\n",
       "   personality_domain_encoded  \n",
       "0                           1  \n",
       "1                           0  \n",
       "2                           0  \n",
       "3                           0  \n",
       "4                           0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1ce8d9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p    0.605349\n",
       "j    0.394651\n",
       "Name: J_P, dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.J_P.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3052c370",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
